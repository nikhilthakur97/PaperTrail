{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 4, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/config.js"],"sourcesContent":["export const HF_HUB_URL = \"https://huggingface.co\";\nexport const HF_ROUTER_URL = \"https://router.huggingface.co\";\nexport const HF_ROUTER_AUTO_ENDPOINT = `${HF_ROUTER_URL}/v1`;\nexport const HF_HEADER_X_BILL_TO = \"X-HF-Bill-To\";\n"],"names":[],"mappings":";;;;;;;;;;AAAO,MAAM,aAAa;AACnB,MAAM,gBAAgB;AACtB,MAAM,0BAA0B,GAAG,cAAc,GAAG,CAAC;AACrD,MAAM,sBAAsB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 22, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/consts.js"],"sourcesContent":["/**\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co\n * for a given Inference Provider,\n * you can add it to the following dictionary, for dev purposes.\n *\n * We also inject into this dictionary from tests.\n */\nexport const HARDCODED_MODEL_INFERENCE_MAPPING = {\n    /**\n     * \"HF model ID\" => \"Model ID on Inference Provider's side\"\n     *\n     * Example:\n     * \"Qwen/Qwen2.5-Coder-32B-Instruct\": \"Qwen2.5-Coder-32B-Instruct\",\n     */\n    baseten: {},\n    \"black-forest-labs\": {},\n    cerebras: {},\n    cohere: {},\n    \"fal-ai\": {},\n    \"featherless-ai\": {},\n    \"fireworks-ai\": {},\n    groq: {},\n    \"hf-inference\": {},\n    hyperbolic: {},\n    nebius: {},\n    novita: {},\n    nscale: {},\n    openai: {},\n    publicai: {},\n    ovhcloud: {},\n    replicate: {},\n    sambanova: {},\n    scaleway: {},\n    together: {},\n    \"zai-org\": {},\n};\n"],"names":[],"mappings":"AAAA;;;;;;CAMC;;;;AACM,MAAM,oCAAoC;IAC7C;;;;;KAKC,GACD,SAAS,CAAC;IACV,qBAAqB,CAAC;IACtB,UAAU,CAAC;IACX,QAAQ,CAAC;IACT,UAAU,CAAC;IACX,kBAAkB,CAAC;IACnB,gBAAgB,CAAC;IACjB,MAAM,CAAC;IACP,gBAAgB,CAAC;IACjB,YAAY,CAAC;IACb,QAAQ,CAAC;IACT,QAAQ,CAAC;IACT,QAAQ,CAAC;IACT,QAAQ,CAAC;IACT,UAAU,CAAC;IACX,UAAU,CAAC;IACX,WAAW,CAAC;IACZ,WAAW,CAAC;IACZ,UAAU,CAAC;IACX,UAAU,CAAC;IACX,WAAW,CAAC;AAChB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 64, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/errors.js"],"sourcesContent":["/**\n * Base class for all inference-related errors.\n */\nexport class InferenceClientError extends Error {\n    constructor(message) {\n        super(message);\n        this.name = \"InferenceClientError\";\n    }\n}\nexport class InferenceClientInputError extends InferenceClientError {\n    constructor(message) {\n        super(message);\n        this.name = \"InputError\";\n    }\n}\nclass InferenceClientHttpRequestError extends InferenceClientError {\n    httpRequest;\n    httpResponse;\n    constructor(message, httpRequest, httpResponse) {\n        super(message);\n        this.httpRequest = {\n            ...httpRequest,\n            ...(httpRequest.headers\n                ? {\n                    headers: {\n                        ...httpRequest.headers,\n                        ...(\"Authorization\" in httpRequest.headers ? { Authorization: `Bearer [redacted]` } : undefined),\n                        /// redact authentication in the request headers\n                    },\n                }\n                : undefined),\n        };\n        this.httpResponse = httpResponse;\n    }\n}\n/**\n * Thrown when the HTTP request to the provider fails, e.g. due to API issues or server errors.\n */\nexport class InferenceClientProviderApiError extends InferenceClientHttpRequestError {\n    constructor(message, httpRequest, httpResponse) {\n        super(message, httpRequest, httpResponse);\n        this.name = \"ProviderApiError\";\n    }\n}\n/**\n * Thrown when the HTTP request to the hub fails, e.g. due to API issues or server errors.\n */\nexport class InferenceClientHubApiError extends InferenceClientHttpRequestError {\n    constructor(message, httpRequest, httpResponse) {\n        super(message, httpRequest, httpResponse);\n        this.name = \"HubApiError\";\n    }\n}\n/**\n * Thrown when the inference output returned by the provider is invalid / does not match the expectations\n */\nexport class InferenceClientProviderOutputError extends InferenceClientError {\n    constructor(message) {\n        super(message);\n        this.name = \"ProviderOutputError\";\n    }\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;;;;;;;;;AACM,MAAM,6BAA6B;IACtC,YAAY,OAAO,CAAE;QACjB,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;AACJ;AACO,MAAM,kCAAkC;IAC3C,YAAY,OAAO,CAAE;QACjB,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;AACJ;AACA,MAAM,wCAAwC;IAC1C,YAAY;IACZ,aAAa;IACb,YAAY,OAAO,EAAE,WAAW,EAAE,YAAY,CAAE;QAC5C,KAAK,CAAC;QACN,IAAI,CAAC,WAAW,GAAG;YACf,GAAG,WAAW;YACd,GAAI,YAAY,OAAO,GACjB;gBACE,SAAS;oBACL,GAAG,YAAY,OAAO;oBACtB,GAAI,mBAAmB,YAAY,OAAO,GAAG;wBAAE,eAAe,CAAC,iBAAiB,CAAC;oBAAC,IAAI,SAAS;gBAEnG;YACJ,IACE,SAAS;QACnB;QACA,IAAI,CAAC,YAAY,GAAG;IACxB;AACJ;AAIO,MAAM,wCAAwC;IACjD,YAAY,OAAO,EAAE,WAAW,EAAE,YAAY,CAAE;QAC5C,KAAK,CAAC,SAAS,aAAa;QAC5B,IAAI,CAAC,IAAI,GAAG;IAChB;AACJ;AAIO,MAAM,mCAAmC;IAC5C,YAAY,OAAO,EAAE,WAAW,EAAE,YAAY,CAAE;QAC5C,KAAK,CAAC,SAAS,aAAa;QAC5B,IAAI,CAAC,IAAI,GAAG;IAChB;AACJ;AAIO,MAAM,2CAA2C;IACpD,YAAY,OAAO,CAAE;QACjB,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 131, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/toArray.js"],"sourcesContent":["export function toArray(obj) {\n    if (Array.isArray(obj)) {\n        return obj;\n    }\n    return [obj];\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,QAAQ,GAAG;IACvB,IAAI,MAAM,OAAO,CAAC,MAAM;QACpB,OAAO;IACX;IACA,OAAO;QAAC;KAAI;AAChB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 147, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/providerHelper.js"],"sourcesContent":["import { HF_ROUTER_URL } from \"../config.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { toArray } from \"../utils/toArray.js\";\n/**\n * Base class for task-specific provider helpers\n */\nexport class TaskProviderHelper {\n    provider;\n    baseUrl;\n    clientSideRoutingOnly;\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        this.provider = provider;\n        this.baseUrl = baseUrl;\n        this.clientSideRoutingOnly = clientSideRoutingOnly;\n    }\n    /**\n     * Prepare the base URL for the request\n     */\n    makeBaseUrl(params) {\n        return params.authMethod !== \"provider-key\" ? `${HF_ROUTER_URL}/${this.provider}` : this.baseUrl;\n    }\n    /**\n     * Prepare the body for the request\n     */\n    makeBody(params) {\n        if (\"data\" in params.args && !!params.args.data) {\n            return params.args.data;\n        }\n        return JSON.stringify(this.preparePayload(params));\n    }\n    /**\n     * Prepare the URL for the request\n     */\n    makeUrl(params) {\n        const baseUrl = this.makeBaseUrl(params);\n        const route = this.makeRoute(params).replace(/^\\/+/, \"\");\n        return `${baseUrl}/${route}`;\n    }\n    /**\n     * Prepare the headers for the request\n     */\n    prepareHeaders(params, isBinary) {\n        const headers = {};\n        if (params.authMethod !== \"none\") {\n            headers[\"Authorization\"] = `Bearer ${params.accessToken}`;\n        }\n        if (!isBinary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n}\n// BASE IMPLEMENTATIONS FOR COMMON PATTERNS\nexport class BaseConversationalTask extends TaskProviderHelper {\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        super(provider, baseUrl, clientSideRoutingOnly);\n    }\n    makeRoute() {\n        return \"v1/chat/completions\";\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            Array.isArray(response?.choices) &&\n            typeof response?.created === \"number\" &&\n            typeof response?.id === \"string\" &&\n            typeof response?.model === \"string\" &&\n            /// Together.ai and Nebius do not output a system_fingerprint\n            (response.system_fingerprint === undefined ||\n                response.system_fingerprint === null ||\n                typeof response.system_fingerprint === \"string\") &&\n            typeof response?.usage === \"object\") {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Expected ChatCompletionOutput\");\n    }\n}\nexport class BaseTextGenerationTask extends TaskProviderHelper {\n    constructor(provider, baseUrl, clientSideRoutingOnly = false) {\n        super(provider, baseUrl, clientSideRoutingOnly);\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/completions\";\n    }\n    async getResponse(response) {\n        const res = toArray(response);\n        if (Array.isArray(res) &&\n            res.length > 0 &&\n            res.every((x) => typeof x === \"object\" && !!x && \"generated_text\" in x && typeof x.generated_text === \"string\")) {\n            return res[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Expected Array<{generated_text: string}>\");\n    }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AAIO,MAAM;IACT,SAAS;IACT,QAAQ;IACR,sBAAsB;IACtB,YAAY,QAAQ,EAAE,OAAO,EAAE,wBAAwB,KAAK,CAAE;QAC1D,IAAI,CAAC,QAAQ,GAAG;QAChB,IAAI,CAAC,OAAO,GAAG;QACf,IAAI,CAAC,qBAAqB,GAAG;IACjC;IACA;;KAEC,GACD,YAAY,MAAM,EAAE;QAChB,OAAO,OAAO,UAAU,KAAK,iBAAiB,GAAG,sLAAa,CAAC,CAAC,EAAE,IAAI,CAAC,QAAQ,EAAE,GAAG,IAAI,CAAC,OAAO;IACpG;IACA;;KAEC,GACD,SAAS,MAAM,EAAE;QACb,IAAI,UAAU,OAAO,IAAI,IAAI,CAAC,CAAC,OAAO,IAAI,CAAC,IAAI,EAAE;YAC7C,OAAO,OAAO,IAAI,CAAC,IAAI;QAC3B;QACA,OAAO,KAAK,SAAS,CAAC,IAAI,CAAC,cAAc,CAAC;IAC9C;IACA;;KAEC,GACD,QAAQ,MAAM,EAAE;QACZ,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC;QACjC,MAAM,QAAQ,IAAI,CAAC,SAAS,CAAC,QAAQ,OAAO,CAAC,QAAQ;QACrD,OAAO,GAAG,QAAQ,CAAC,EAAE,OAAO;IAChC;IACA;;KAEC,GACD,eAAe,MAAM,EAAE,QAAQ,EAAE;QAC7B,MAAM,UAAU,CAAC;QACjB,IAAI,OAAO,UAAU,KAAK,QAAQ;YAC9B,OAAO,CAAC,gBAAgB,GAAG,CAAC,OAAO,EAAE,OAAO,WAAW,EAAE;QAC7D;QACA,IAAI,CAAC,UAAU;YACX,OAAO,CAAC,eAAe,GAAG;QAC9B;QACA,OAAO;IACX;AACJ;AAEO,MAAM,+BAA+B;IACxC,YAAY,QAAQ,EAAE,OAAO,EAAE,wBAAwB,KAAK,CAAE;QAC1D,KAAK,CAAC,UAAU,SAAS;IAC7B;IACA,YAAY;QACR,OAAO;IACX;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,OAAO,IAAI;YACd,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,MAAM,OAAO,CAAC,UAAU,YACxB,OAAO,UAAU,YAAY,YAC7B,OAAO,UAAU,OAAO,YACxB,OAAO,UAAU,UAAU,YAC3B,6DAA6D;QAC7D,CAAC,SAAS,kBAAkB,KAAK,aAC7B,SAAS,kBAAkB,KAAK,QAChC,OAAO,SAAS,kBAAkB,KAAK,QAAQ,KACnD,OAAO,UAAU,UAAU,UAAU;YACrC,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,+BAA+B;IACxC,YAAY,QAAQ,EAAE,OAAO,EAAE,wBAAwB,KAAK,CAAE;QAC1D,KAAK,CAAC,UAAU,SAAS;IAC7B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,OAAO,IAAI;YACd,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,YAAY;QACR,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,MAAM,IAAA,0LAAO,EAAC;QACpB,IAAI,MAAM,OAAO,CAAC,QACd,IAAI,MAAM,GAAG,KACb,IAAI,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,YAAY,CAAC,CAAC,KAAK,oBAAoB,KAAK,OAAO,EAAE,cAAc,KAAK,WAAW;YACjH,OAAO,GAAG,CAAC,EAAE;QACjB;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 249, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/base64FromBytes.js"],"sourcesContent":["export function base64FromBytes(arr) {\n    if (globalThis.Buffer) {\n        return globalThis.Buffer.from(arr).toString(\"base64\");\n    }\n    else {\n        const bin = [];\n        arr.forEach((byte) => {\n            bin.push(String.fromCharCode(byte));\n        });\n        return globalThis.btoa(bin.join(\"\"));\n    }\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,gBAAgB,GAAG;IAC/B,IAAI,WAAW,MAAM,EAAE;QACnB,OAAO,WAAW,MAAM,CAAC,IAAI,CAAC,KAAK,QAAQ,CAAC;IAChD,OACK;QACD,MAAM,MAAM,EAAE;QACd,IAAI,OAAO,CAAC,CAAC;YACT,IAAI,IAAI,CAAC,OAAO,YAAY,CAAC;QACjC;QACA,OAAO,WAAW,IAAI,CAAC,IAAI,IAAI,CAAC;IACpC;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 268, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/pick.js"],"sourcesContent":["/**\n * Return copy of object, only keeping allowlisted properties.\n */\nexport function pick(o, props) {\n    return Object.assign({}, ...props.map((prop) => {\n        if (o[prop] !== undefined) {\n            return { [prop]: o[prop] };\n        }\n    }));\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;AACM,SAAS,KAAK,CAAC,EAAE,KAAK;IACzB,OAAO,OAAO,MAAM,CAAC,CAAC,MAAM,MAAM,GAAG,CAAC,CAAC;QACnC,IAAI,CAAC,CAAC,KAAK,KAAK,WAAW;YACvB,OAAO;gBAAE,CAAC,KAAK,EAAE,CAAC,CAAC,KAAK;YAAC;QAC7B;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 287, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/typedInclude.js"],"sourcesContent":["export function typedInclude(arr, v) {\n    return arr.includes(v);\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,aAAa,GAAG,EAAE,CAAC;IAC/B,OAAO,IAAI,QAAQ,CAAC;AACxB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 298, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/omit.js"],"sourcesContent":["import { pick } from \"./pick.js\";\nimport { typedInclude } from \"./typedInclude.js\";\n/**\n * Return copy of object, omitting blocklisted array of props\n */\nexport function omit(o, props) {\n    const propsArr = Array.isArray(props) ? props : [props];\n    const letsKeep = Object.keys(o).filter((prop) => !typedInclude(propsArr, prop));\n    return pick(o, letsKeep);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;;;AAIO,SAAS,KAAK,CAAC,EAAE,KAAK;IACzB,MAAM,WAAW,MAAM,OAAO,CAAC,SAAS,QAAQ;QAAC;KAAM;IACvD,MAAM,WAAW,OAAO,IAAI,CAAC,GAAG,MAAM,CAAC,CAAC,OAAS,CAAC,IAAA,oMAAY,EAAC,UAAU;IACzE,OAAO,IAAA,oLAAI,EAAC,GAAG;AACnB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 317, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/hf-inference.js"],"sourcesContent":["import { HF_ROUTER_URL } from \"../config.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { toArray } from \"../utils/toArray.js\";\nimport { TaskProviderHelper } from \"./providerHelper.js\";\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nimport { omit } from \"../utils/omit.js\";\nexport const EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS = [\"feature-extraction\", \"sentence-similarity\"];\nexport class HFInferenceTask extends TaskProviderHelper {\n    constructor() {\n        super(\"hf-inference\", `${HF_ROUTER_URL}/hf-inference`);\n    }\n    preparePayload(params) {\n        return params.args;\n    }\n    makeUrl(params) {\n        if (params.model.startsWith(\"http://\") || params.model.startsWith(\"https://\")) {\n            return params.model;\n        }\n        return super.makeUrl(params);\n    }\n    makeRoute(params) {\n        if (params.task && [\"feature-extraction\", \"sentence-similarity\"].includes(params.task)) {\n            // when deployed on hf-inference, those two tasks are automatically compatible with one another.\n            return `models/${params.model}/pipeline/${params.task}`;\n        }\n        return `models/${params.model}`;\n    }\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTextToImageTask extends HFInferenceTask {\n    async getResponse(response, url, headers, outputType) {\n        if (!response) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-to-image API: response is undefined\");\n        }\n        if (typeof response == \"object\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (\"data\" in response && Array.isArray(response.data) && response.data[0].b64_json) {\n                const base64Data = response.data[0].b64_json;\n                if (outputType === \"url\") {\n                    return `data:image/jpeg;base64,${base64Data}`;\n                }\n                const base64Response = await fetch(`data:image/jpeg;base64,${base64Data}`);\n                return await base64Response.blob();\n            }\n            if (\"output\" in response && Array.isArray(response.output)) {\n                if (outputType === \"url\") {\n                    return response.output[0];\n                }\n                const urlResponse = await fetch(response.output[0]);\n                const blob = await urlResponse.blob();\n                return blob;\n            }\n        }\n        if (response instanceof Blob) {\n            if (outputType === \"url\" || outputType === \"json\") {\n                const b64 = await response.arrayBuffer().then((buf) => Buffer.from(buf).toString(\"base64\"));\n                return outputType === \"url\" ? `data:image/jpeg;base64,${b64}` : { output: `data:image/jpeg;base64,${b64}` };\n            }\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-to-image API: expected a Blob\");\n    }\n}\nexport class HFInferenceConversationalTask extends HFInferenceTask {\n    makeUrl(params) {\n        let url;\n        if (params.model.startsWith(\"http://\") || params.model.startsWith(\"https://\")) {\n            url = params.model.trim();\n        }\n        else {\n            url = `${this.makeBaseUrl(params)}/models/${params.model}`;\n        }\n        url = url.replace(/\\/+$/, \"\");\n        if (url.endsWith(\"/v1\")) {\n            url += \"/chat/completions\";\n        }\n        else if (!url.endsWith(\"/chat/completions\")) {\n            url += \"/v1/chat/completions\";\n        }\n        return url;\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTextGenerationTask extends HFInferenceTask {\n    async getResponse(response) {\n        const res = toArray(response);\n        if (Array.isArray(res) && res.every((x) => \"generated_text\" in x && typeof x?.generated_text === \"string\")) {\n            return res?.[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text generation API: expected Array<{generated_text: string}>\");\n    }\n}\nexport class HFInferenceAudioClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x === \"object\" && x !== null && typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-classification API: expected Array<{label: string, score: number}> but received different format\");\n    }\n}\nexport class HFInferenceAutomaticSpeechRecognitionTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n    async preparePayloadAsync(args) {\n        return \"data\" in args\n            ? args\n            : {\n                ...omit(args, \"inputs\"),\n                data: args.inputs,\n            };\n    }\n}\nexport class HFInferenceAudioToAudioTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (!Array.isArray(response)) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-to-audio API: expected Array\");\n        }\n        if (!response.every((elem) => {\n            return (typeof elem === \"object\" &&\n                elem &&\n                \"label\" in elem &&\n                typeof elem.label === \"string\" &&\n                \"content-type\" in elem &&\n                typeof elem[\"content-type\"] === \"string\" &&\n                \"blob\" in elem &&\n                typeof elem.blob === \"string\");\n        })) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference audio-to-audio API: expected Array<{label: string, audio: Blob}>\");\n        }\n        return response;\n    }\n}\nexport class HFInferenceDocumentQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((elem) => typeof elem === \"object\" &&\n                !!elem &&\n                typeof elem?.answer === \"string\" &&\n                (typeof elem.end === \"number\" || typeof elem.end === \"undefined\") &&\n                (typeof elem.score === \"number\" || typeof elem.score === \"undefined\") &&\n                (typeof elem.start === \"number\" || typeof elem.start === \"undefined\"))) {\n            return response[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference document-question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>\");\n    }\n}\nexport class HFInferenceFeatureExtractionTask extends HFInferenceTask {\n    async getResponse(response) {\n        const isNumArrayRec = (arr, maxDepth, curDepth = 0) => {\n            if (curDepth > maxDepth)\n                return false;\n            if (arr.every((x) => Array.isArray(x))) {\n                return arr.every((x) => isNumArrayRec(x, maxDepth, curDepth + 1));\n            }\n            else {\n                return arr.every((x) => typeof x === \"number\");\n            }\n        };\n        if (Array.isArray(response) && isNumArrayRec(response, 3, 0)) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference feature-extraction API: expected Array<number[][][] | number[][] | number[] | number>\");\n    }\n}\nexport class HFInferenceImageClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceImageSegmentationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.label === \"string\" &&\n                typeof x.mask === \"string\" &&\n                (x.score === undefined || typeof x.score === \"number\"))) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-segmentation API: expected Array<{label: string, mask: string, score: number}>\");\n    }\n    async preparePayloadAsync(args) {\n        return {\n            ...args,\n            inputs: base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer())),\n        };\n    }\n}\nexport class HFInferenceImageToTextTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (typeof response?.generated_text !== \"string\") {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-to-text API: expected {generated_text: string}\");\n        }\n        return response;\n    }\n}\nexport class HFInferenceImageToImageTask extends HFInferenceTask {\n    async preparePayloadAsync(args) {\n        if (!args.parameters) {\n            return {\n                ...args,\n                model: args.model,\n                data: args.inputs,\n            };\n        }\n        else {\n            return {\n                ...args,\n                inputs: base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer())),\n            };\n        }\n    }\n    async getResponse(response) {\n        if (response instanceof Blob) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference image-to-image API: expected Blob\");\n    }\n}\nexport class HFInferenceObjectDetectionTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.label === \"string\" &&\n                typeof x.score === \"number\" &&\n                typeof x.box.xmin === \"number\" &&\n                typeof x.box.ymin === \"number\" &&\n                typeof x.box.xmax === \"number\" &&\n                typeof x.box.ymax === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference object-detection API: expected Array<{label: string, score: number, box: {xmin: number, ymin: number, xmax: number, ymax: number}}>\");\n    }\n}\nexport class HFInferenceZeroShotImageClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x.label === \"string\" && typeof x.score === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference zero-shot-image-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceTextClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        const output = response?.[0];\n        if (Array.isArray(output) && output.every((x) => typeof x?.label === \"string\" && typeof x.score === \"number\")) {\n            return output;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference text-classification API: expected Array<{label: string, score: number}>\");\n    }\n}\nexport class HFInferenceQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response)\n            ? response.every((elem) => typeof elem === \"object\" &&\n                !!elem &&\n                typeof elem.answer === \"string\" &&\n                typeof elem.end === \"number\" &&\n                typeof elem.score === \"number\" &&\n                typeof elem.start === \"number\")\n            : typeof response === \"object\" &&\n                !!response &&\n                typeof response.answer === \"string\" &&\n                typeof response.end === \"number\" &&\n                typeof response.score === \"number\" &&\n                typeof response.start === \"number\") {\n            return Array.isArray(response) ? response[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>\");\n    }\n}\nexport class HFInferenceFillMaskTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.score === \"number\" &&\n                typeof x.sequence === \"string\" &&\n                typeof x.token === \"number\" &&\n                typeof x.token_str === \"string\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference fill-mask API: expected Array<{score: number, sequence: string, token: number, token_str: string}>\");\n    }\n}\nexport class HFInferenceZeroShotClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        /// Handle Legacy response format from Inference API\n        if (typeof response === \"object\" &&\n            response !== null &&\n            \"labels\" in response &&\n            \"scores\" in response &&\n            Array.isArray(response.labels) &&\n            Array.isArray(response.scores) &&\n            response.labels.length === response.scores.length &&\n            response.labels.every((label) => typeof label === \"string\") &&\n            response.scores.every((score) => typeof score === \"number\")) {\n            const scores = response.scores;\n            return response.labels.map((label, index) => ({\n                label,\n                score: scores[index],\n            }));\n        }\n        if (Array.isArray(response) && response.every(HFInferenceZeroShotClassificationTask.validateOutputElement)) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference zero-shot-classification API: expected Array<{label: string, score: number}>\");\n    }\n    static validateOutputElement(elem) {\n        return (typeof elem === \"object\" &&\n            !!elem &&\n            \"label\" in elem &&\n            \"score\" in elem &&\n            typeof elem.label === \"string\" &&\n            typeof elem.score === \"number\");\n    }\n}\nexport class HFInferenceSentenceSimilarityTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference sentence-similarity API: expected Array<number>\");\n    }\n}\nexport class HFInferenceTableQuestionAnsweringTask extends HFInferenceTask {\n    static validate(elem) {\n        return (typeof elem === \"object\" &&\n            !!elem &&\n            \"aggregator\" in elem &&\n            typeof elem.aggregator === \"string\" &&\n            \"answer\" in elem &&\n            typeof elem.answer === \"string\" &&\n            \"cells\" in elem &&\n            Array.isArray(elem.cells) &&\n            elem.cells.every((x) => typeof x === \"string\") &&\n            \"coordinates\" in elem &&\n            Array.isArray(elem.coordinates) &&\n            elem.coordinates.every((coord) => Array.isArray(coord) && coord.every((x) => typeof x === \"number\")));\n    }\n    async getResponse(response) {\n        if (Array.isArray(response) && Array.isArray(response)\n            ? response.every((elem) => HFInferenceTableQuestionAnsweringTask.validate(elem))\n            : HFInferenceTableQuestionAnsweringTask.validate(response)) {\n            return Array.isArray(response) ? response[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference table-question-answering API: expected {aggregator: string, answer: string, cells: string[], coordinates: number[][]}\");\n    }\n}\nexport class HFInferenceTokenClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((x) => typeof x.end === \"number\" &&\n                typeof x.entity_group === \"string\" &&\n                typeof x.score === \"number\" &&\n                typeof x.start === \"number\" &&\n                typeof x.word === \"string\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference token-classification API: expected Array<{end: number, entity_group: string, score: number, start: number, word: string}>\");\n    }\n}\nexport class HFInferenceTranslationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x?.translation_text === \"string\")) {\n            return response?.length === 1 ? response?.[0] : response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference translation API: expected Array<{translation_text: string}>\");\n    }\n}\nexport class HFInferenceSummarizationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x?.summary_text === \"string\")) {\n            return response?.[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference summarization API: expected Array<{summary_text: string}>\");\n    }\n}\nexport class HFInferenceTextToSpeechTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n}\nexport class HFInferenceTabularClassificationTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference tabular-classification API: expected Array<number>\");\n    }\n}\nexport class HFInferenceVisualQuestionAnsweringTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) &&\n            response.every((elem) => typeof elem === \"object\" && !!elem && typeof elem?.answer === \"string\" && typeof elem.score === \"number\")) {\n            return response[0];\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference visual-question-answering API: expected Array<{answer: string, score: number}>\");\n    }\n}\nexport class HFInferenceTabularRegressionTask extends HFInferenceTask {\n    async getResponse(response) {\n        if (Array.isArray(response) && response.every((x) => typeof x === \"number\")) {\n            return response;\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from HF-Inference tabular-regression API: expected Array<number>\");\n    }\n}\nexport class HFInferenceTextToAudioTask extends HFInferenceTask {\n    async getResponse(response) {\n        return response;\n    }\n}\n"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;AACO,MAAM,yCAAyC;IAAC;IAAsB;CAAsB;AAC5F,MAAM,wBAAwB,gNAAkB;IACnD,aAAc;QACV,KAAK,CAAC,gBAAgB,GAAG,sLAAa,CAAC,aAAa,CAAC;IACzD;IACA,eAAe,MAAM,EAAE;QACnB,OAAO,OAAO,IAAI;IACtB;IACA,QAAQ,MAAM,EAAE;QACZ,IAAI,OAAO,KAAK,CAAC,UAAU,CAAC,cAAc,OAAO,KAAK,CAAC,UAAU,CAAC,aAAa;YAC3E,OAAO,OAAO,KAAK;QACvB;QACA,OAAO,KAAK,CAAC,QAAQ;IACzB;IACA,UAAU,MAAM,EAAE;QACd,IAAI,OAAO,IAAI,IAAI;YAAC;YAAsB;SAAsB,CAAC,QAAQ,CAAC,OAAO,IAAI,GAAG;YACpF,gGAAgG;YAChG,OAAO,CAAC,OAAO,EAAE,OAAO,KAAK,CAAC,UAAU,EAAE,OAAO,IAAI,EAAE;QAC3D;QACA,OAAO,CAAC,OAAO,EAAE,OAAO,KAAK,EAAE;IACnC;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO;IACX;AACJ;AACO,MAAM,mCAAmC;IAC5C,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,CAAC,UAAU;YACX,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,IAAI,OAAO,YAAY,UAAU;YAC7B,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,IAAI,UAAU,YAAY,MAAM,OAAO,CAAC,SAAS,IAAI,KAAK,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ,EAAE;gBACjF,MAAM,aAAa,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ;gBAC5C,IAAI,eAAe,OAAO;oBACtB,OAAO,CAAC,uBAAuB,EAAE,YAAY;gBACjD;gBACA,MAAM,iBAAiB,MAAM,MAAM,CAAC,uBAAuB,EAAE,YAAY;gBACzE,OAAO,MAAM,eAAe,IAAI;YACpC;YACA,IAAI,YAAY,YAAY,MAAM,OAAO,CAAC,SAAS,MAAM,GAAG;gBACxD,IAAI,eAAe,OAAO;oBACtB,OAAO,SAAS,MAAM,CAAC,EAAE;gBAC7B;gBACA,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM,CAAC,EAAE;gBAClD,MAAM,OAAO,MAAM,YAAY,IAAI;gBACnC,OAAO;YACX;QACJ;QACA,IAAI,oBAAoB,MAAM;YAC1B,IAAI,eAAe,SAAS,eAAe,QAAQ;gBAC/C,MAAM,MAAM,MAAM,SAAS,WAAW,GAAG,IAAI,CAAC,CAAC,MAAQ,OAAO,IAAI,CAAC,KAAK,QAAQ,CAAC;gBACjF,OAAO,eAAe,QAAQ,CAAC,uBAAuB,EAAE,KAAK,GAAG;oBAAE,QAAQ,CAAC,uBAAuB,EAAE,KAAK;gBAAC;YAC9G;YACA,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,sCAAsC;IAC/C,QAAQ,MAAM,EAAE;QACZ,IAAI;QACJ,IAAI,OAAO,KAAK,CAAC,UAAU,CAAC,cAAc,OAAO,KAAK,CAAC,UAAU,CAAC,aAAa;YAC3E,MAAM,OAAO,KAAK,CAAC,IAAI;QAC3B,OACK;YACD,MAAM,GAAG,IAAI,CAAC,WAAW,CAAC,QAAQ,QAAQ,EAAE,OAAO,KAAK,EAAE;QAC9D;QACA,MAAM,IAAI,OAAO,CAAC,QAAQ;QAC1B,IAAI,IAAI,QAAQ,CAAC,QAAQ;YACrB,OAAO;QACX,OACK,IAAI,CAAC,IAAI,QAAQ,CAAC,sBAAsB;YACzC,OAAO;QACX;QACA,OAAO;IACX;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,OAAO,IAAI;YACd,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO;IACX;AACJ;AACO,MAAM,sCAAsC;IAC/C,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,MAAM,IAAA,0LAAO,EAAC;QACpB,IAAI,MAAM,OAAO,CAAC,QAAQ,IAAI,KAAK,CAAC,CAAC,IAAM,oBAAoB,KAAK,OAAO,GAAG,mBAAmB,WAAW;YACxG,OAAO,KAAK,CAAC,EAAE;QACnB;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,2CAA2C;IACpD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,YAAY,MAAM,QAAQ,OAAO,EAAE,KAAK,KAAK,YAAY,OAAO,EAAE,KAAK,KAAK,WAAW;YAC1H,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,kDAAkD;IAC3D,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO;IACX;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,OAAO,UAAU,OACX,OACA;YACE,GAAG,IAAA,oLAAI,EAAC,MAAM,SAAS;YACvB,MAAM,KAAK,MAAM;QACrB;IACR;AACJ;AACO,MAAM,oCAAoC;IAC7C,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,CAAC,MAAM,OAAO,CAAC,WAAW;YAC1B,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,IAAI,CAAC,SAAS,KAAK,CAAC,CAAC;YACjB,OAAQ,OAAO,SAAS,YACpB,QACA,WAAW,QACX,OAAO,KAAK,KAAK,KAAK,YACtB,kBAAkB,QAClB,OAAO,IAAI,CAAC,eAAe,KAAK,YAChC,UAAU,QACV,OAAO,KAAK,IAAI,KAAK;QAC7B,IAAI;YACA,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,OAAO;IACX;AACJ;AACO,MAAM,iDAAiD;IAC1D,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,OAAS,OAAO,SAAS,YACrC,CAAC,CAAC,QACF,OAAO,MAAM,WAAW,YACxB,CAAC,OAAO,KAAK,GAAG,KAAK,YAAY,OAAO,KAAK,GAAG,KAAK,WAAW,KAChE,CAAC,OAAO,KAAK,KAAK,KAAK,YAAY,OAAO,KAAK,KAAK,KAAK,WAAW,KACpE,CAAC,OAAO,KAAK,KAAK,KAAK,YAAY,OAAO,KAAK,KAAK,KAAK,WAAW,IAAI;YAC5E,OAAO,QAAQ,CAAC,EAAE;QACtB;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,yCAAyC;IAClD,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,gBAAgB,CAAC,KAAK,UAAU,WAAW,CAAC;YAC9C,IAAI,WAAW,UACX,OAAO;YACX,IAAI,IAAI,KAAK,CAAC,CAAC,IAAM,MAAM,OAAO,CAAC,KAAK;gBACpC,OAAO,IAAI,KAAK,CAAC,CAAC,IAAM,cAAc,GAAG,UAAU,WAAW;YAClE,OACK;gBACD,OAAO,IAAI,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM;YACzC;QACJ;QACA,IAAI,MAAM,OAAO,CAAC,aAAa,cAAc,UAAU,GAAG,IAAI;YAC1D,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,2CAA2C;IACpD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,KAAK,KAAK,YAAY,OAAO,EAAE,KAAK,KAAK,WAAW;YAC9G,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,yCAAyC;IAClD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,KAAK,KAAK,YACrC,OAAO,EAAE,IAAI,KAAK,YAClB,CAAC,EAAE,KAAK,KAAK,aAAa,OAAO,EAAE,KAAK,KAAK,QAAQ,IAAI;YAC7D,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,OAAO;YACH,GAAG,IAAI;YACP,QAAQ,IAAA,0MAAe,EAAC,IAAI,WAAW,KAAK,MAAM,YAAY,cAAc,KAAK,MAAM,GAAG,MAAM,KAAK,MAAM,CAAC,WAAW;QAC3H;IACJ;AACJ;AACO,MAAM,mCAAmC;IAC5C,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,UAAU,mBAAmB,UAAU;YAC9C,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,OAAO;IACX;AACJ;AACO,MAAM,oCAAoC;IAC7C,MAAM,oBAAoB,IAAI,EAAE;QAC5B,IAAI,CAAC,KAAK,UAAU,EAAE;YAClB,OAAO;gBACH,GAAG,IAAI;gBACP,OAAO,KAAK,KAAK;gBACjB,MAAM,KAAK,MAAM;YACrB;QACJ,OACK;YACD,OAAO;gBACH,GAAG,IAAI;gBACP,QAAQ,IAAA,0MAAe,EAAC,IAAI,WAAW,KAAK,MAAM,YAAY,cAAc,KAAK,MAAM,GAAG,MAAM,KAAK,MAAM,CAAC,WAAW;YAC3H;QACJ;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,oBAAoB,MAAM;YAC1B,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,uCAAuC;IAChD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,KAAK,KAAK,YACrC,OAAO,EAAE,KAAK,KAAK,YACnB,OAAO,EAAE,GAAG,CAAC,IAAI,KAAK,YACtB,OAAO,EAAE,GAAG,CAAC,IAAI,KAAK,YACtB,OAAO,EAAE,GAAG,CAAC,IAAI,KAAK,YACtB,OAAO,EAAE,GAAG,CAAC,IAAI,KAAK,WAAW;YACrC,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,mDAAmD;IAC5D,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,KAAK,KAAK,YAAY,OAAO,EAAE,KAAK,KAAK,WAAW;YAC9G,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,0CAA0C;IACnD,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,SAAS,UAAU,CAAC,EAAE;QAC5B,IAAI,MAAM,OAAO,CAAC,WAAW,OAAO,KAAK,CAAC,CAAC,IAAM,OAAO,GAAG,UAAU,YAAY,OAAO,EAAE,KAAK,KAAK,WAAW;YAC3G,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,yCAAyC;IAClD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,YACZ,SAAS,KAAK,CAAC,CAAC,OAAS,OAAO,SAAS,YACvC,CAAC,CAAC,QACF,OAAO,KAAK,MAAM,KAAK,YACvB,OAAO,KAAK,GAAG,KAAK,YACpB,OAAO,KAAK,KAAK,KAAK,YACtB,OAAO,KAAK,KAAK,KAAK,YACxB,OAAO,aAAa,YAClB,CAAC,CAAC,YACF,OAAO,SAAS,MAAM,KAAK,YAC3B,OAAO,SAAS,GAAG,KAAK,YACxB,OAAO,SAAS,KAAK,KAAK,YAC1B,OAAO,SAAS,KAAK,KAAK,UAAU;YACxC,OAAO,MAAM,OAAO,CAAC,YAAY,QAAQ,CAAC,EAAE,GAAG;QACnD;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,gCAAgC;IACzC,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,KAAK,KAAK,YACrC,OAAO,EAAE,QAAQ,KAAK,YACtB,OAAO,EAAE,KAAK,KAAK,YACnB,OAAO,EAAE,SAAS,KAAK,WAAW;YACtC,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,8CAA8C;IACvD,MAAM,YAAY,QAAQ,EAAE;QACxB,oDAAoD;QACpD,IAAI,OAAO,aAAa,YACpB,aAAa,QACb,YAAY,YACZ,YAAY,YACZ,MAAM,OAAO,CAAC,SAAS,MAAM,KAC7B,MAAM,OAAO,CAAC,SAAS,MAAM,KAC7B,SAAS,MAAM,CAAC,MAAM,KAAK,SAAS,MAAM,CAAC,MAAM,IACjD,SAAS,MAAM,CAAC,KAAK,CAAC,CAAC,QAAU,OAAO,UAAU,aAClD,SAAS,MAAM,CAAC,KAAK,CAAC,CAAC,QAAU,OAAO,UAAU,WAAW;YAC7D,MAAM,SAAS,SAAS,MAAM;YAC9B,OAAO,SAAS,MAAM,CAAC,GAAG,CAAC,CAAC,OAAO,QAAU,CAAC;oBAC1C;oBACA,OAAO,MAAM,CAAC,MAAM;gBACxB,CAAC;QACL;QACA,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,sCAAsC,qBAAqB,GAAG;YACxG,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;IACA,OAAO,sBAAsB,IAAI,EAAE;QAC/B,OAAQ,OAAO,SAAS,YACpB,CAAC,CAAC,QACF,WAAW,QACX,WAAW,QACX,OAAO,KAAK,KAAK,KAAK,YACtB,OAAO,KAAK,KAAK,KAAK;IAC9B;AACJ;AACO,MAAM,0CAA0C;IACnD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,WAAW;YACzE,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,8CAA8C;IACvD,OAAO,SAAS,IAAI,EAAE;QAClB,OAAQ,OAAO,SAAS,YACpB,CAAC,CAAC,QACF,gBAAgB,QAChB,OAAO,KAAK,UAAU,KAAK,YAC3B,YAAY,QACZ,OAAO,KAAK,MAAM,KAAK,YACvB,WAAW,QACX,MAAM,OAAO,CAAC,KAAK,KAAK,KACxB,KAAK,KAAK,CAAC,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,aACrC,iBAAiB,QACjB,MAAM,OAAO,CAAC,KAAK,WAAW,KAC9B,KAAK,WAAW,CAAC,KAAK,CAAC,CAAC,QAAU,MAAM,OAAO,CAAC,UAAU,MAAM,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM;IAClG;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,MAAM,OAAO,CAAC,YACvC,SAAS,KAAK,CAAC,CAAC,OAAS,sCAAsC,QAAQ,CAAC,SACxE,sCAAsC,QAAQ,CAAC,WAAW;YAC5D,OAAO,MAAM,OAAO,CAAC,YAAY,QAAQ,CAAC,EAAE,GAAG;QACnD;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,2CAA2C;IACpD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,EAAE,GAAG,KAAK,YACnC,OAAO,EAAE,YAAY,KAAK,YAC1B,OAAO,EAAE,KAAK,KAAK,YACnB,OAAO,EAAE,KAAK,KAAK,YACnB,OAAO,EAAE,IAAI,KAAK,WAAW;YACjC,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,mCAAmC;IAC5C,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,GAAG,qBAAqB,WAAW;YAC3F,OAAO,UAAU,WAAW,IAAI,UAAU,CAAC,EAAE,GAAG;QACpD;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,qCAAqC;IAC9C,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,GAAG,iBAAiB,WAAW;YACvF,OAAO,UAAU,CAAC,EAAE;QACxB;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,oCAAoC;IAC7C,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO;IACX;AACJ;AACO,MAAM,6CAA6C;IACtD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,WAAW;YACzE,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,+CAA+C;IACxD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aACd,SAAS,KAAK,CAAC,CAAC,OAAS,OAAO,SAAS,YAAY,CAAC,CAAC,QAAQ,OAAO,MAAM,WAAW,YAAY,OAAO,KAAK,KAAK,KAAK,WAAW;YACpI,OAAO,QAAQ,CAAC,EAAE;QACtB;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,yCAAyC;IAClD,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,MAAM,OAAO,CAAC,aAAa,SAAS,KAAK,CAAC,CAAC,IAAM,OAAO,MAAM,WAAW;YACzE,OAAO;QACX;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,mCAAmC;IAC5C,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 746, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/lib/logger.js"],"sourcesContent":["let globalLogger = console;\nexport function setLogger(logger) {\n    globalLogger = logger;\n}\nexport function getLogger() {\n    return globalLogger;\n}\n"],"names":[],"mappings":";;;;;;AAAA,IAAI,eAAe;AACZ,SAAS,UAAU,MAAM;IAC5B,eAAe;AACnB;AACO,SAAS;IACZ,OAAO;AACX","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 763, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js"],"sourcesContent":["import { HF_HUB_URL } from \"../config.js\";\nimport { HARDCODED_MODEL_INFERENCE_MAPPING } from \"../providers/consts.js\";\nimport { EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS } from \"../providers/hf-inference.js\";\nimport { typedInclude } from \"../utils/typedInclude.js\";\nimport { InferenceClientHubApiError, InferenceClientInputError } from \"../errors.js\";\nimport { getLogger } from \"./logger.js\";\nexport const inferenceProviderMappingCache = new Map();\n/**\n * Normalize inferenceProviderMapping to always return an array format.\n * This provides backward and forward compatibility for the API changes.\n *\n * Vendored from @huggingface/hub to avoid extra dependency.\n */\nfunction normalizeInferenceProviderMapping(modelId, inferenceProviderMapping) {\n    if (!inferenceProviderMapping) {\n        return [];\n    }\n    // If it's already an array, return it as is\n    if (Array.isArray(inferenceProviderMapping)) {\n        return inferenceProviderMapping;\n    }\n    // Convert mapping to array format\n    return Object.entries(inferenceProviderMapping).map(([provider, mapping]) => ({\n        provider,\n        hfModelId: modelId,\n        providerId: mapping.providerId,\n        status: mapping.status,\n        task: mapping.task,\n        adapter: mapping.adapter,\n        adapterWeightsPath: mapping.adapterWeightsPath,\n    }));\n}\nexport async function fetchInferenceProviderMappingForModel(modelId, accessToken, options) {\n    let inferenceProviderMapping;\n    if (inferenceProviderMappingCache.has(modelId)) {\n        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n        inferenceProviderMapping = inferenceProviderMappingCache.get(modelId);\n    }\n    else {\n        const url = `${HF_HUB_URL}/api/models/${modelId}?expand[]=inferenceProviderMapping`;\n        const resp = await (options?.fetch ?? fetch)(url, {\n            headers: accessToken?.startsWith(\"hf_\") ? { Authorization: `Bearer ${accessToken}` } : {},\n        });\n        if (!resp.ok) {\n            if (resp.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n                const error = await resp.json();\n                if (\"error\" in error && typeof error.error === \"string\") {\n                    throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}: ${error.error}`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: error });\n                }\n            }\n            else {\n                throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n            }\n        }\n        let payload = null;\n        try {\n            payload = await resp.json();\n        }\n        catch {\n            throw new InferenceClientHubApiError(`Failed to fetch inference provider mapping for model ${modelId}: malformed API response, invalid JSON`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n        }\n        if (!payload?.inferenceProviderMapping) {\n            throw new InferenceClientHubApiError(`We have not been able to find inference provider information for model ${modelId}.`, { url, method: \"GET\" }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n        }\n        inferenceProviderMapping = normalizeInferenceProviderMapping(modelId, payload.inferenceProviderMapping);\n        inferenceProviderMappingCache.set(modelId, inferenceProviderMapping);\n    }\n    return inferenceProviderMapping;\n}\nexport async function getInferenceProviderMapping(params, options) {\n    const logger = getLogger();\n    if (HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId]) {\n        return HARDCODED_MODEL_INFERENCE_MAPPING[params.provider][params.modelId];\n    }\n    const mappings = await fetchInferenceProviderMappingForModel(params.modelId, params.accessToken, options);\n    const providerMapping = mappings.find((mapping) => mapping.provider === params.provider);\n    if (providerMapping) {\n        const equivalentTasks = params.provider === \"hf-inference\" && typedInclude(EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS, params.task)\n            ? EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS\n            : [params.task];\n        if (!typedInclude(equivalentTasks, providerMapping.task)) {\n            throw new InferenceClientInputError(`Model ${params.modelId} is not supported for task ${params.task} and provider ${params.provider}. Supported task: ${providerMapping.task}.`);\n        }\n        if (providerMapping.status === \"staging\") {\n            logger.warn(`Model ${params.modelId} is in staging mode for provider ${params.provider}. Meant for test purposes only.`);\n        }\n        return providerMapping;\n    }\n    return null;\n}\nexport async function resolveProvider(provider, modelId, endpointUrl) {\n    const logger = getLogger();\n    if (endpointUrl) {\n        if (provider) {\n            throw new InferenceClientInputError(\"Specifying both endpointUrl and provider is not supported.\");\n        }\n        /// Defaulting to hf-inference helpers / API\n        return \"hf-inference\";\n    }\n    if (!provider) {\n        logger.log(\"Defaulting to 'auto' which will select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.\");\n        provider = \"auto\";\n    }\n    if (provider === \"auto\") {\n        if (!modelId) {\n            throw new InferenceClientInputError(\"Specifying a model is required when provider is 'auto'\");\n        }\n        const mappings = await fetchInferenceProviderMappingForModel(modelId);\n        provider = mappings[0]?.provider;\n        logger.log(\"Auto selected provider:\", provider);\n    }\n    if (!provider) {\n        throw new InferenceClientInputError(`No Inference Provider available for model ${modelId}.`);\n    }\n    return provider;\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;AACO,MAAM,gCAAgC,IAAI;AACjD;;;;;CAKC,GACD,SAAS,kCAAkC,OAAO,EAAE,wBAAwB;IACxE,IAAI,CAAC,0BAA0B;QAC3B,OAAO,EAAE;IACb;IACA,4CAA4C;IAC5C,IAAI,MAAM,OAAO,CAAC,2BAA2B;QACzC,OAAO;IACX;IACA,kCAAkC;IAClC,OAAO,OAAO,OAAO,CAAC,0BAA0B,GAAG,CAAC,CAAC,CAAC,UAAU,QAAQ,GAAK,CAAC;YAC1E;YACA,WAAW;YACX,YAAY,QAAQ,UAAU;YAC9B,QAAQ,QAAQ,MAAM;YACtB,MAAM,QAAQ,IAAI;YAClB,SAAS,QAAQ,OAAO;YACxB,oBAAoB,QAAQ,kBAAkB;QAClD,CAAC;AACL;AACO,eAAe,sCAAsC,OAAO,EAAE,WAAW,EAAE,OAAO;IACrF,IAAI;IACJ,IAAI,8BAA8B,GAAG,CAAC,UAAU;QAC5C,oEAAoE;QACpE,2BAA2B,8BAA8B,GAAG,CAAC;IACjE,OACK;QACD,MAAM,MAAM,GAAG,mLAAU,CAAC,YAAY,EAAE,QAAQ,kCAAkC,CAAC;QACnF,MAAM,OAAO,MAAM,CAAC,SAAS,SAAS,KAAK,EAAE,KAAK;YAC9C,SAAS,aAAa,WAAW,SAAS;gBAAE,eAAe,CAAC,OAAO,EAAE,aAAa;YAAC,IAAI,CAAC;QAC5F;QACA,IAAI,CAAC,KAAK,EAAE,EAAE;YACV,IAAI,KAAK,OAAO,CAAC,GAAG,CAAC,iBAAiB,WAAW,qBAAqB;gBAClE,MAAM,QAAQ,MAAM,KAAK,IAAI;gBAC7B,IAAI,WAAW,SAAS,OAAO,MAAM,KAAK,KAAK,UAAU;oBACrD,MAAM,IAAI,mMAA0B,CAAC,CAAC,qDAAqD,EAAE,QAAQ,EAAE,EAAE,MAAM,KAAK,EAAE,EAAE;wBAAE;wBAAK,QAAQ;oBAAM,GAAG;wBAAE,WAAW,KAAK,OAAO,CAAC,GAAG,CAAC,mBAAmB;wBAAI,QAAQ,KAAK,MAAM;wBAAE,MAAM;oBAAM;gBAC1O;YACJ,OACK;gBACD,MAAM,IAAI,mMAA0B,CAAC,CAAC,qDAAqD,EAAE,SAAS,EAAE;oBAAE;oBAAK,QAAQ;gBAAM,GAAG;oBAAE,WAAW,KAAK,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,KAAK,MAAM;oBAAE,MAAM,MAAM,KAAK,IAAI;gBAAG;YACtO;QACJ;QACA,IAAI,UAAU;QACd,IAAI;YACA,UAAU,MAAM,KAAK,IAAI;QAC7B,EACA,OAAM;YACF,MAAM,IAAI,mMAA0B,CAAC,CAAC,qDAAqD,EAAE,QAAQ,sCAAsC,CAAC,EAAE;gBAAE;gBAAK,QAAQ;YAAM,GAAG;gBAAE,WAAW,KAAK,OAAO,CAAC,GAAG,CAAC,mBAAmB;gBAAI,QAAQ,KAAK,MAAM;gBAAE,MAAM,MAAM,KAAK,IAAI;YAAG;QAC5Q;QACA,IAAI,CAAC,SAAS,0BAA0B;YACpC,MAAM,IAAI,mMAA0B,CAAC,CAAC,uEAAuE,EAAE,QAAQ,CAAC,CAAC,EAAE;gBAAE;gBAAK,QAAQ;YAAM,GAAG;gBAAE,WAAW,KAAK,OAAO,CAAC,GAAG,CAAC,mBAAmB;gBAAI,QAAQ,KAAK,MAAM;gBAAE,MAAM,MAAM,KAAK,IAAI;YAAG;QACzP;QACA,2BAA2B,kCAAkC,SAAS,QAAQ,wBAAwB;QACtG,8BAA8B,GAAG,CAAC,SAAS;IAC/C;IACA,OAAO;AACX;AACO,eAAe,4BAA4B,MAAM,EAAE,OAAO;IAC7D,MAAM,SAAS,IAAA,yLAAS;IACxB,IAAI,uNAAiC,CAAC,OAAO,QAAQ,CAAC,CAAC,OAAO,OAAO,CAAC,EAAE;QACpE,OAAO,uNAAiC,CAAC,OAAO,QAAQ,CAAC,CAAC,OAAO,OAAO,CAAC;IAC7E;IACA,MAAM,WAAW,MAAM,sCAAsC,OAAO,OAAO,EAAE,OAAO,WAAW,EAAE;IACjG,MAAM,kBAAkB,SAAS,IAAI,CAAC,CAAC,UAAY,QAAQ,QAAQ,KAAK,OAAO,QAAQ;IACvF,IAAI,iBAAiB;QACjB,MAAM,kBAAkB,OAAO,QAAQ,KAAK,kBAAkB,IAAA,oMAAY,EAAC,qOAAsC,EAAE,OAAO,IAAI,IACxH,qOAAsC,GACtC;YAAC,OAAO,IAAI;SAAC;QACnB,IAAI,CAAC,IAAA,oMAAY,EAAC,iBAAiB,gBAAgB,IAAI,GAAG;YACtD,MAAM,IAAI,kMAAyB,CAAC,CAAC,MAAM,EAAE,OAAO,OAAO,CAAC,2BAA2B,EAAE,OAAO,IAAI,CAAC,cAAc,EAAE,OAAO,QAAQ,CAAC,kBAAkB,EAAE,gBAAgB,IAAI,CAAC,CAAC,CAAC;QACpL;QACA,IAAI,gBAAgB,MAAM,KAAK,WAAW;YACtC,OAAO,IAAI,CAAC,CAAC,MAAM,EAAE,OAAO,OAAO,CAAC,iCAAiC,EAAE,OAAO,QAAQ,CAAC,+BAA+B,CAAC;QAC3H;QACA,OAAO;IACX;IACA,OAAO;AACX;AACO,eAAe,gBAAgB,QAAQ,EAAE,OAAO,EAAE,WAAW;IAChE,MAAM,SAAS,IAAA,yLAAS;IACxB,IAAI,aAAa;QACb,IAAI,UAAU;YACV,MAAM,IAAI,kMAAyB,CAAC;QACxC;QACA,4CAA4C;QAC5C,OAAO;IACX;IACA,IAAI,CAAC,UAAU;QACX,OAAO,GAAG,CAAC;QACX,WAAW;IACf;IACA,IAAI,aAAa,QAAQ;QACrB,IAAI,CAAC,SAAS;YACV,MAAM,IAAI,kMAAyB,CAAC;QACxC;QACA,MAAM,WAAW,MAAM,sCAAsC;QAC7D,WAAW,QAAQ,CAAC,EAAE,EAAE;QACxB,OAAO,GAAG,CAAC,2BAA2B;IAC1C;IACA,IAAI,CAAC,UAAU;QACX,MAAM,IAAI,kMAAyB,CAAC,CAAC,0CAA0C,EAAE,QAAQ,CAAC,CAAC;IAC/F;IACA,OAAO;AACX","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 925, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/baseten.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Baseten model ID here:\n *\n * https://huggingface.co/api/partners/baseten/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Baseten and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Baseten, please open an issue on the present repo\n * and we will tag Baseten team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst BASETEN_API_BASE_URL = \"https://inference.baseten.co\";\nexport class BasetenConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"baseten\", BASETEN_API_BASE_URL);\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;;AACA,MAAM,uBAAuB;AACtB,MAAM,kCAAkC,oNAAsB;IACjE,aAAc;QACV,KAAK,CAAC,WAAW;IACrB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 956, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/delay.js"],"sourcesContent":["export function delay(ms) {\n    return new Promise((resolve) => {\n        setTimeout(() => resolve(), ms);\n    });\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,MAAM,EAAE;IACpB,OAAO,IAAI,QAAQ,CAAC;QAChB,WAAW,IAAM,WAAW;IAChC;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 969, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/black-forest-labs.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Black Forest Labs model ID here:\n *\n * https://huggingface.co/api/partners/blackforestlabs/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Black Forest Labs and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Black Forest Labs, please open an issue on the present repo\n * and we will tag Black Forest Labs team members.\n *\n * Thanks!\n */\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nimport { getLogger } from \"../lib/logger.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper } from \"./providerHelper.js\";\nconst BLACK_FOREST_LABS_AI_API_BASE_URL = \"https://api.us1.bfl.ai\";\nexport class BlackForestLabsTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"black-forest-labs\", BLACK_FOREST_LABS_AI_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n        };\n    }\n    prepareHeaders(params, binary) {\n        const headers = {\n            Authorization: params.authMethod !== \"provider-key\" ? `Bearer ${params.accessToken}` : `X-Key ${params.accessToken}`,\n        };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n    makeRoute(params) {\n        if (!params) {\n            throw new InferenceClientInputError(\"Params are required\");\n        }\n        return `/v1/${params.model}`;\n    }\n    async getResponse(response, url, headers, outputType) {\n        const logger = getLogger();\n        const urlObj = new URL(response.polling_url);\n        for (let step = 0; step < 5; step++) {\n            await delay(1000);\n            logger.debug(`Polling Black Forest Labs API for the result... ${step + 1}/5`);\n            urlObj.searchParams.set(\"attempt\", step.toString(10));\n            const resp = await fetch(urlObj, { headers: { \"Content-Type\": \"application/json\" } });\n            if (!resp.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch result from black forest labs API\", { url: urlObj.toString(), method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, { requestId: resp.headers.get(\"x-request-id\") ?? \"\", status: resp.status, body: await resp.text() });\n            }\n            const payload = await resp.json();\n            if (typeof payload === \"object\" &&\n                payload &&\n                \"status\" in payload &&\n                typeof payload.status === \"string\" &&\n                payload.status === \"Ready\" &&\n                \"result\" in payload &&\n                typeof payload.result === \"object\" &&\n                payload.result &&\n                \"sample\" in payload.result &&\n                typeof payload.result.sample === \"string\") {\n                if (outputType === \"json\") {\n                    return payload.result;\n                }\n                if (outputType === \"url\") {\n                    return payload.result.sample;\n                }\n                const image = await fetch(payload.result.sample);\n                return await image.blob();\n            }\n        }\n        throw new InferenceClientProviderOutputError(`Timed out while waiting for the result from black forest labs API - aborting after 5 attempts`);\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;AACA;AACA;AACA;AACA;;;;;;AACA,MAAM,oCAAoC;AACnC,MAAM,uCAAuC,gNAAkB;IAClE,aAAc;QACV,KAAK,CAAC,qBAAqB;IAC/B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,eAAe,MAAM,EAAE,MAAM,EAAE;QAC3B,MAAM,UAAU;YACZ,eAAe,OAAO,UAAU,KAAK,iBAAiB,CAAC,OAAO,EAAE,OAAO,WAAW,EAAE,GAAG,CAAC,MAAM,EAAE,OAAO,WAAW,EAAE;QACxH;QACA,IAAI,CAAC,QAAQ;YACT,OAAO,CAAC,eAAe,GAAG;QAC9B;QACA,OAAO;IACX;IACA,UAAU,MAAM,EAAE;QACd,IAAI,CAAC,QAAQ;YACT,MAAM,IAAI,kMAAyB,CAAC;QACxC;QACA,OAAO,CAAC,IAAI,EAAE,OAAO,KAAK,EAAE;IAChC;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,MAAM,SAAS,IAAA,yLAAS;QACxB,MAAM,SAAS,IAAI,IAAI,SAAS,WAAW;QAC3C,IAAK,IAAI,OAAO,GAAG,OAAO,GAAG,OAAQ;YACjC,MAAM,IAAA,sLAAK,EAAC;YACZ,OAAO,KAAK,CAAC,CAAC,gDAAgD,EAAE,OAAO,EAAE,EAAE,CAAC;YAC5E,OAAO,YAAY,CAAC,GAAG,CAAC,WAAW,KAAK,QAAQ,CAAC;YACjD,MAAM,OAAO,MAAM,MAAM,QAAQ;gBAAE,SAAS;oBAAE,gBAAgB;gBAAmB;YAAE;YACnF,IAAI,CAAC,KAAK,EAAE,EAAE;gBACV,MAAM,IAAI,wMAA+B,CAAC,qDAAqD;oBAAE,KAAK,OAAO,QAAQ;oBAAI,QAAQ;oBAAO,SAAS;wBAAE,gBAAgB;oBAAmB;gBAAE,GAAG;oBAAE,WAAW,KAAK,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,KAAK,MAAM;oBAAE,MAAM,MAAM,KAAK,IAAI;gBAAG;YACjS;YACA,MAAM,UAAU,MAAM,KAAK,IAAI;YAC/B,IAAI,OAAO,YAAY,YACnB,WACA,YAAY,WACZ,OAAO,QAAQ,MAAM,KAAK,YAC1B,QAAQ,MAAM,KAAK,WACnB,YAAY,WACZ,OAAO,QAAQ,MAAM,KAAK,YAC1B,QAAQ,MAAM,IACd,YAAY,QAAQ,MAAM,IAC1B,OAAO,QAAQ,MAAM,CAAC,MAAM,KAAK,UAAU;gBAC3C,IAAI,eAAe,QAAQ;oBACvB,OAAO,QAAQ,MAAM;gBACzB;gBACA,IAAI,eAAe,OAAO;oBACtB,OAAO,QAAQ,MAAM,CAAC,MAAM;gBAChC;gBACA,MAAM,QAAQ,MAAM,MAAM,QAAQ,MAAM,CAAC,MAAM;gBAC/C,OAAO,MAAM,MAAM,IAAI;YAC3B;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC,CAAC,6FAA6F,CAAC;IAChJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1072, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/cerebras.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Cerebras model ID here:\n *\n * https://huggingface.co/api/partners/cerebras/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Cerebras and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Cerebras, please open an issue on the present repo\n * and we will tag Cerebras team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class CerebrasConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"cerebras\", \"https://api.cerebras.ai\");\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;;AACO,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1102, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/cohere.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Cohere model ID here:\n *\n * https://huggingface.co/api/partners/cohere/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Cohere and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Cohere, please open an issue on the present repo\n * and we will tag Cohere team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class CohereConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"cohere\", \"https://api.cohere.com\");\n    }\n    makeRoute() {\n        return \"/compatibility/v1/chat/completions\";\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;;AACO,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,YAAY;QACR,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1135, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/lib/isUrl.js"],"sourcesContent":["export function isUrl(modelOrUrl) {\n    return /^http(s?):/.test(modelOrUrl) || modelOrUrl.startsWith(\"/\");\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,MAAM,UAAU;IAC5B,OAAO,aAAa,IAAI,CAAC,eAAe,WAAW,UAAU,CAAC;AAClE","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1146, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/fal-ai.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Fal model ID here:\n *\n * https://huggingface.co/api/partners/fal-ai/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Fal and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Fal, please open an issue on the present repo\n * and we will tag Fal team members.\n *\n * Thanks!\n */\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper, } from \"./providerHelper.js\";\nimport { HF_HUB_URL } from \"../config.js\";\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nexport const FAL_AI_SUPPORTED_BLOB_TYPES = [\"audio/mpeg\", \"audio/mp4\", \"audio/wav\", \"audio/x-wav\"];\nclass FalAITask extends TaskProviderHelper {\n    constructor(url) {\n        super(\"fal-ai\", url || \"https://fal.run\");\n    }\n    preparePayload(params) {\n        return params.args;\n    }\n    makeRoute(params) {\n        return `/${params.model}`;\n    }\n    prepareHeaders(params, binary) {\n        const headers = {\n            Authorization: params.authMethod !== \"provider-key\" ? `Bearer ${params.accessToken}` : `Key ${params.accessToken}`,\n        };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n}\nclass FalAiQueueTask extends FalAITask {\n    async getResponseFromQueueApi(response, url, headers) {\n        if (!url || !headers) {\n            throw new InferenceClientInputError(`URL and headers are required for ${this.task} task`);\n        }\n        const requestId = response.request_id;\n        if (!requestId) {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai ${this.task} API: no request ID found in the response`);\n        }\n        let status = response.status;\n        const parsedUrl = new URL(url);\n        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === \"router.huggingface.co\" ? \"/fal-ai\" : \"\"}`;\n        // extracting the provider model id for status and result urls\n        // from the response as it might be different from the mapped model in `url`\n        const modelId = new URL(response.response_url).pathname;\n        const queryParams = parsedUrl.search;\n        const statusUrl = `${baseUrl}${modelId}/status${queryParams}`;\n        const resultUrl = `${baseUrl}${modelId}${queryParams}`;\n        while (status !== \"COMPLETED\") {\n            await delay(500);\n            const statusResponse = await fetch(statusUrl, { headers });\n            if (!statusResponse.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch response status from fal-ai API\", { url: statusUrl, method: \"GET\" }, {\n                    requestId: statusResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: statusResponse.status,\n                    body: await statusResponse.text(),\n                });\n            }\n            try {\n                status = (await statusResponse.json()).status;\n            }\n            catch (error) {\n                throw new InferenceClientProviderOutputError(\"Failed to parse status response from fal-ai API: received malformed response\");\n            }\n        }\n        const resultResponse = await fetch(resultUrl, { headers });\n        let result;\n        try {\n            result = await resultResponse.json();\n        }\n        catch (error) {\n            throw new InferenceClientProviderOutputError(\"Failed to parse result response from fal-ai API: received malformed response\");\n        }\n        return result;\n    }\n}\nfunction buildLoraPath(modelId, adapterWeightsPath) {\n    return `${HF_HUB_URL}/${modelId}/resolve/main/${adapterWeightsPath}`;\n}\nexport class FalAITextToImageTask extends FalAITask {\n    preparePayload(params) {\n        const payload = {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            sync_mode: true,\n            prompt: params.args.inputs,\n        };\n        if (params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath) {\n            payload.loras = [\n                {\n                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),\n                    scale: 1,\n                },\n            ];\n            if (params.mapping.providerId === \"fal-ai/lora\") {\n                payload.model_name = \"stabilityai/stable-diffusion-xl-base-1.0\";\n            }\n        }\n        return payload;\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"images\" in response &&\n            Array.isArray(response.images) &&\n            response.images.length > 0 &&\n            \"url\" in response.images[0] &&\n            typeof response.images[0].url === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (outputType === \"url\") {\n                return response.images[0].url;\n            }\n            const urlResponse = await fetch(response.images[0].url);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Fal.ai text-to-image API\");\n    }\n}\nexport class FalAIImageToImageTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-to-image\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        const payload = params.args;\n        if (params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath) {\n            payload.loras = [\n                {\n                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),\n                    scale: 1,\n                },\n            ];\n        }\n        return payload;\n    }\n    async preparePayloadAsync(args) {\n        const mimeType = args.inputs instanceof Blob ? args.inputs.type : \"image/png\";\n        return {\n            ...omit(args, [\"inputs\", \"parameters\"]),\n            image_url: `data:${mimeType};base64,${base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`,\n            ...args.parameters,\n            ...args,\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            !!result &&\n            \"images\" in result &&\n            Array.isArray(result.images) &&\n            result.images.length > 0 &&\n            typeof result.images[0] === \"object\" &&\n            !!result.images[0] &&\n            \"url\" in result.images[0] &&\n            typeof result.images[0].url === \"string\" &&\n            isUrl(result.images[0].url)) {\n            const urlResponse = await fetch(result.images[0].url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai image-to-image API: expected { images: Array<{ url: string }> } result format, got instead: ${JSON.stringify(result)}`);\n        }\n    }\n}\nexport class FalAITextToVideoTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"text-to-video\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            !!result &&\n            \"video\" in result &&\n            typeof result.video === \"object\" &&\n            !!result.video &&\n            \"url\" in result.video &&\n            typeof result.video.url === \"string\" &&\n            isUrl(result.video.url)) {\n            const urlResponse = await fetch(result.video.url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai text-to-video API: expected { video: { url: string } } result format, got instead: ${JSON.stringify(result)}`);\n        }\n    }\n}\nexport class FalAIImageToVideoTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-to-video\";\n    }\n    /** Same queue routing rule as the other Fal queue tasks */\n    makeRoute(params) {\n        return params.authMethod !== \"provider-key\" ? `/${params.model}?_subdomain=queue` : `/${params.model}`;\n    }\n    /** Synchronous case – caller already gave us base64 or a URL */\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            // args.inputs is expected to be a base64 data URI or an URL\n            image_url: params.args.image_url,\n        };\n    }\n    /** Asynchronous helper – caller gave us a Blob */\n    async preparePayloadAsync(args) {\n        const mimeType = args.inputs instanceof Blob ? args.inputs.type : \"image/png\";\n        return {\n            ...omit(args, [\"inputs\", \"parameters\"]),\n            image_url: `data:${mimeType};base64,${base64FromBytes(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`,\n            ...args.parameters,\n            ...args,\n        };\n    }\n    /** Queue polling + final download – mirrors Text‑to‑Video */\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            result !== null &&\n            \"video\" in result &&\n            typeof result.video === \"object\" &&\n            result.video !== null &&\n            \"url\" in result.video &&\n            typeof result.video.url === \"string\" &&\n            \"url\" in result.video &&\n            isUrl(result.video.url)) {\n            const urlResponse = await fetch(result.video.url);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai image‑to‑video API: expected { video: { url: string } }, got: ${JSON.stringify(result)}`);\n    }\n}\nexport class FalAIAutomaticSpeechRecognitionTask extends FalAITask {\n    prepareHeaders(params, binary) {\n        const headers = super.prepareHeaders(params, binary);\n        headers[\"Content-Type\"] = \"application/json\";\n        return headers;\n    }\n    async getResponse(response) {\n        const res = response;\n        if (typeof res?.text !== \"string\") {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai Automatic Speech Recognition API: expected { text: string } format, got instead: ${JSON.stringify(response)}`);\n        }\n        return { text: res.text };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        const contentType = blob?.type;\n        if (!contentType) {\n            throw new InferenceClientInputError(`Unable to determine the input's content-type. Make sure your are passing a Blob when using provider fal-ai.`);\n        }\n        if (!FAL_AI_SUPPORTED_BLOB_TYPES.includes(contentType)) {\n            throw new InferenceClientInputError(`Provider fal-ai does not support blob type ${contentType} - supported content types are: ${FAL_AI_SUPPORTED_BLOB_TYPES.join(\", \")}`);\n        }\n        const base64audio = base64FromBytes(new Uint8Array(await blob.arrayBuffer()));\n        return {\n            ...(\"data\" in args ? omit(args, \"data\") : omit(args, \"inputs\")),\n            audio_url: `data:${contentType};base64,${base64audio}`,\n        };\n    }\n}\nexport class FalAITextToSpeechTask extends FalAITask {\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            text: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        const res = response;\n        if (typeof res?.audio?.url !== \"string\") {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai Text-to-Speech API: expected { audio: { url: string } } format, got instead: ${JSON.stringify(response)}`);\n        }\n        const urlResponse = await fetch(res.audio.url);\n        if (!urlResponse.ok) {\n            throw new InferenceClientProviderApiError(`Failed to fetch audio from ${res.audio.url}: ${urlResponse.statusText}`, { url: res.audio.url, method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, {\n                requestId: urlResponse.headers.get(\"x-request-id\") ?? \"\",\n                status: urlResponse.status,\n                body: await urlResponse.text(),\n            });\n        }\n        try {\n            return await urlResponse.blob();\n        }\n        catch (error) {\n            throw new InferenceClientProviderApiError(`Failed to fetch audio from ${res.audio.url}: ${error instanceof Error ? error.message : String(error)}`, { url: res.audio.url, method: \"GET\", headers: { \"Content-Type\": \"application/json\" } }, {\n                requestId: urlResponse.headers.get(\"x-request-id\") ?? \"\",\n                status: urlResponse.status,\n                body: await urlResponse.text(),\n            });\n        }\n    }\n}\nexport class FalAIImageSegmentationTask extends FalAiQueueTask {\n    task;\n    constructor() {\n        super(\"https://queue.fal.run\");\n        this.task = \"image-segmentation\";\n    }\n    makeRoute(params) {\n        if (params.authMethod !== \"provider-key\") {\n            return `/${params.model}?_subdomain=queue`;\n        }\n        return `/${params.model}`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            sync_mode: true,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        const mimeType = blob instanceof Blob ? blob.type : \"image/png\";\n        const base64Image = base64FromBytes(new Uint8Array(blob instanceof ArrayBuffer ? blob : await blob.arrayBuffer()));\n        return {\n            ...omit(args, [\"inputs\", \"parameters\", \"data\"]),\n            ...args.parameters,\n            ...args,\n            image_url: `data:${mimeType};base64,${base64Image}`,\n            sync_mode: true,\n        };\n    }\n    async getResponse(response, url, headers) {\n        const result = await this.getResponseFromQueueApi(response, url, headers);\n        if (typeof result === \"object\" &&\n            result !== null &&\n            \"image\" in result &&\n            typeof result.image === \"object\" &&\n            result.image !== null &&\n            \"url\" in result.image &&\n            typeof result.image.url === \"string\") {\n            const maskResponse = await fetch(result.image.url);\n            if (!maskResponse.ok) {\n                throw new InferenceClientProviderApiError(`Failed to fetch segmentation mask from ${result.image.url}`, { url: result.image.url, method: \"GET\" }, {\n                    requestId: maskResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: maskResponse.status,\n                    body: await maskResponse.text(),\n                });\n            }\n            const maskBlob = await maskResponse.blob();\n            const maskArrayBuffer = await maskBlob.arrayBuffer();\n            const maskBase64 = base64FromBytes(new Uint8Array(maskArrayBuffer));\n            return [\n                {\n                    label: \"mask\", // placeholder label, as Fal does not provide labels in the response(?)\n                    score: 1.0, // placeholder score, as Fal does not provide scores in the response(?)\n                    mask: maskBase64,\n                },\n            ];\n        }\n        throw new InferenceClientProviderOutputError(`Received malformed response from Fal.ai image-segmentation API: expected { image: { url: string } } format, got instead: ${JSON.stringify(response)}`);\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;;;;;;;;;;;;;;;AACD;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AACO,MAAM,8BAA8B;IAAC;IAAc;IAAa;IAAa;CAAc;AAClG,MAAM,kBAAkB,gNAAkB;IACtC,YAAY,GAAG,CAAE;QACb,KAAK,CAAC,UAAU,OAAO;IAC3B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO,OAAO,IAAI;IACtB;IACA,UAAU,MAAM,EAAE;QACd,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,EAAE;IAC7B;IACA,eAAe,MAAM,EAAE,MAAM,EAAE;QAC3B,MAAM,UAAU;YACZ,eAAe,OAAO,UAAU,KAAK,iBAAiB,CAAC,OAAO,EAAE,OAAO,WAAW,EAAE,GAAG,CAAC,IAAI,EAAE,OAAO,WAAW,EAAE;QACtH;QACA,IAAI,CAAC,QAAQ;YACT,OAAO,CAAC,eAAe,GAAG;QAC9B;QACA,OAAO;IACX;AACJ;AACA,MAAM,uBAAuB;IACzB,MAAM,wBAAwB,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QAClD,IAAI,CAAC,OAAO,CAAC,SAAS;YAClB,MAAM,IAAI,kMAAyB,CAAC,CAAC,iCAAiC,EAAE,IAAI,CAAC,IAAI,CAAC,KAAK,CAAC;QAC5F;QACA,MAAM,YAAY,SAAS,UAAU;QACrC,IAAI,CAAC,WAAW;YACZ,MAAM,IAAI,2MAAkC,CAAC,CAAC,wCAAwC,EAAE,IAAI,CAAC,IAAI,CAAC,yCAAyC,CAAC;QAChJ;QACA,IAAI,SAAS,SAAS,MAAM;QAC5B,MAAM,YAAY,IAAI,IAAI;QAC1B,MAAM,UAAU,GAAG,UAAU,QAAQ,CAAC,EAAE,EAAE,UAAU,IAAI,GAAG,UAAU,IAAI,KAAK,0BAA0B,YAAY,IAAI;QACxH,8DAA8D;QAC9D,4EAA4E;QAC5E,MAAM,UAAU,IAAI,IAAI,SAAS,YAAY,EAAE,QAAQ;QACvD,MAAM,cAAc,UAAU,MAAM;QACpC,MAAM,YAAY,GAAG,UAAU,QAAQ,OAAO,EAAE,aAAa;QAC7D,MAAM,YAAY,GAAG,UAAU,UAAU,aAAa;QACtD,MAAO,WAAW,YAAa;YAC3B,MAAM,IAAA,sLAAK,EAAC;YACZ,MAAM,iBAAiB,MAAM,MAAM,WAAW;gBAAE;YAAQ;YACxD,IAAI,CAAC,eAAe,EAAE,EAAE;gBACpB,MAAM,IAAI,wMAA+B,CAAC,mDAAmD;oBAAE,KAAK;oBAAW,QAAQ;gBAAM,GAAG;oBAC5H,WAAW,eAAe,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBACzD,QAAQ,eAAe,MAAM;oBAC7B,MAAM,MAAM,eAAe,IAAI;gBACnC;YACJ;YACA,IAAI;gBACA,SAAS,CAAC,MAAM,eAAe,IAAI,EAAE,EAAE,MAAM;YACjD,EACA,OAAO,OAAO;gBACV,MAAM,IAAI,2MAAkC,CAAC;YACjD;QACJ;QACA,MAAM,iBAAiB,MAAM,MAAM,WAAW;YAAE;QAAQ;QACxD,IAAI;QACJ,IAAI;YACA,SAAS,MAAM,eAAe,IAAI;QACtC,EACA,OAAO,OAAO;YACV,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,OAAO;IACX;AACJ;AACA,SAAS,cAAc,OAAO,EAAE,kBAAkB;IAC9C,OAAO,GAAG,mLAAU,CAAC,CAAC,EAAE,QAAQ,cAAc,EAAE,oBAAoB;AACxE;AACO,MAAM,6BAA6B;IACtC,eAAe,MAAM,EAAE;QACnB,MAAM,UAAU;YACZ,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,WAAW;YACX,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;QACA,IAAI,OAAO,OAAO,EAAE,YAAY,UAAU,OAAO,OAAO,CAAC,kBAAkB,EAAE;YACzE,QAAQ,KAAK,GAAG;gBACZ;oBACI,MAAM,cAAc,OAAO,OAAO,CAAC,SAAS,EAAE,OAAO,OAAO,CAAC,kBAAkB;oBAC/E,OAAO;gBACX;aACH;YACD,IAAI,OAAO,OAAO,CAAC,UAAU,KAAK,eAAe;gBAC7C,QAAQ,UAAU,GAAG;YACzB;QACJ;QACA,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,OAAO,aAAa,YACpB,YAAY,YACZ,MAAM,OAAO,CAAC,SAAS,MAAM,KAC7B,SAAS,MAAM,CAAC,MAAM,GAAG,KACzB,SAAS,SAAS,MAAM,CAAC,EAAE,IAC3B,OAAO,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG,KAAK,UAAU;YAC5C,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,IAAI,eAAe,OAAO;gBACtB,OAAO,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG;YACjC;YACA,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM,CAAC,EAAE,CAAC,GAAG;YACtD,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,8BAA8B;IACvC,KAAK;IACL,aAAc;QACV,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;IACA,UAAU,MAAM,EAAE;QACd,IAAI,OAAO,UAAU,KAAK,gBAAgB;YACtC,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,CAAC,iBAAiB,CAAC;QAC9C;QACA,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,EAAE;IAC7B;IACA,eAAe,MAAM,EAAE;QACnB,MAAM,UAAU,OAAO,IAAI;QAC3B,IAAI,OAAO,OAAO,EAAE,YAAY,UAAU,OAAO,OAAO,CAAC,kBAAkB,EAAE;YACzE,QAAQ,KAAK,GAAG;gBACZ;oBACI,MAAM,cAAc,OAAO,OAAO,CAAC,SAAS,EAAE,OAAO,OAAO,CAAC,kBAAkB;oBAC/E,OAAO;gBACX;aACH;QACL;QACA,OAAO;IACX;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,WAAW,KAAK,MAAM,YAAY,OAAO,KAAK,MAAM,CAAC,IAAI,GAAG;QAClE,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,MAAM;gBAAC;gBAAU;aAAa,CAAC;YACvC,WAAW,CAAC,KAAK,EAAE,SAAS,QAAQ,EAAE,IAAA,0MAAe,EAAC,IAAI,WAAW,KAAK,MAAM,YAAY,cAAc,KAAK,MAAM,GAAG,MAAM,KAAK,MAAM,CAAC,WAAW,MAAM;YAC3J,GAAG,KAAK,UAAU;YAClB,GAAG,IAAI;QACX;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QACtC,MAAM,SAAS,MAAM,IAAI,CAAC,uBAAuB,CAAC,UAAU,KAAK;QACjE,IAAI,OAAO,WAAW,YAClB,CAAC,CAAC,UACF,YAAY,UACZ,MAAM,OAAO,CAAC,OAAO,MAAM,KAC3B,OAAO,MAAM,CAAC,MAAM,GAAG,KACvB,OAAO,OAAO,MAAM,CAAC,EAAE,KAAK,YAC5B,CAAC,CAAC,OAAO,MAAM,CAAC,EAAE,IAClB,SAAS,OAAO,MAAM,CAAC,EAAE,IACzB,OAAO,OAAO,MAAM,CAAC,EAAE,CAAC,GAAG,KAAK,YAChC,IAAA,oLAAK,EAAC,OAAO,MAAM,CAAC,EAAE,CAAC,GAAG,GAAG;YAC7B,MAAM,cAAc,MAAM,MAAM,OAAO,MAAM,CAAC,EAAE,CAAC,GAAG;YACpD,OAAO,MAAM,YAAY,IAAI;QACjC,OACK;YACD,MAAM,IAAI,2MAAkC,CAAC,CAAC,oIAAoI,EAAE,KAAK,SAAS,CAAC,SAAS;QAChN;IACJ;AACJ;AACO,MAAM,6BAA6B;IACtC,KAAK;IACL,aAAc;QACV,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;IACA,UAAU,MAAM,EAAE;QACd,IAAI,OAAO,UAAU,KAAK,gBAAgB;YACtC,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,CAAC,iBAAiB,CAAC;QAC9C;QACA,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,EAAE;IAC7B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QACtC,MAAM,SAAS,MAAM,IAAI,CAAC,uBAAuB,CAAC,UAAU,KAAK;QACjE,IAAI,OAAO,WAAW,YAClB,CAAC,CAAC,UACF,WAAW,UACX,OAAO,OAAO,KAAK,KAAK,YACxB,CAAC,CAAC,OAAO,KAAK,IACd,SAAS,OAAO,KAAK,IACrB,OAAO,OAAO,KAAK,CAAC,GAAG,KAAK,YAC5B,IAAA,oLAAK,EAAC,OAAO,KAAK,CAAC,GAAG,GAAG;YACzB,MAAM,cAAc,MAAM,MAAM,OAAO,KAAK,CAAC,GAAG;YAChD,OAAO,MAAM,YAAY,IAAI;QACjC,OACK;YACD,MAAM,IAAI,2MAAkC,CAAC,CAAC,2HAA2H,EAAE,KAAK,SAAS,CAAC,SAAS;QACvM;IACJ;AACJ;AACO,MAAM,8BAA8B;IACvC,KAAK;IACL,aAAc;QACV,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;IACA,yDAAyD,GACzD,UAAU,MAAM,EAAE;QACd,OAAO,OAAO,UAAU,KAAK,iBAAiB,CAAC,CAAC,EAAE,OAAO,KAAK,CAAC,iBAAiB,CAAC,GAAG,CAAC,CAAC,EAAE,OAAO,KAAK,EAAE;IAC1G;IACA,8DAA8D,GAC9D,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,4DAA4D;YAC5D,WAAW,OAAO,IAAI,CAAC,SAAS;QACpC;IACJ;IACA,gDAAgD,GAChD,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,WAAW,KAAK,MAAM,YAAY,OAAO,KAAK,MAAM,CAAC,IAAI,GAAG;QAClE,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,MAAM;gBAAC;gBAAU;aAAa,CAAC;YACvC,WAAW,CAAC,KAAK,EAAE,SAAS,QAAQ,EAAE,IAAA,0MAAe,EAAC,IAAI,WAAW,KAAK,MAAM,YAAY,cAAc,KAAK,MAAM,GAAG,MAAM,KAAK,MAAM,CAAC,WAAW,MAAM;YAC3J,GAAG,KAAK,UAAU;YAClB,GAAG,IAAI;QACX;IACJ;IACA,2DAA2D,GAC3D,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QACtC,MAAM,SAAS,MAAM,IAAI,CAAC,uBAAuB,CAAC,UAAU,KAAK;QACjE,IAAI,OAAO,WAAW,YAClB,WAAW,QACX,WAAW,UACX,OAAO,OAAO,KAAK,KAAK,YACxB,OAAO,KAAK,KAAK,QACjB,SAAS,OAAO,KAAK,IACrB,OAAO,OAAO,KAAK,CAAC,GAAG,KAAK,YAC5B,SAAS,OAAO,KAAK,IACrB,IAAA,oLAAK,EAAC,OAAO,KAAK,CAAC,GAAG,GAAG;YACzB,MAAM,cAAc,MAAM,MAAM,OAAO,KAAK,CAAC,GAAG;YAChD,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,MAAM,IAAI,2MAAkC,CAAC,CAAC,sGAAsG,EAAE,KAAK,SAAS,CAAC,SAAS;IAClL;AACJ;AACO,MAAM,4CAA4C;IACrD,eAAe,MAAM,EAAE,MAAM,EAAE;QAC3B,MAAM,UAAU,KAAK,CAAC,eAAe,QAAQ;QAC7C,OAAO,CAAC,eAAe,GAAG;QAC1B,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,MAAM;QACZ,IAAI,OAAO,KAAK,SAAS,UAAU;YAC/B,MAAM,IAAI,2MAAkC,CAAC,CAAC,yHAAyH,EAAE,KAAK,SAAS,CAAC,WAAW;QACvM;QACA,OAAO;YAAE,MAAM,IAAI,IAAI;QAAC;IAC5B;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,OAAO,UAAU,QAAQ,KAAK,IAAI,YAAY,OAAO,KAAK,IAAI,GAAG,YAAY,OAAO,KAAK,MAAM,GAAG;QACxG,MAAM,cAAc,MAAM;QAC1B,IAAI,CAAC,aAAa;YACd,MAAM,IAAI,kMAAyB,CAAC,CAAC,2GAA2G,CAAC;QACrJ;QACA,IAAI,CAAC,4BAA4B,QAAQ,CAAC,cAAc;YACpD,MAAM,IAAI,kMAAyB,CAAC,CAAC,2CAA2C,EAAE,YAAY,gCAAgC,EAAE,4BAA4B,IAAI,CAAC,OAAO;QAC5K;QACA,MAAM,cAAc,IAAA,0MAAe,EAAC,IAAI,WAAW,MAAM,KAAK,WAAW;QACzE,OAAO;YACH,GAAI,UAAU,OAAO,IAAA,oLAAI,EAAC,MAAM,UAAU,IAAA,oLAAI,EAAC,MAAM,SAAS;YAC9D,WAAW,CAAC,KAAK,EAAE,YAAY,QAAQ,EAAE,aAAa;QAC1D;IACJ;AACJ;AACO,MAAM,8BAA8B;IACvC,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,MAAM,OAAO,IAAI,CAAC,MAAM;QAC5B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,MAAM,MAAM;QACZ,IAAI,OAAO,KAAK,OAAO,QAAQ,UAAU;YACrC,MAAM,IAAI,2MAAkC,CAAC,CAAC,qHAAqH,EAAE,KAAK,SAAS,CAAC,WAAW;QACnM;QACA,MAAM,cAAc,MAAM,MAAM,IAAI,KAAK,CAAC,GAAG;QAC7C,IAAI,CAAC,YAAY,EAAE,EAAE;YACjB,MAAM,IAAI,wMAA+B,CAAC,CAAC,2BAA2B,EAAE,IAAI,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,YAAY,UAAU,EAAE,EAAE;gBAAE,KAAK,IAAI,KAAK,CAAC,GAAG;gBAAE,QAAQ;gBAAO,SAAS;oBAAE,gBAAgB;gBAAmB;YAAE,GAAG;gBACxM,WAAW,YAAY,OAAO,CAAC,GAAG,CAAC,mBAAmB;gBACtD,QAAQ,YAAY,MAAM;gBAC1B,MAAM,MAAM,YAAY,IAAI;YAChC;QACJ;QACA,IAAI;YACA,OAAO,MAAM,YAAY,IAAI;QACjC,EACA,OAAO,OAAO;YACV,MAAM,IAAI,wMAA+B,CAAC,CAAC,2BAA2B,EAAE,IAAI,KAAK,CAAC,GAAG,CAAC,EAAE,EAAE,iBAAiB,QAAQ,MAAM,OAAO,GAAG,OAAO,QAAQ,EAAE;gBAAE,KAAK,IAAI,KAAK,CAAC,GAAG;gBAAE,QAAQ;gBAAO,SAAS;oBAAE,gBAAgB;gBAAmB;YAAE,GAAG;gBACxO,WAAW,YAAY,OAAO,CAAC,GAAG,CAAC,mBAAmB;gBACtD,QAAQ,YAAY,MAAM;gBAC1B,MAAM,MAAM,YAAY,IAAI;YAChC;QACJ;IACJ;AACJ;AACO,MAAM,mCAAmC;IAC5C,KAAK;IACL,aAAc;QACV,KAAK,CAAC;QACN,IAAI,CAAC,IAAI,GAAG;IAChB;IACA,UAAU,MAAM,EAAE;QACd,IAAI,OAAO,UAAU,KAAK,gBAAgB;YACtC,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,CAAC,iBAAiB,CAAC;QAC9C;QACA,OAAO,CAAC,CAAC,EAAE,OAAO,KAAK,EAAE;IAC7B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,WAAW;QACf;IACJ;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,OAAO,UAAU,QAAQ,KAAK,IAAI,YAAY,OAAO,KAAK,IAAI,GAAG,YAAY,OAAO,KAAK,MAAM,GAAG;QACxG,MAAM,WAAW,gBAAgB,OAAO,KAAK,IAAI,GAAG;QACpD,MAAM,cAAc,IAAA,0MAAe,EAAC,IAAI,WAAW,gBAAgB,cAAc,OAAO,MAAM,KAAK,WAAW;QAC9G,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,MAAM;gBAAC;gBAAU;gBAAc;aAAO,CAAC;YAC/C,GAAG,KAAK,UAAU;YAClB,GAAG,IAAI;YACP,WAAW,CAAC,KAAK,EAAE,SAAS,QAAQ,EAAE,aAAa;YACnD,WAAW;QACf;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QACtC,MAAM,SAAS,MAAM,IAAI,CAAC,uBAAuB,CAAC,UAAU,KAAK;QACjE,IAAI,OAAO,WAAW,YAClB,WAAW,QACX,WAAW,UACX,OAAO,OAAO,KAAK,KAAK,YACxB,OAAO,KAAK,KAAK,QACjB,SAAS,OAAO,KAAK,IACrB,OAAO,OAAO,KAAK,CAAC,GAAG,KAAK,UAAU;YACtC,MAAM,eAAe,MAAM,MAAM,OAAO,KAAK,CAAC,GAAG;YACjD,IAAI,CAAC,aAAa,EAAE,EAAE;gBAClB,MAAM,IAAI,wMAA+B,CAAC,CAAC,uCAAuC,EAAE,OAAO,KAAK,CAAC,GAAG,EAAE,EAAE;oBAAE,KAAK,OAAO,KAAK,CAAC,GAAG;oBAAE,QAAQ;gBAAM,GAAG;oBAC9I,WAAW,aAAa,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBACvD,QAAQ,aAAa,MAAM;oBAC3B,MAAM,MAAM,aAAa,IAAI;gBACjC;YACJ;YACA,MAAM,WAAW,MAAM,aAAa,IAAI;YACxC,MAAM,kBAAkB,MAAM,SAAS,WAAW;YAClD,MAAM,aAAa,IAAA,0MAAe,EAAC,IAAI,WAAW;YAClD,OAAO;gBACH;oBACI,OAAO;oBACP,OAAO;oBACP,MAAM;gBACV;aACH;QACL;QACA,MAAM,IAAI,2MAAkC,CAAC,CAAC,yHAAyH,EAAE,KAAK,SAAS,CAAC,WAAW;IACvM;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1580, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/featherless-ai.js"],"sourcesContent":["import { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst FEATHERLESS_API_BASE_URL = \"https://api.featherless.ai\";\nexport class FeatherlessAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"featherless-ai\", FEATHERLESS_API_BASE_URL);\n    }\n}\nexport class FeatherlessAITextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"featherless-ai\", FEATHERLESS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Featherless AI text generation API\");\n    }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AACA,MAAM,2BAA2B;AAC1B,MAAM,wCAAwC,oNAAsB;IACvE,aAAc;QACV,KAAK,CAAC,kBAAkB;IAC5B;AACJ;AACO,MAAM,wCAAwC,oNAAsB;IACvE,aAAc;QACV,KAAK,CAAC,kBAAkB;IAC5B;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,KAAK;YACnB,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAI,OAAO,IAAI,CAAC,UAAU,GACpB;gBACE,YAAY,OAAO,IAAI,CAAC,UAAU,CAAC,cAAc;gBACjD,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,CAAC,UAAU,EAAE,iBAAiB;YACrD,IACE,SAAS;YACf,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,YACb,MAAM,OAAO,CAAC,UAAU,YACxB,OAAO,UAAU,UAAU,UAAU;YACrC,MAAM,aAAa,SAAS,OAAO,CAAC,EAAE;YACtC,OAAO;gBACH,gBAAgB,WAAW,IAAI;YACnC;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1630, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/fireworks-ai.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Fireworks model ID here:\n *\n * https://huggingface.co/api/partners/fireworks/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Fireworks and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Fireworks, please open an issue on the present repo\n * and we will tag Fireworks team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nexport class FireworksConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"fireworks-ai\", \"https://api.fireworks.ai\");\n    }\n    makeRoute() {\n        return \"/inference/v1/chat/completions\";\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;;AACO,MAAM,oCAAoC,oNAAsB;IACnE,aAAc;QACV,KAAK,CAAC,gBAAgB;IAC1B;IACA,YAAY;QACR,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1663, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/groq.js"],"sourcesContent":["import { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\n/**\n * See the registered mapping of HF model ID => Groq model ID here:\n *\n * https://huggingface.co/api/partners/groq/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Groq and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Groq, please open an issue on the present repo\n * and we will tag Groq team members.\n *\n * Thanks!\n */\nconst GROQ_API_BASE_URL = \"https://api.groq.com\";\nexport class GroqTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"groq\", GROQ_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/openai/v1/chat/completions\";\n    }\n}\nexport class GroqConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"groq\", GROQ_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/openai/v1/chat/completions\";\n    }\n}\n"],"names":[],"mappings":";;;;;;AAAA;;AACA;;;;;;;;;;;;;;;CAeC,GACD,MAAM,oBAAoB;AACnB,MAAM,+BAA+B,oNAAsB;IAC9D,aAAc;QACV,KAAK,CAAC,QAAQ;IAClB;IACA,YAAY;QACR,OAAO;IACX;AACJ;AACO,MAAM,+BAA+B,oNAAsB;IAC9D,aAAc;QACV,KAAK,CAAC,QAAQ;IAClB;IACA,YAAY;QACR,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1707, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/hyperbolic.js"],"sourcesContent":["import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst HYPERBOLIC_API_BASE_URL = \"https://api.hyperbolic.xyz\";\nexport class HyperbolicConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n}\nexport class HyperbolicTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"v1/chat/completions\";\n    }\n    preparePayload(params) {\n        return {\n            messages: [{ content: params.args.inputs, role: \"user\" }],\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            model: params.model,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.message.content,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Hyperbolic text generation API\");\n    }\n}\nexport class HyperbolicTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"hyperbolic\", HYPERBOLIC_API_BASE_URL);\n    }\n    makeRoute(params) {\n        void params;\n        return `/v1/images/generations`;\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n            model_name: params.model,\n        };\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"images\" in response &&\n            Array.isArray(response.images) &&\n            response.images[0] &&\n            typeof response.images[0].image === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${response.images[0].image}`;\n            }\n            return fetch(`data:image/jpeg;base64,${response.images[0].image}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Hyperbolic text-to-image API\");\n    }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AACA,MAAM,0BAA0B;AACzB,MAAM,qCAAqC,oNAAsB;IACpE,aAAc;QACV,KAAK,CAAC,cAAc;IACxB;AACJ;AACO,MAAM,qCAAqC,oNAAsB;IACpE,aAAc;QACV,KAAK,CAAC,cAAc;IACxB;IACA,YAAY;QACR,OAAO;IACX;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,UAAU;gBAAC;oBAAE,SAAS,OAAO,IAAI,CAAC,MAAM;oBAAE,MAAM;gBAAO;aAAE;YACzD,GAAI,OAAO,IAAI,CAAC,UAAU,GACpB;gBACE,YAAY,OAAO,IAAI,CAAC,UAAU,CAAC,cAAc;gBACjD,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,CAAC,UAAU,EAAE,iBAAiB;YACrD,IACE,SAAS;YACf,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,YACb,MAAM,OAAO,CAAC,UAAU,YACxB,OAAO,UAAU,UAAU,UAAU;YACrC,MAAM,aAAa,SAAS,OAAO,CAAC,EAAE;YACtC,OAAO;gBACH,gBAAgB,WAAW,OAAO,CAAC,OAAO;YAC9C;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,kCAAkC,gNAAkB;IAC7D,aAAc;QACV,KAAK,CAAC,cAAc;IACxB;IACA,UAAU,MAAM,EAAE;QACd,KAAK;QACL,OAAO,CAAC,sBAAsB,CAAC;IACnC;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;YAC1B,YAAY,OAAO,KAAK;QAC5B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,OAAO,aAAa,YACpB,YAAY,YACZ,MAAM,OAAO,CAAC,SAAS,MAAM,KAC7B,SAAS,MAAM,CAAC,EAAE,IAClB,OAAO,SAAS,MAAM,CAAC,EAAE,CAAC,KAAK,KAAK,UAAU;YAC9C,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,IAAI,eAAe,OAAO;gBACtB,OAAO,CAAC,uBAAuB,EAAE,SAAS,MAAM,CAAC,EAAE,CAAC,KAAK,EAAE;YAC/D;YACA,OAAO,MAAM,CAAC,uBAAuB,EAAE,SAAS,MAAM,CAAC,EAAE,CAAC,KAAK,EAAE,EAAE,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI;QAC7F;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1801, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/nebius.js"],"sourcesContent":["import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst NEBIUS_API_BASE_URL = \"https://api.studio.nebius.ai\";\nexport class NebiusConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const responseFormat = params.args.response_format;\n        if (responseFormat?.type === \"json_schema\" && responseFormat.json_schema?.schema) {\n            payload[\"guided_json\"] = responseFormat.json_schema.schema;\n        }\n        return payload;\n    }\n}\nexport class NebiusTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...params.args,\n            model: params.model,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            response.choices.length > 0 &&\n            typeof response.choices[0]?.text === \"string\") {\n            return {\n                generated_text: response.choices[0].text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nebius text generation API\");\n    }\n}\nexport class NebiusTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            response_format: \"b64_json\",\n            prompt: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nebius text-to-image API\");\n    }\n}\nexport class NebiusFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nebius\", NEBIUS_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            input: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/embeddings\";\n    }\n    async getResponse(response) {\n        return response.data.map((item) => item.embedding);\n    }\n}\n"],"names":[],"mappings":";;;;;;;;;;AAAA;AACA;AACA;;;;AACA,MAAM,sBAAsB;AACrB,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,eAAe,MAAM,EAAE;QACnB,MAAM,UAAU,KAAK,CAAC,eAAe;QACrC,MAAM,iBAAiB,OAAO,IAAI,CAAC,eAAe;QAClD,IAAI,gBAAgB,SAAS,iBAAiB,eAAe,WAAW,EAAE,QAAQ;YAC9E,OAAO,CAAC,cAAc,GAAG,eAAe,WAAW,CAAC,MAAM;QAC9D;QACA,OAAO;IACX;AACJ;AACO,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,OAAO,IAAI;YACd,OAAO,OAAO,KAAK;YACnB,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,YACb,MAAM,OAAO,CAAC,UAAU,YACxB,SAAS,OAAO,CAAC,MAAM,GAAG,KAC1B,OAAO,SAAS,OAAO,CAAC,EAAE,EAAE,SAAS,UAAU;YAC/C,OAAO;gBACH,gBAAgB,SAAS,OAAO,CAAC,EAAE,CAAC,IAAI;YAC5C;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,8BAA8B,gNAAkB;IACzD,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,iBAAiB;YACjB,QAAQ,OAAO,IAAI,CAAC,MAAM;YAC1B,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,YAAY;QACR,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,OAAO,aAAa,YACpB,UAAU,YACV,MAAM,OAAO,CAAC,SAAS,IAAI,KAC3B,SAAS,IAAI,CAAC,MAAM,GAAG,KACvB,cAAc,SAAS,IAAI,CAAC,EAAE,IAC9B,OAAO,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ,KAAK,UAAU;YAC/C,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,MAAM,aAAa,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ;YAC5C,IAAI,eAAe,OAAO;gBACtB,OAAO,CAAC,uBAAuB,EAAE,YAAY;YACjD;YACA,OAAO,MAAM,CAAC,uBAAuB,EAAE,YAAY,EAAE,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI;QAC/E;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,oCAAoC,gNAAkB;IAC/D,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,IAAI,CAAC,MAAM;YACzB,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,YAAY;QACR,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO,SAAS,IAAI,CAAC,GAAG,CAAC,CAAC,OAAS,KAAK,SAAS;IACrD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 1907, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/novita.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Novita model ID here:\n *\n * https://huggingface.co/api/partners/novita/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Novita and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Novita, please open an issue on the present repo\n * and we will tag Novita team members.\n *\n * Thanks!\n */\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { delay } from \"../utils/delay.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientInputError, InferenceClientProviderApiError, InferenceClientProviderOutputError, } from \"../errors.js\";\nconst NOVITA_API_BASE_URL = \"https://api.novita.ai\";\nexport class NovitaTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/v3/openai/chat/completions\";\n    }\n}\nexport class NovitaConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"/v3/openai/chat/completions\";\n    }\n}\nexport class NovitaTextToVideoTask extends TaskProviderHelper {\n    constructor() {\n        super(\"novita\", NOVITA_API_BASE_URL);\n    }\n    makeRoute(params) {\n        return `/v3/async/${params.model}`;\n    }\n    preparePayload(params) {\n        const { num_inference_steps, ...restParameters } = params.args.parameters ?? {};\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...restParameters,\n            steps: num_inference_steps,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response, url, headers) {\n        if (!url || !headers) {\n            throw new InferenceClientInputError(\"URL and headers are required for text-to-video task\");\n        }\n        const taskId = response.task_id;\n        if (!taskId) {\n            throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: no task ID found in the response\");\n        }\n        const parsedUrl = new URL(url);\n        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === \"router.huggingface.co\" ? \"/novita\" : \"\"}`;\n        const resultUrl = `${baseUrl}/v3/async/task-result?task_id=${taskId}`;\n        let status = \"\";\n        let taskResult;\n        while (status !== \"TASK_STATUS_SUCCEED\" && status !== \"TASK_STATUS_FAILED\") {\n            await delay(500);\n            const resultResponse = await fetch(resultUrl, { headers });\n            if (!resultResponse.ok) {\n                throw new InferenceClientProviderApiError(\"Failed to fetch task result\", { url: resultUrl, method: \"GET\", headers }, {\n                    requestId: resultResponse.headers.get(\"x-request-id\") ?? \"\",\n                    status: resultResponse.status,\n                    body: await resultResponse.text(),\n                });\n            }\n            try {\n                taskResult = await resultResponse.json();\n                if (taskResult &&\n                    typeof taskResult === \"object\" &&\n                    \"task\" in taskResult &&\n                    taskResult.task &&\n                    typeof taskResult.task === \"object\" &&\n                    \"status\" in taskResult.task &&\n                    typeof taskResult.task.status === \"string\") {\n                    status = taskResult.task.status;\n                }\n                else {\n                    throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: failed to get task status\");\n                }\n            }\n            catch (error) {\n                throw new InferenceClientProviderOutputError(\"Received malformed response from Novita text-to-video API: failed to parse task result\");\n            }\n        }\n        if (status === \"TASK_STATUS_FAILED\") {\n            throw new InferenceClientProviderOutputError(\"Novita text-to-video task failed\");\n        }\n        if (typeof taskResult === \"object\" &&\n            !!taskResult &&\n            \"videos\" in taskResult &&\n            typeof taskResult.videos === \"object\" &&\n            !!taskResult.videos &&\n            Array.isArray(taskResult.videos) &&\n            taskResult.videos.length > 0 &&\n            \"video_url\" in taskResult.videos[0] &&\n            typeof taskResult.videos[0].video_url === \"string\" &&\n            isUrl(taskResult.videos[0].video_url)) {\n            const urlResponse = await fetch(taskResult.videos[0].video_url);\n            return await urlResponse.blob();\n        }\n        else {\n            throw new InferenceClientProviderOutputError(`Received malformed response from Novita text-to-video API: expected { videos: [{ video_url: string }] } format, got instead: ${JSON.stringify(taskResult)}`);\n        }\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;;;;;AACD;AACA;AACA;AACA;AACA;;;;;;AACA,MAAM,sBAAsB;AACrB,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,YAAY;QACR,OAAO;IACX;AACJ;AACO,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,YAAY;QACR,OAAO;IACX;AACJ;AACO,MAAM,8BAA8B,gNAAkB;IACzD,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,UAAU,MAAM,EAAE;QACd,OAAO,CAAC,UAAU,EAAE,OAAO,KAAK,EAAE;IACtC;IACA,eAAe,MAAM,EAAE;QACnB,MAAM,EAAE,mBAAmB,EAAE,GAAG,gBAAgB,GAAG,OAAO,IAAI,CAAC,UAAU,IAAI,CAAC;QAC9E,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,cAAc;YACjB,OAAO;YACP,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE;QACtC,IAAI,CAAC,OAAO,CAAC,SAAS;YAClB,MAAM,IAAI,kMAAyB,CAAC;QACxC;QACA,MAAM,SAAS,SAAS,OAAO;QAC/B,IAAI,CAAC,QAAQ;YACT,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,MAAM,YAAY,IAAI,IAAI;QAC1B,MAAM,UAAU,GAAG,UAAU,QAAQ,CAAC,EAAE,EAAE,UAAU,IAAI,GAAG,UAAU,IAAI,KAAK,0BAA0B,YAAY,IAAI;QACxH,MAAM,YAAY,GAAG,QAAQ,8BAA8B,EAAE,QAAQ;QACrE,IAAI,SAAS;QACb,IAAI;QACJ,MAAO,WAAW,yBAAyB,WAAW,qBAAsB;YACxE,MAAM,IAAA,sLAAK,EAAC;YACZ,MAAM,iBAAiB,MAAM,MAAM,WAAW;gBAAE;YAAQ;YACxD,IAAI,CAAC,eAAe,EAAE,EAAE;gBACpB,MAAM,IAAI,wMAA+B,CAAC,+BAA+B;oBAAE,KAAK;oBAAW,QAAQ;oBAAO;gBAAQ,GAAG;oBACjH,WAAW,eAAe,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBACzD,QAAQ,eAAe,MAAM;oBAC7B,MAAM,MAAM,eAAe,IAAI;gBACnC;YACJ;YACA,IAAI;gBACA,aAAa,MAAM,eAAe,IAAI;gBACtC,IAAI,cACA,OAAO,eAAe,YACtB,UAAU,cACV,WAAW,IAAI,IACf,OAAO,WAAW,IAAI,KAAK,YAC3B,YAAY,WAAW,IAAI,IAC3B,OAAO,WAAW,IAAI,CAAC,MAAM,KAAK,UAAU;oBAC5C,SAAS,WAAW,IAAI,CAAC,MAAM;gBACnC,OACK;oBACD,MAAM,IAAI,2MAAkC,CAAC;gBACjD;YACJ,EACA,OAAO,OAAO;gBACV,MAAM,IAAI,2MAAkC,CAAC;YACjD;QACJ;QACA,IAAI,WAAW,sBAAsB;YACjC,MAAM,IAAI,2MAAkC,CAAC;QACjD;QACA,IAAI,OAAO,eAAe,YACtB,CAAC,CAAC,cACF,YAAY,cACZ,OAAO,WAAW,MAAM,KAAK,YAC7B,CAAC,CAAC,WAAW,MAAM,IACnB,MAAM,OAAO,CAAC,WAAW,MAAM,KAC/B,WAAW,MAAM,CAAC,MAAM,GAAG,KAC3B,eAAe,WAAW,MAAM,CAAC,EAAE,IACnC,OAAO,WAAW,MAAM,CAAC,EAAE,CAAC,SAAS,KAAK,YAC1C,IAAA,oLAAK,EAAC,WAAW,MAAM,CAAC,EAAE,CAAC,SAAS,GAAG;YACvC,MAAM,cAAc,MAAM,MAAM,WAAW,MAAM,CAAC,EAAE,CAAC,SAAS;YAC9D,OAAO,MAAM,YAAY,IAAI;QACjC,OACK;YACD,MAAM,IAAI,2MAAkC,CAAC,CAAC,6HAA6H,EAAE,KAAK,SAAS,CAAC,aAAa;QAC7M;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2031, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/nscale.js"],"sourcesContent":["import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, TaskProviderHelper } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst NSCALE_API_BASE_URL = \"https://inference.api.nscale.com\";\nexport class NscaleConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"nscale\", NSCALE_API_BASE_URL);\n    }\n}\nexport class NscaleTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"nscale\", NSCALE_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            response_format: \"b64_json\",\n            prompt: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Nscale text-to-image API\");\n    }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AACA,MAAM,sBAAsB;AACrB,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;AACJ;AACO,MAAM,8BAA8B,gNAAkB;IACzD,aAAc;QACV,KAAK,CAAC,UAAU;IACpB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,iBAAiB;YACjB,QAAQ,OAAO,IAAI,CAAC,MAAM;YAC1B,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,YAAY;QACR,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,OAAO,aAAa,YACpB,UAAU,YACV,MAAM,OAAO,CAAC,SAAS,IAAI,KAC3B,SAAS,IAAI,CAAC,MAAM,GAAG,KACvB,cAAc,SAAS,IAAI,CAAC,EAAE,IAC9B,OAAO,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ,KAAK,UAAU;YAC/C,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,MAAM,aAAa,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ;YAC5C,IAAI,eAAe,OAAO;gBACtB,OAAO,CAAC,uBAAuB,EAAE,YAAY;YACjD;YACA,OAAO,MAAM,CAAC,uBAAuB,EAAE,YAAY,EAAE,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI;QAC/E;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2088, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/openai.js"],"sourcesContent":["/**\n * Special case: provider configuration for a private models provider (OpenAI in this case).\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst OPENAI_API_BASE_URL = \"https://api.openai.com\";\nexport class OpenAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        // Pass clientSideRoutingOnly: true to the constructor\n        super(\"openai\", OPENAI_API_BASE_URL, true);\n    }\n}\n"],"names":[],"mappings":"AAAA;;CAEC;;;;AACD;;AACA,MAAM,sBAAsB;AACrB,MAAM,iCAAiC,oNAAsB;IAChE,aAAc;QACV,sDAAsD;QACtD,KAAK,CAAC,UAAU,qBAAqB;IACzC;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2107, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/ovhcloud.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => OVHcloud model ID here:\n *\n * https://huggingface.co/api/partners/ovhcloud/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at OVHcloud and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to OVHcloud, please open an issue on the present repo\n * and we will tag OVHcloud team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask, BaseTextGenerationTask } from \"./providerHelper.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst OVHCLOUD_API_BASE_URL = \"https://oai.endpoints.kepler.ai.cloud.ovh.net\";\nexport class OvhCloudConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"ovhcloud\", OVHCLOUD_API_BASE_URL);\n    }\n}\nexport class OvhCloudTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"ovhcloud\", OVHCLOUD_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...(params.args.parameters\n                ? {\n                    max_tokens: params.args.parameters.max_new_tokens,\n                    ...omit(params.args.parameters, \"max_new_tokens\"),\n                }\n                : undefined),\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from OVHcloud text generation API\");\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;;;AACD;AACA;AACA;;;;AACA,MAAM,wBAAwB;AACvB,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;AACJ;AACO,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,KAAK;YACnB,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAI,OAAO,IAAI,CAAC,UAAU,GACpB;gBACE,YAAY,OAAO,IAAI,CAAC,UAAU,CAAC,cAAc;gBACjD,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,CAAC,UAAU,EAAE,iBAAiB;YACrD,IACE,SAAS;YACf,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,YACb,MAAM,OAAO,CAAC,UAAU,YACxB,OAAO,UAAU,UAAU,UAAU;YACrC,MAAM,aAAa,SAAS,OAAO,CAAC,EAAE;YACtC,OAAO;gBACH,gBAAgB,WAAW,IAAI;YACnC;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2172, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/publicai.js"],"sourcesContent":["import { BaseConversationalTask } from \"./providerHelper.js\";\nexport class PublicAIConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"publicai\", \"https://api.publicai.co\");\n    }\n}\n"],"names":[],"mappings":";;;;AAAA;;AACO,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2187, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/replicate.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => Replicate model ID here:\n *\n * https://huggingface.co/api/partners/replicate/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at Replicate and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to Replicate, please open an issue on the present repo\n * and we will tag Replicate team members.\n *\n * Thanks!\n */\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { isUrl } from \"../lib/isUrl.js\";\nimport { omit } from \"../utils/omit.js\";\nimport { TaskProviderHelper, } from \"./providerHelper.js\";\nimport { base64FromBytes } from \"../utils/base64FromBytes.js\";\nclass ReplicateTask extends TaskProviderHelper {\n    constructor(url) {\n        super(\"replicate\", url || \"https://api.replicate.com\");\n    }\n    makeRoute(params) {\n        if (params.model.includes(\":\")) {\n            return \"v1/predictions\";\n        }\n        return `v1/models/${params.model}/predictions`;\n    }\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                prompt: params.args.inputs,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    prepareHeaders(params, binary) {\n        const headers = { Authorization: `Bearer ${params.accessToken}`, Prefer: \"wait\" };\n        if (!binary) {\n            headers[\"Content-Type\"] = \"application/json\";\n        }\n        return headers;\n    }\n    makeUrl(params) {\n        const baseUrl = this.makeBaseUrl(params);\n        if (params.model.includes(\":\")) {\n            return `${baseUrl}/v1/predictions`;\n        }\n        return `${baseUrl}/v1/models/${params.model}/predictions`;\n    }\n}\nexport class ReplicateTextToImageTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                prompt: params.args.inputs,\n                lora_weights: params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath\n                    ? `https://huggingface.co/${params.mapping.hfModelId}`\n                    : undefined,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async getResponse(res, url, headers, outputType) {\n        void url;\n        void headers;\n        if (typeof res === \"object\" &&\n            \"output\" in res &&\n            Array.isArray(res.output) &&\n            res.output.length > 0 &&\n            typeof res.output[0] === \"string\") {\n            if (outputType === \"json\") {\n                return { ...res };\n            }\n            if (outputType === \"url\") {\n                return res.output[0];\n            }\n            const urlResponse = await fetch(res.output[0]);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-image API\");\n    }\n}\nexport class ReplicateTextToSpeechTask extends ReplicateTask {\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const input = payload[\"input\"];\n        if (typeof input === \"object\" && input !== null && \"prompt\" in input) {\n            const inputObj = input;\n            inputObj[\"text\"] = inputObj[\"prompt\"];\n            delete inputObj[\"prompt\"];\n        }\n        return payload;\n    }\n    async getResponse(response) {\n        if (response instanceof Blob) {\n            return response;\n        }\n        if (response && typeof response === \"object\") {\n            if (\"output\" in response) {\n                if (typeof response.output === \"string\") {\n                    const urlResponse = await fetch(response.output);\n                    return await urlResponse.blob();\n                }\n                else if (Array.isArray(response.output)) {\n                    const urlResponse = await fetch(response.output[0]);\n                    return await urlResponse.blob();\n                }\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-speech API\");\n    }\n}\nexport class ReplicateTextToVideoTask extends ReplicateTask {\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            typeof response.output === \"string\" &&\n            isUrl(response.output)) {\n            const urlResponse = await fetch(response.output);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate text-to-video API\");\n    }\n}\nexport class ReplicateAutomaticSpeechRecognitionTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                audio: params.args.inputs, // This will be processed in preparePayloadAsync\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const blob = \"data\" in args && args.data instanceof Blob ? args.data : \"inputs\" in args ? args.inputs : undefined;\n        if (!blob || !(blob instanceof Blob)) {\n            throw new Error(\"Audio input must be a Blob\");\n        }\n        // Convert Blob to base64 data URL\n        const bytes = new Uint8Array(await blob.arrayBuffer());\n        const base64 = base64FromBytes(bytes);\n        const audioInput = `data:${blob.type || \"audio/wav\"};base64,${base64}`;\n        return {\n            ...(\"data\" in args ? omit(args, \"data\") : omit(args, \"inputs\")),\n            inputs: audioInput,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response?.output === \"string\")\n            return { text: response.output };\n        if (Array.isArray(response?.output) && typeof response.output[0] === \"string\")\n            return { text: response.output[0] };\n        const out = response?.output;\n        if (out && typeof out === \"object\") {\n            if (typeof out.transcription === \"string\")\n                return { text: out.transcription };\n            if (typeof out.translation === \"string\")\n                return { text: out.translation };\n            if (typeof out.txt_file === \"string\") {\n                const r = await fetch(out.txt_file);\n                return { text: await r.text() };\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate automatic-speech-recognition API\");\n    }\n}\nexport class ReplicateImageToImageTask extends ReplicateTask {\n    preparePayload(params) {\n        return {\n            input: {\n                ...omit(params.args, [\"inputs\", \"parameters\"]),\n                ...params.args.parameters,\n                input_image: params.args.inputs, // This will be processed in preparePayloadAsync\n                lora_weights: params.mapping?.adapter === \"lora\" && params.mapping.adapterWeightsPath\n                    ? `https://huggingface.co/${params.mapping.hfModelId}`\n                    : undefined,\n            },\n            version: params.model.includes(\":\") ? params.model.split(\":\")[1] : undefined,\n        };\n    }\n    async preparePayloadAsync(args) {\n        const { inputs, ...restArgs } = args;\n        // Convert Blob to base64 data URL\n        const bytes = new Uint8Array(await inputs.arrayBuffer());\n        const base64 = base64FromBytes(bytes);\n        const imageInput = `data:${inputs.type || \"image/jpeg\"};base64,${base64}`;\n        return {\n            ...restArgs,\n            inputs: imageInput,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            Array.isArray(response.output) &&\n            response.output.length > 0 &&\n            typeof response.output[0] === \"string\") {\n            const urlResponse = await fetch(response.output[0]);\n            return await urlResponse.blob();\n        }\n        if (typeof response === \"object\" &&\n            !!response &&\n            \"output\" in response &&\n            typeof response.output === \"string\" &&\n            isUrl(response.output)) {\n            const urlResponse = await fetch(response.output);\n            return await urlResponse.blob();\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Replicate image-to-image API\");\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;;;;;;;;;AACD;AACA;AACA;AACA;AACA;;;;;;AACA,MAAM,sBAAsB,gNAAkB;IAC1C,YAAY,GAAG,CAAE;QACb,KAAK,CAAC,aAAa,OAAO;IAC9B;IACA,UAAU,MAAM,EAAE;QACd,IAAI,OAAO,KAAK,CAAC,QAAQ,CAAC,MAAM;YAC5B,OAAO;QACX;QACA,OAAO,CAAC,UAAU,EAAE,OAAO,KAAK,CAAC,YAAY,CAAC;IAClD;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO;gBACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;oBAAC;oBAAU;iBAAa,CAAC;gBAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;gBACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;YAC9B;YACA,SAAS,OAAO,KAAK,CAAC,QAAQ,CAAC,OAAO,OAAO,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,GAAG;QACvE;IACJ;IACA,eAAe,MAAM,EAAE,MAAM,EAAE;QAC3B,MAAM,UAAU;YAAE,eAAe,CAAC,OAAO,EAAE,OAAO,WAAW,EAAE;YAAE,QAAQ;QAAO;QAChF,IAAI,CAAC,QAAQ;YACT,OAAO,CAAC,eAAe,GAAG;QAC9B;QACA,OAAO;IACX;IACA,QAAQ,MAAM,EAAE;QACZ,MAAM,UAAU,IAAI,CAAC,WAAW,CAAC;QACjC,IAAI,OAAO,KAAK,CAAC,QAAQ,CAAC,MAAM;YAC5B,OAAO,GAAG,QAAQ,eAAe,CAAC;QACtC;QACA,OAAO,GAAG,QAAQ,WAAW,EAAE,OAAO,KAAK,CAAC,YAAY,CAAC;IAC7D;AACJ;AACO,MAAM,iCAAiC;IAC1C,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO;gBACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;oBAAC;oBAAU;iBAAa,CAAC;gBAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;gBACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;gBAC1B,cAAc,OAAO,OAAO,EAAE,YAAY,UAAU,OAAO,OAAO,CAAC,kBAAkB,GAC/E,CAAC,uBAAuB,EAAE,OAAO,OAAO,CAAC,SAAS,EAAE,GACpD;YACV;YACA,SAAS,OAAO,KAAK,CAAC,QAAQ,CAAC,OAAO,OAAO,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,GAAG;QACvE;IACJ;IACA,MAAM,YAAY,GAAG,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAC7C,KAAK;QACL,KAAK;QACL,IAAI,OAAO,QAAQ,YACf,YAAY,OACZ,MAAM,OAAO,CAAC,IAAI,MAAM,KACxB,IAAI,MAAM,CAAC,MAAM,GAAG,KACpB,OAAO,IAAI,MAAM,CAAC,EAAE,KAAK,UAAU;YACnC,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,GAAG;gBAAC;YACpB;YACA,IAAI,eAAe,OAAO;gBACtB,OAAO,IAAI,MAAM,CAAC,EAAE;YACxB;YACA,MAAM,cAAc,MAAM,MAAM,IAAI,MAAM,CAAC,EAAE;YAC7C,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,kCAAkC;IAC3C,eAAe,MAAM,EAAE;QACnB,MAAM,UAAU,KAAK,CAAC,eAAe;QACrC,MAAM,QAAQ,OAAO,CAAC,QAAQ;QAC9B,IAAI,OAAO,UAAU,YAAY,UAAU,QAAQ,YAAY,OAAO;YAClE,MAAM,WAAW;YACjB,QAAQ,CAAC,OAAO,GAAG,QAAQ,CAAC,SAAS;YACrC,OAAO,QAAQ,CAAC,SAAS;QAC7B;QACA,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,oBAAoB,MAAM;YAC1B,OAAO;QACX;QACA,IAAI,YAAY,OAAO,aAAa,UAAU;YAC1C,IAAI,YAAY,UAAU;gBACtB,IAAI,OAAO,SAAS,MAAM,KAAK,UAAU;oBACrC,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM;oBAC/C,OAAO,MAAM,YAAY,IAAI;gBACjC,OACK,IAAI,MAAM,OAAO,CAAC,SAAS,MAAM,GAAG;oBACrC,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM,CAAC,EAAE;oBAClD,OAAO,MAAM,YAAY,IAAI;gBACjC;YACJ;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,iCAAiC;IAC1C,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,CAAC,CAAC,YACF,YAAY,YACZ,OAAO,SAAS,MAAM,KAAK,YAC3B,IAAA,oLAAK,EAAC,SAAS,MAAM,GAAG;YACxB,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM;YAC/C,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,gDAAgD;IACzD,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO;gBACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;oBAAC;oBAAU;iBAAa,CAAC;gBAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;gBACzB,OAAO,OAAO,IAAI,CAAC,MAAM;YAC7B;YACA,SAAS,OAAO,KAAK,CAAC,QAAQ,CAAC,OAAO,OAAO,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,GAAG;QACvE;IACJ;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,OAAO,UAAU,QAAQ,KAAK,IAAI,YAAY,OAAO,KAAK,IAAI,GAAG,YAAY,OAAO,KAAK,MAAM,GAAG;QACxG,IAAI,CAAC,QAAQ,CAAC,CAAC,gBAAgB,IAAI,GAAG;YAClC,MAAM,IAAI,MAAM;QACpB;QACA,kCAAkC;QAClC,MAAM,QAAQ,IAAI,WAAW,MAAM,KAAK,WAAW;QACnD,MAAM,SAAS,IAAA,0MAAe,EAAC;QAC/B,MAAM,aAAa,CAAC,KAAK,EAAE,KAAK,IAAI,IAAI,YAAY,QAAQ,EAAE,QAAQ;QACtE,OAAO;YACH,GAAI,UAAU,OAAO,IAAA,oLAAI,EAAC,MAAM,UAAU,IAAA,oLAAI,EAAC,MAAM,SAAS;YAC9D,QAAQ;QACZ;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,UAAU,WAAW,UAC5B,OAAO;YAAE,MAAM,SAAS,MAAM;QAAC;QACnC,IAAI,MAAM,OAAO,CAAC,UAAU,WAAW,OAAO,SAAS,MAAM,CAAC,EAAE,KAAK,UACjE,OAAO;YAAE,MAAM,SAAS,MAAM,CAAC,EAAE;QAAC;QACtC,MAAM,MAAM,UAAU;QACtB,IAAI,OAAO,OAAO,QAAQ,UAAU;YAChC,IAAI,OAAO,IAAI,aAAa,KAAK,UAC7B,OAAO;gBAAE,MAAM,IAAI,aAAa;YAAC;YACrC,IAAI,OAAO,IAAI,WAAW,KAAK,UAC3B,OAAO;gBAAE,MAAM,IAAI,WAAW;YAAC;YACnC,IAAI,OAAO,IAAI,QAAQ,KAAK,UAAU;gBAClC,MAAM,IAAI,MAAM,MAAM,IAAI,QAAQ;gBAClC,OAAO;oBAAE,MAAM,MAAM,EAAE,IAAI;gBAAG;YAClC;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,kCAAkC;IAC3C,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO;gBACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;oBAAC;oBAAU;iBAAa,CAAC;gBAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;gBACzB,aAAa,OAAO,IAAI,CAAC,MAAM;gBAC/B,cAAc,OAAO,OAAO,EAAE,YAAY,UAAU,OAAO,OAAO,CAAC,kBAAkB,GAC/E,CAAC,uBAAuB,EAAE,OAAO,OAAO,CAAC,SAAS,EAAE,GACpD;YACV;YACA,SAAS,OAAO,KAAK,CAAC,QAAQ,CAAC,OAAO,OAAO,KAAK,CAAC,KAAK,CAAC,IAAI,CAAC,EAAE,GAAG;QACvE;IACJ;IACA,MAAM,oBAAoB,IAAI,EAAE;QAC5B,MAAM,EAAE,MAAM,EAAE,GAAG,UAAU,GAAG;QAChC,kCAAkC;QAClC,MAAM,QAAQ,IAAI,WAAW,MAAM,OAAO,WAAW;QACrD,MAAM,SAAS,IAAA,0MAAe,EAAC;QAC/B,MAAM,aAAa,CAAC,KAAK,EAAE,OAAO,IAAI,IAAI,aAAa,QAAQ,EAAE,QAAQ;QACzE,OAAO;YACH,GAAG,QAAQ;YACX,QAAQ;QACZ;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,CAAC,CAAC,YACF,YAAY,YACZ,MAAM,OAAO,CAAC,SAAS,MAAM,KAC7B,SAAS,MAAM,CAAC,MAAM,GAAG,KACzB,OAAO,SAAS,MAAM,CAAC,EAAE,KAAK,UAAU;YACxC,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM,CAAC,EAAE;YAClD,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,IAAI,OAAO,aAAa,YACpB,CAAC,CAAC,YACF,YAAY,YACZ,OAAO,SAAS,MAAM,KAAK,YAC3B,IAAA,oLAAK,EAAC,SAAS,MAAM,GAAG;YACxB,MAAM,cAAc,MAAM,MAAM,SAAS,MAAM;YAC/C,OAAO,MAAM,YAAY,IAAI;QACjC;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2431, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/sambanova.js"],"sourcesContent":["import { BaseConversationalTask, TaskProviderHelper } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nexport class SambanovaConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"sambanova\", \"https://api.sambanova.ai\");\n    }\n    preparePayload(params) {\n        const responseFormat = params.args.response_format;\n        if (responseFormat?.type === \"json_schema\" && responseFormat.json_schema) {\n            if (responseFormat.json_schema.strict ?? true) {\n                responseFormat.json_schema.strict = false;\n            }\n        }\n        const payload = super.preparePayload(params);\n        return payload;\n    }\n}\nexport class SambanovaFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"sambanova\", \"https://api.sambanova.ai\");\n    }\n    makeRoute() {\n        return `/v1/embeddings`;\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" && \"data\" in response && Array.isArray(response.data)) {\n            return response.data.map((item) => item.embedding);\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Sambanova feature-extraction (embeddings) API\");\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            input: params.args.inputs,\n            ...params.args,\n        };\n    }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;;;AACO,MAAM,oCAAoC,oNAAsB;IACnE,aAAc;QACV,KAAK,CAAC,aAAa;IACvB;IACA,eAAe,MAAM,EAAE;QACnB,MAAM,iBAAiB,OAAO,IAAI,CAAC,eAAe;QAClD,IAAI,gBAAgB,SAAS,iBAAiB,eAAe,WAAW,EAAE;YACtE,IAAI,eAAe,WAAW,CAAC,MAAM,IAAI,MAAM;gBAC3C,eAAe,WAAW,CAAC,MAAM,GAAG;YACxC;QACJ;QACA,MAAM,UAAU,KAAK,CAAC,eAAe;QACrC,OAAO;IACX;AACJ;AACO,MAAM,uCAAuC,gNAAkB;IAClE,aAAc;QACV,KAAK,CAAC,aAAa;IACvB;IACA,YAAY;QACR,OAAO,CAAC,cAAc,CAAC;IAC3B;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YAAY,UAAU,YAAY,MAAM,OAAO,CAAC,SAAS,IAAI,GAAG;YACpF,OAAO,SAAS,IAAI,CAAC,GAAG,CAAC,CAAC,OAAS,KAAK,SAAS;QACrD;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,KAAK;YACnB,OAAO,OAAO,IAAI,CAAC,MAAM;YACzB,GAAG,OAAO,IAAI;QAClB;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2481, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/scaleway.js"],"sourcesContent":["import { InferenceClientProviderOutputError } from \"../errors.js\";\nimport { BaseConversationalTask, TaskProviderHelper, BaseTextGenerationTask } from \"./providerHelper.js\";\nconst SCALEWAY_API_BASE_URL = \"https://api.scaleway.ai\";\nexport class ScalewayConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n}\nexport class ScalewayTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...params.args,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            response !== null &&\n            \"choices\" in response &&\n            Array.isArray(response.choices) &&\n            response.choices.length > 0) {\n            const completion = response.choices[0];\n            if (typeof completion === \"object\" &&\n                !!completion &&\n                \"text\" in completion &&\n                completion.text &&\n                typeof completion.text === \"string\") {\n                return {\n                    generated_text: completion.text,\n                };\n            }\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Scaleway text generation API\");\n    }\n}\nexport class ScalewayFeatureExtractionTask extends TaskProviderHelper {\n    constructor() {\n        super(\"scaleway\", SCALEWAY_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            input: params.args.inputs,\n            model: params.model,\n        };\n    }\n    makeRoute() {\n        return \"v1/embeddings\";\n    }\n    async getResponse(response) {\n        return response.data.map((item) => item.embedding);\n    }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;;;AACA,MAAM,wBAAwB;AACvB,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;AACJ;AACO,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,KAAK;YACnB,GAAG,OAAO,IAAI;YACd,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,QACb,aAAa,YACb,MAAM,OAAO,CAAC,SAAS,OAAO,KAC9B,SAAS,OAAO,CAAC,MAAM,GAAG,GAAG;YAC7B,MAAM,aAAa,SAAS,OAAO,CAAC,EAAE;YACtC,IAAI,OAAO,eAAe,YACtB,CAAC,CAAC,cACF,UAAU,cACV,WAAW,IAAI,IACf,OAAO,WAAW,IAAI,KAAK,UAAU;gBACrC,OAAO;oBACH,gBAAgB,WAAW,IAAI;gBACnC;YACJ;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,sCAAsC,gNAAkB;IACjE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,IAAI,CAAC,MAAM;YACzB,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,YAAY;QACR,OAAO;IACX;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,OAAO,SAAS,IAAI,CAAC,GAAG,CAAC,CAAC,OAAS,KAAK,SAAS;IACrD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2543, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/together.js"],"sourcesContent":["import { omit } from \"../utils/omit.js\";\nimport { BaseConversationalTask, BaseTextGenerationTask, TaskProviderHelper, } from \"./providerHelper.js\";\nimport { InferenceClientProviderOutputError } from \"../errors.js\";\nconst TOGETHER_API_BASE_URL = \"https://api.together.xyz\";\nexport class TogetherConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    preparePayload(params) {\n        const payload = super.preparePayload(params);\n        const response_format = payload.response_format;\n        if (response_format?.type === \"json_schema\" && response_format?.json_schema?.schema) {\n            payload.response_format = {\n                type: \"json_schema\",\n                schema: response_format.json_schema.schema,\n            };\n        }\n        return payload;\n    }\n}\nexport class TogetherTextGenerationTask extends BaseTextGenerationTask {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    preparePayload(params) {\n        return {\n            model: params.model,\n            ...params.args,\n            prompt: params.args.inputs,\n        };\n    }\n    async getResponse(response) {\n        if (typeof response === \"object\" &&\n            \"choices\" in response &&\n            Array.isArray(response?.choices) &&\n            typeof response?.model === \"string\") {\n            const completion = response.choices[0];\n            return {\n                generated_text: completion.text,\n            };\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Together text generation API\");\n    }\n}\nexport class TogetherTextToImageTask extends TaskProviderHelper {\n    constructor() {\n        super(\"together\", TOGETHER_API_BASE_URL);\n    }\n    makeRoute() {\n        return \"v1/images/generations\";\n    }\n    preparePayload(params) {\n        return {\n            ...omit(params.args, [\"inputs\", \"parameters\"]),\n            ...params.args.parameters,\n            prompt: params.args.inputs,\n            response_format: \"base64\",\n            model: params.model,\n        };\n    }\n    async getResponse(response, url, headers, outputType) {\n        if (typeof response === \"object\" &&\n            \"data\" in response &&\n            Array.isArray(response.data) &&\n            response.data.length > 0 &&\n            \"b64_json\" in response.data[0] &&\n            typeof response.data[0].b64_json === \"string\") {\n            if (outputType === \"json\") {\n                return { ...response };\n            }\n            const base64Data = response.data[0].b64_json;\n            if (outputType === \"url\") {\n                return `data:image/jpeg;base64,${base64Data}`;\n            }\n            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res) => res.blob());\n        }\n        throw new InferenceClientProviderOutputError(\"Received malformed response from Together text-to-image API\");\n    }\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AACA;AACA;;;;AACA,MAAM,wBAAwB;AACvB,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,eAAe,MAAM,EAAE;QACnB,MAAM,UAAU,KAAK,CAAC,eAAe;QACrC,MAAM,kBAAkB,QAAQ,eAAe;QAC/C,IAAI,iBAAiB,SAAS,iBAAiB,iBAAiB,aAAa,QAAQ;YACjF,QAAQ,eAAe,GAAG;gBACtB,MAAM;gBACN,QAAQ,gBAAgB,WAAW,CAAC,MAAM;YAC9C;QACJ;QACA,OAAO;IACX;AACJ;AACO,MAAM,mCAAmC,oNAAsB;IAClE,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,OAAO,OAAO,KAAK;YACnB,GAAG,OAAO,IAAI;YACd,QAAQ,OAAO,IAAI,CAAC,MAAM;QAC9B;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE;QACxB,IAAI,OAAO,aAAa,YACpB,aAAa,YACb,MAAM,OAAO,CAAC,UAAU,YACxB,OAAO,UAAU,UAAU,UAAU;YACrC,MAAM,aAAa,SAAS,OAAO,CAAC,EAAE;YACtC,OAAO;gBACH,gBAAgB,WAAW,IAAI;YACnC;QACJ;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ;AACO,MAAM,gCAAgC,gNAAkB;IAC3D,aAAc;QACV,KAAK,CAAC,YAAY;IACtB;IACA,YAAY;QACR,OAAO;IACX;IACA,eAAe,MAAM,EAAE;QACnB,OAAO;YACH,GAAG,IAAA,oLAAI,EAAC,OAAO,IAAI,EAAE;gBAAC;gBAAU;aAAa,CAAC;YAC9C,GAAG,OAAO,IAAI,CAAC,UAAU;YACzB,QAAQ,OAAO,IAAI,CAAC,MAAM;YAC1B,iBAAiB;YACjB,OAAO,OAAO,KAAK;QACvB;IACJ;IACA,MAAM,YAAY,QAAQ,EAAE,GAAG,EAAE,OAAO,EAAE,UAAU,EAAE;QAClD,IAAI,OAAO,aAAa,YACpB,UAAU,YACV,MAAM,OAAO,CAAC,SAAS,IAAI,KAC3B,SAAS,IAAI,CAAC,MAAM,GAAG,KACvB,cAAc,SAAS,IAAI,CAAC,EAAE,IAC9B,OAAO,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ,KAAK,UAAU;YAC/C,IAAI,eAAe,QAAQ;gBACvB,OAAO;oBAAE,GAAG,QAAQ;gBAAC;YACzB;YACA,MAAM,aAAa,SAAS,IAAI,CAAC,EAAE,CAAC,QAAQ;YAC5C,IAAI,eAAe,OAAO;gBACtB,OAAO,CAAC,uBAAuB,EAAE,YAAY;YACjD;YACA,OAAO,MAAM,CAAC,uBAAuB,EAAE,YAAY,EAAE,IAAI,CAAC,CAAC,MAAQ,IAAI,IAAI;QAC/E;QACA,MAAM,IAAI,2MAAkC,CAAC;IACjD;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2634, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/providers/zai-org.js"],"sourcesContent":["/**\n * See the registered mapping of HF model ID => ZAI model ID here:\n *\n * https://huggingface.co/api/partners/zai-org/models\n *\n * This is a publicly available mapping.\n *\n * If you want to try to run inference for a new model locally before it's registered on huggingface.co,\n * you can add it to the dictionary \"HARDCODED_MODEL_ID_MAPPING\" in consts.ts, for dev purposes.\n *\n * - If you work at zai and want to update this mapping, please use the model mapping API we provide on huggingface.co\n * - If you're a community member and want to add a new supported HF model to zai, please open an issue on the present repo\n * and we will tag zai team members.\n *\n * Thanks!\n */\nimport { BaseConversationalTask } from \"./providerHelper.js\";\nconst ZAI_API_BASE_URL = \"https://api.z.ai\";\nexport class ZaiConversationalTask extends BaseConversationalTask {\n    constructor() {\n        super(\"zai-org\", ZAI_API_BASE_URL);\n    }\n    prepareHeaders(params, binary) {\n        const headers = super.prepareHeaders(params, binary);\n        headers[\"x-source-channel\"] = \"hugging_face\";\n        headers[\"accept-language\"] = \"en-US,en\";\n        return headers;\n    }\n    makeRoute() {\n        return \"/api/paas/v4/chat/completions\";\n    }\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;CAeC;;;;AACD;;AACA,MAAM,mBAAmB;AAClB,MAAM,8BAA8B,oNAAsB;IAC7D,aAAc;QACV,KAAK,CAAC,WAAW;IACrB;IACA,eAAe,MAAM,EAAE,MAAM,EAAE;QAC3B,MAAM,UAAU,KAAK,CAAC,eAAe,QAAQ;QAC7C,OAAO,CAAC,mBAAmB,GAAG;QAC9B,OAAO,CAAC,kBAAkB,GAAG;QAC7B,OAAO;IACX;IACA,YAAY;QACR,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2674, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/lib/getProviderHelper.js"],"sourcesContent":["import * as Baseten from \"../providers/baseten.js\";\nimport * as BlackForestLabs from \"../providers/black-forest-labs.js\";\nimport * as Cerebras from \"../providers/cerebras.js\";\nimport * as Cohere from \"../providers/cohere.js\";\nimport * as FalAI from \"../providers/fal-ai.js\";\nimport * as FeatherlessAI from \"../providers/featherless-ai.js\";\nimport * as Fireworks from \"../providers/fireworks-ai.js\";\nimport * as Groq from \"../providers/groq.js\";\nimport * as HFInference from \"../providers/hf-inference.js\";\nimport * as Hyperbolic from \"../providers/hyperbolic.js\";\nimport * as Nebius from \"../providers/nebius.js\";\nimport * as Novita from \"../providers/novita.js\";\nimport * as Nscale from \"../providers/nscale.js\";\nimport * as OpenAI from \"../providers/openai.js\";\nimport * as OvhCloud from \"../providers/ovhcloud.js\";\nimport * as PublicAI from \"../providers/publicai.js\";\nimport * as Replicate from \"../providers/replicate.js\";\nimport * as Sambanova from \"../providers/sambanova.js\";\nimport * as Scaleway from \"../providers/scaleway.js\";\nimport * as Together from \"../providers/together.js\";\nimport * as Zai from \"../providers/zai-org.js\";\nimport { InferenceClientInputError } from \"../errors.js\";\nexport const PROVIDERS = {\n    baseten: {\n        conversational: new Baseten.BasetenConversationalTask(),\n    },\n    \"black-forest-labs\": {\n        \"text-to-image\": new BlackForestLabs.BlackForestLabsTextToImageTask(),\n    },\n    cerebras: {\n        conversational: new Cerebras.CerebrasConversationalTask(),\n    },\n    cohere: {\n        conversational: new Cohere.CohereConversationalTask(),\n    },\n    \"fal-ai\": {\n        \"text-to-image\": new FalAI.FalAITextToImageTask(),\n        \"text-to-speech\": new FalAI.FalAITextToSpeechTask(),\n        \"text-to-video\": new FalAI.FalAITextToVideoTask(),\n        \"image-to-image\": new FalAI.FalAIImageToImageTask(),\n        \"automatic-speech-recognition\": new FalAI.FalAIAutomaticSpeechRecognitionTask(),\n        \"image-segmentation\": new FalAI.FalAIImageSegmentationTask(),\n        \"image-to-video\": new FalAI.FalAIImageToVideoTask(),\n    },\n    \"featherless-ai\": {\n        conversational: new FeatherlessAI.FeatherlessAIConversationalTask(),\n        \"text-generation\": new FeatherlessAI.FeatherlessAITextGenerationTask(),\n    },\n    \"hf-inference\": {\n        \"text-to-image\": new HFInference.HFInferenceTextToImageTask(),\n        conversational: new HFInference.HFInferenceConversationalTask(),\n        \"text-generation\": new HFInference.HFInferenceTextGenerationTask(),\n        \"text-classification\": new HFInference.HFInferenceTextClassificationTask(),\n        \"question-answering\": new HFInference.HFInferenceQuestionAnsweringTask(),\n        \"audio-classification\": new HFInference.HFInferenceAudioClassificationTask(),\n        \"automatic-speech-recognition\": new HFInference.HFInferenceAutomaticSpeechRecognitionTask(),\n        \"fill-mask\": new HFInference.HFInferenceFillMaskTask(),\n        \"feature-extraction\": new HFInference.HFInferenceFeatureExtractionTask(),\n        \"image-classification\": new HFInference.HFInferenceImageClassificationTask(),\n        \"image-segmentation\": new HFInference.HFInferenceImageSegmentationTask(),\n        \"document-question-answering\": new HFInference.HFInferenceDocumentQuestionAnsweringTask(),\n        \"image-to-text\": new HFInference.HFInferenceImageToTextTask(),\n        \"object-detection\": new HFInference.HFInferenceObjectDetectionTask(),\n        \"audio-to-audio\": new HFInference.HFInferenceAudioToAudioTask(),\n        \"zero-shot-image-classification\": new HFInference.HFInferenceZeroShotImageClassificationTask(),\n        \"zero-shot-classification\": new HFInference.HFInferenceZeroShotClassificationTask(),\n        \"image-to-image\": new HFInference.HFInferenceImageToImageTask(),\n        \"sentence-similarity\": new HFInference.HFInferenceSentenceSimilarityTask(),\n        \"table-question-answering\": new HFInference.HFInferenceTableQuestionAnsweringTask(),\n        \"tabular-classification\": new HFInference.HFInferenceTabularClassificationTask(),\n        \"text-to-speech\": new HFInference.HFInferenceTextToSpeechTask(),\n        \"token-classification\": new HFInference.HFInferenceTokenClassificationTask(),\n        translation: new HFInference.HFInferenceTranslationTask(),\n        summarization: new HFInference.HFInferenceSummarizationTask(),\n        \"visual-question-answering\": new HFInference.HFInferenceVisualQuestionAnsweringTask(),\n        \"tabular-regression\": new HFInference.HFInferenceTabularRegressionTask(),\n        \"text-to-audio\": new HFInference.HFInferenceTextToAudioTask(),\n    },\n    \"fireworks-ai\": {\n        conversational: new Fireworks.FireworksConversationalTask(),\n    },\n    groq: {\n        conversational: new Groq.GroqConversationalTask(),\n        \"text-generation\": new Groq.GroqTextGenerationTask(),\n    },\n    hyperbolic: {\n        \"text-to-image\": new Hyperbolic.HyperbolicTextToImageTask(),\n        conversational: new Hyperbolic.HyperbolicConversationalTask(),\n        \"text-generation\": new Hyperbolic.HyperbolicTextGenerationTask(),\n    },\n    nebius: {\n        \"text-to-image\": new Nebius.NebiusTextToImageTask(),\n        conversational: new Nebius.NebiusConversationalTask(),\n        \"text-generation\": new Nebius.NebiusTextGenerationTask(),\n        \"feature-extraction\": new Nebius.NebiusFeatureExtractionTask(),\n    },\n    novita: {\n        conversational: new Novita.NovitaConversationalTask(),\n        \"text-generation\": new Novita.NovitaTextGenerationTask(),\n        \"text-to-video\": new Novita.NovitaTextToVideoTask(),\n    },\n    nscale: {\n        \"text-to-image\": new Nscale.NscaleTextToImageTask(),\n        conversational: new Nscale.NscaleConversationalTask(),\n    },\n    openai: {\n        conversational: new OpenAI.OpenAIConversationalTask(),\n    },\n    ovhcloud: {\n        conversational: new OvhCloud.OvhCloudConversationalTask(),\n        \"text-generation\": new OvhCloud.OvhCloudTextGenerationTask(),\n    },\n    publicai: {\n        conversational: new PublicAI.PublicAIConversationalTask(),\n    },\n    replicate: {\n        \"text-to-image\": new Replicate.ReplicateTextToImageTask(),\n        \"text-to-speech\": new Replicate.ReplicateTextToSpeechTask(),\n        \"text-to-video\": new Replicate.ReplicateTextToVideoTask(),\n        \"image-to-image\": new Replicate.ReplicateImageToImageTask(),\n        \"automatic-speech-recognition\": new Replicate.ReplicateAutomaticSpeechRecognitionTask(),\n    },\n    sambanova: {\n        conversational: new Sambanova.SambanovaConversationalTask(),\n        \"feature-extraction\": new Sambanova.SambanovaFeatureExtractionTask(),\n    },\n    scaleway: {\n        conversational: new Scaleway.ScalewayConversationalTask(),\n        \"text-generation\": new Scaleway.ScalewayTextGenerationTask(),\n        \"feature-extraction\": new Scaleway.ScalewayFeatureExtractionTask(),\n    },\n    together: {\n        \"text-to-image\": new Together.TogetherTextToImageTask(),\n        conversational: new Together.TogetherConversationalTask(),\n        \"text-generation\": new Together.TogetherTextGenerationTask(),\n    },\n    \"zai-org\": {\n        conversational: new Zai.ZaiConversationalTask(),\n    },\n};\nexport function getProviderHelper(provider, task) {\n    if ((provider === \"hf-inference\" && !task) || provider === \"auto\") {\n        return new HFInference.HFInferenceTask();\n    }\n    if (!task) {\n        throw new InferenceClientInputError(\"you need to provide a task name when using an external provider, e.g. 'text-to-image'\");\n    }\n    if (!(provider in PROVIDERS)) {\n        throw new InferenceClientInputError(`Provider '${provider}' not supported. Available providers: ${Object.keys(PROVIDERS)}`);\n    }\n    const providerTasks = PROVIDERS[provider];\n    if (!providerTasks || !(task in providerTasks)) {\n        throw new InferenceClientInputError(`Task '${task}' not supported for provider '${provider}'. Available tasks: ${Object.keys(providerTasks ?? {})}`);\n    }\n    return providerTasks[task];\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;;;;;;;;;;;;;;;;;;;;;AACO,MAAM,YAAY;IACrB,SAAS;QACL,gBAAgB,IAAI,gNAAiC;IACzD;IACA,qBAAqB;QACjB,iBAAiB,IAAI,qOAA8C;IACvE;IACA,UAAU;QACN,gBAAgB,IAAI,kNAAmC;IAC3D;IACA,QAAQ;QACJ,gBAAgB,IAAI,8MAA+B;IACvD;IACA,UAAU;QACN,iBAAiB,IAAI,6MAA0B;QAC/C,kBAAkB,IAAI,8MAA2B;QACjD,iBAAiB,IAAI,6MAA0B;QAC/C,kBAAkB,IAAI,8MAA2B;QACjD,gCAAgC,IAAI,4NAAyC;QAC7E,sBAAsB,IAAI,mNAAgC;QAC1D,kBAAkB,IAAI,8MAA2B;IACrD;IACA,kBAAkB;QACd,gBAAgB,IAAI,gOAA6C;QACjE,mBAAmB,IAAI,gOAA6C;IACxE;IACA,gBAAgB;QACZ,iBAAiB,IAAI,yNAAsC;QAC3D,gBAAgB,IAAI,4NAAyC;QAC7D,mBAAmB,IAAI,4NAAyC;QAChE,uBAAuB,IAAI,gOAA6C;QACxE,sBAAsB,IAAI,+NAA4C;QACtE,wBAAwB,IAAI,iOAA8C;QAC1E,gCAAgC,IAAI,wOAAqD;QACzF,aAAa,IAAI,sNAAmC;QACpD,sBAAsB,IAAI,+NAA4C;QACtE,wBAAwB,IAAI,iOAA8C;QAC1E,sBAAsB,IAAI,+NAA4C;QACtE,+BAA+B,IAAI,uOAAoD;QACvF,iBAAiB,IAAI,yNAAsC;QAC3D,oBAAoB,IAAI,6NAA0C;QAClE,kBAAkB,IAAI,0NAAuC;QAC7D,kCAAkC,IAAI,yOAAsD;QAC5F,4BAA4B,IAAI,oOAAiD;QACjF,kBAAkB,IAAI,0NAAuC;QAC7D,uBAAuB,IAAI,gOAA6C;QACxE,4BAA4B,IAAI,oOAAiD;QACjF,0BAA0B,IAAI,mOAAgD;QAC9E,kBAAkB,IAAI,0NAAuC;QAC7D,wBAAwB,IAAI,iOAA8C;QAC1E,aAAa,IAAI,yNAAsC;QACvD,eAAe,IAAI,2NAAwC;QAC3D,6BAA6B,IAAI,qOAAkD;QACnF,sBAAsB,IAAI,+NAA4C;QACtE,iBAAiB,IAAI,yNAAsC;IAC/D;IACA,gBAAgB;QACZ,gBAAgB,IAAI,0NAAqC;IAC7D;IACA,MAAM;QACF,gBAAgB,IAAI,0MAA2B;QAC/C,mBAAmB,IAAI,0MAA2B;IACtD;IACA,YAAY;QACR,iBAAiB,IAAI,mNAAoC;QACzD,gBAAgB,IAAI,sNAAuC;QAC3D,mBAAmB,IAAI,sNAAuC;IAClE;IACA,QAAQ;QACJ,iBAAiB,IAAI,2MAA4B;QACjD,gBAAgB,IAAI,8MAA+B;QACnD,mBAAmB,IAAI,8MAA+B;QACtD,sBAAsB,IAAI,iNAAkC;IAChE;IACA,QAAQ;QACJ,gBAAgB,IAAI,8MAA+B;QACnD,mBAAmB,IAAI,8MAA+B;QACtD,iBAAiB,IAAI,2MAA4B;IACrD;IACA,QAAQ;QACJ,iBAAiB,IAAI,2MAA4B;QACjD,gBAAgB,IAAI,8MAA+B;IACvD;IACA,QAAQ;QACJ,gBAAgB,IAAI,8MAA+B;IACvD;IACA,UAAU;QACN,gBAAgB,IAAI,kNAAmC;QACvD,mBAAmB,IAAI,kNAAmC;IAC9D;IACA,UAAU;QACN,gBAAgB,IAAI,kNAAmC;IAC3D;IACA,WAAW;QACP,iBAAiB,IAAI,iNAAkC;QACvD,kBAAkB,IAAI,kNAAmC;QACzD,iBAAiB,IAAI,iNAAkC;QACvD,kBAAkB,IAAI,kNAAmC;QACzD,gCAAgC,IAAI,gOAAiD;IACzF;IACA,WAAW;QACP,gBAAgB,IAAI,oNAAqC;QACzD,sBAAsB,IAAI,uNAAwC;IACtE;IACA,UAAU;QACN,gBAAgB,IAAI,kNAAmC;QACvD,mBAAmB,IAAI,kNAAmC;QAC1D,sBAAsB,IAAI,qNAAsC;IACpE;IACA,UAAU;QACN,iBAAiB,IAAI,+MAAgC;QACrD,gBAAgB,IAAI,kNAAmC;QACvD,mBAAmB,IAAI,kNAAmC;IAC9D;IACA,WAAW;QACP,gBAAgB,IAAI,+MAAyB;IACjD;AACJ;AACO,SAAS,kBAAkB,QAAQ,EAAE,IAAI;IAC5C,IAAI,AAAC,aAAa,kBAAkB,CAAC,QAAS,aAAa,QAAQ;QAC/D,OAAO,IAAI,8MAA2B;IAC1C;IACA,IAAI,CAAC,MAAM;QACP,MAAM,IAAI,kMAAyB,CAAC;IACxC;IACA,IAAI,CAAC,CAAC,YAAY,SAAS,GAAG;QAC1B,MAAM,IAAI,kMAAyB,CAAC,CAAC,UAAU,EAAE,SAAS,sCAAsC,EAAE,OAAO,IAAI,CAAC,YAAY;IAC9H;IACA,MAAM,gBAAgB,SAAS,CAAC,SAAS;IACzC,IAAI,CAAC,iBAAiB,CAAC,CAAC,QAAQ,aAAa,GAAG;QAC5C,MAAM,IAAI,kMAAyB,CAAC,CAAC,MAAM,EAAE,KAAK,8BAA8B,EAAE,SAAS,oBAAoB,EAAE,OAAO,IAAI,CAAC,iBAAiB,CAAC,IAAI;IACvJ;IACA,OAAO,aAAa,CAAC,KAAK;AAC9B","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2862, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/package.js"],"sourcesContent":["// Generated file from package.json. Issues importing JSON directly when publishing on commonjs/ESM - see https://github.com/microsoft/TypeScript/issues/51783\nexport const PACKAGE_VERSION = \"4.10.0\";\nexport const PACKAGE_NAME = \"@huggingface/inference\";\n"],"names":[],"mappings":"AAAA,8JAA8J;;;;;;;AACvJ,MAAM,kBAAkB;AACxB,MAAM,eAAe","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 2875, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/lib/makeRequestOptions.js"],"sourcesContent":["import { HF_HEADER_X_BILL_TO, HF_HUB_URL } from \"../config.js\";\nimport { PACKAGE_NAME, PACKAGE_VERSION } from \"../package.js\";\nimport { getInferenceProviderMapping } from \"./getInferenceProviderMapping.js\";\nimport { isUrl } from \"./isUrl.js\";\nimport { InferenceClientHubApiError, InferenceClientInputError } from \"../errors.js\";\n/**\n * Lazy-loaded from huggingface.co/api/tasks when needed\n * Used to determine the default model to use when it's not user defined\n */\nlet tasks = null;\n/**\n * Helper that prepares request arguments.\n * This async version handle the model ID resolution step.\n */\nexport async function makeRequestOptions(args, providerHelper, options) {\n    const { model: maybeModel } = args;\n    const provider = providerHelper.provider;\n    const { task } = options ?? {};\n    // Validate inputs\n    if (args.endpointUrl && provider !== \"hf-inference\") {\n        throw new InferenceClientInputError(`Cannot use endpointUrl with a third-party provider.`);\n    }\n    if (maybeModel && isUrl(maybeModel)) {\n        throw new InferenceClientInputError(`Model URLs are no longer supported. Use endpointUrl instead.`);\n    }\n    if (args.endpointUrl) {\n        // No need to have maybeModel, or to load default model for a task\n        return makeRequestOptionsFromResolvedModel(maybeModel ?? args.endpointUrl, providerHelper, args, undefined, options);\n    }\n    if (!maybeModel && !task) {\n        throw new InferenceClientInputError(\"No model provided, and no task has been specified.\");\n    }\n    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n    const hfModel = maybeModel ?? (await loadDefaultModel(task));\n    if (providerHelper.clientSideRoutingOnly && !maybeModel) {\n        throw new InferenceClientInputError(`Provider ${provider} requires a model ID to be passed directly.`);\n    }\n    const inferenceProviderMapping = providerHelper.clientSideRoutingOnly\n        ? {\n            provider: provider,\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            providerId: removeProviderPrefix(maybeModel, provider),\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            hfModelId: maybeModel,\n            status: \"live\",\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            task: task,\n        }\n        : await getInferenceProviderMapping({\n            modelId: hfModel,\n            // eslint-disable-next-line @typescript-eslint/no-non-null-assertion\n            task: task,\n            provider,\n            accessToken: args.accessToken,\n        }, { fetch: options?.fetch });\n    if (!inferenceProviderMapping) {\n        throw new InferenceClientInputError(`We have not been able to find inference provider information for model ${hfModel}.`);\n    }\n    // Use the sync version with the resolved model\n    return makeRequestOptionsFromResolvedModel(inferenceProviderMapping.providerId, providerHelper, args, inferenceProviderMapping, options);\n}\n/**\n * Helper that prepares request arguments. - for internal use only\n * This sync version skips the model ID resolution step\n */\nexport function makeRequestOptionsFromResolvedModel(resolvedModel, providerHelper, args, mapping, options) {\n    const { accessToken, endpointUrl, provider: maybeProvider, model, ...remainingArgs } = args;\n    void model;\n    void maybeProvider;\n    const provider = providerHelper.provider;\n    const { includeCredentials, task, signal, billTo } = options ?? {};\n    const authMethod = (() => {\n        if (providerHelper.clientSideRoutingOnly) {\n            // Closed-source providers require an accessToken (cannot be routed).\n            if (accessToken && accessToken.startsWith(\"hf_\")) {\n                throw new InferenceClientInputError(`Provider ${provider} is closed-source and does not support HF tokens.`);\n            }\n        }\n        if (accessToken) {\n            return accessToken.startsWith(\"hf_\") ? \"hf-token\" : \"provider-key\";\n        }\n        if (includeCredentials === \"include\") {\n            // If accessToken is passed, it should take precedence over includeCredentials\n            return \"credentials-include\";\n        }\n        return \"none\";\n    })();\n    // Make URL\n    const modelId = endpointUrl ?? resolvedModel;\n    const url = providerHelper.makeUrl({\n        authMethod,\n        model: modelId,\n        task,\n    });\n    // Make headers\n    const headers = providerHelper.prepareHeaders({\n        accessToken,\n        authMethod,\n    }, \"data\" in args && !!args.data);\n    if (billTo) {\n        headers[HF_HEADER_X_BILL_TO] = billTo;\n    }\n    // Add user-agent to headers\n    // e.g. @huggingface/inference/3.1.3\n    const ownUserAgent = `${PACKAGE_NAME}/${PACKAGE_VERSION}`;\n    const userAgent = [ownUserAgent, typeof navigator !== \"undefined\" ? navigator.userAgent : undefined]\n        .filter((x) => x !== undefined)\n        .join(\" \");\n    headers[\"User-Agent\"] = userAgent;\n    // Make body\n    const body = providerHelper.makeBody({\n        args: remainingArgs,\n        model: resolvedModel,\n        task,\n        mapping,\n    });\n    /**\n     * For edge runtimes, leave 'credentials' undefined, otherwise cloudflare workers will error\n     */\n    let credentials;\n    if (typeof includeCredentials === \"string\") {\n        credentials = includeCredentials;\n    }\n    else if (includeCredentials === true) {\n        credentials = \"include\";\n    }\n    const info = {\n        headers,\n        method: \"POST\",\n        body: body,\n        ...(credentials ? { credentials } : undefined),\n        signal,\n    };\n    return { url, info };\n}\nasync function loadDefaultModel(task) {\n    if (!tasks) {\n        tasks = await loadTaskInfo();\n    }\n    const taskInfo = tasks[task];\n    if ((taskInfo?.models.length ?? 0) <= 0) {\n        throw new InferenceClientInputError(`No default model defined for task ${task}, please define the model explicitly.`);\n    }\n    return taskInfo.models[0].id;\n}\nasync function loadTaskInfo() {\n    const url = `${HF_HUB_URL}/api/tasks`;\n    const res = await fetch(url);\n    if (!res.ok) {\n        throw new InferenceClientHubApiError(\"Failed to load tasks definitions from Hugging Face Hub.\", { url, method: \"GET\" }, { requestId: res.headers.get(\"x-request-id\") ?? \"\", status: res.status, body: await res.text() });\n    }\n    return await res.json();\n}\nfunction removeProviderPrefix(model, provider) {\n    if (!model.startsWith(`${provider}/`)) {\n        throw new InferenceClientInputError(`Models from ${provider} must be prefixed by \"${provider}/\". Got \"${model}\".`);\n    }\n    return model.slice(provider.length + 1);\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;AACA;AACA;;;;;;AACA;;;CAGC,GACD,IAAI,QAAQ;AAKL,eAAe,mBAAmB,IAAI,EAAE,cAAc,EAAE,OAAO;IAClE,MAAM,EAAE,OAAO,UAAU,EAAE,GAAG;IAC9B,MAAM,WAAW,eAAe,QAAQ;IACxC,MAAM,EAAE,IAAI,EAAE,GAAG,WAAW,CAAC;IAC7B,kBAAkB;IAClB,IAAI,KAAK,WAAW,IAAI,aAAa,gBAAgB;QACjD,MAAM,IAAI,kMAAyB,CAAC,CAAC,mDAAmD,CAAC;IAC7F;IACA,IAAI,cAAc,IAAA,oLAAK,EAAC,aAAa;QACjC,MAAM,IAAI,kMAAyB,CAAC,CAAC,4DAA4D,CAAC;IACtG;IACA,IAAI,KAAK,WAAW,EAAE;QAClB,kEAAkE;QAClE,OAAO,oCAAoC,cAAc,KAAK,WAAW,EAAE,gBAAgB,MAAM,WAAW;IAChH;IACA,IAAI,CAAC,cAAc,CAAC,MAAM;QACtB,MAAM,IAAI,kMAAyB,CAAC;IACxC;IACA,oEAAoE;IACpE,MAAM,UAAU,cAAe,MAAM,iBAAiB;IACtD,IAAI,eAAe,qBAAqB,IAAI,CAAC,YAAY;QACrD,MAAM,IAAI,kMAAyB,CAAC,CAAC,SAAS,EAAE,SAAS,2CAA2C,CAAC;IACzG;IACA,MAAM,2BAA2B,eAAe,qBAAqB,GAC/D;QACE,UAAU;QACV,oEAAoE;QACpE,YAAY,qBAAqB,YAAY;QAC7C,oEAAoE;QACpE,WAAW;QACX,QAAQ;QACR,oEAAoE;QACpE,MAAM;IACV,IACE,MAAM,IAAA,gOAA2B,EAAC;QAChC,SAAS;QACT,oEAAoE;QACpE,MAAM;QACN;QACA,aAAa,KAAK,WAAW;IACjC,GAAG;QAAE,OAAO,SAAS;IAAM;IAC/B,IAAI,CAAC,0BAA0B;QAC3B,MAAM,IAAI,kMAAyB,CAAC,CAAC,uEAAuE,EAAE,QAAQ,CAAC,CAAC;IAC5H;IACA,+CAA+C;IAC/C,OAAO,oCAAoC,yBAAyB,UAAU,EAAE,gBAAgB,MAAM,0BAA0B;AACpI;AAKO,SAAS,oCAAoC,aAAa,EAAE,cAAc,EAAE,IAAI,EAAE,OAAO,EAAE,OAAO;IACrG,MAAM,EAAE,WAAW,EAAE,WAAW,EAAE,UAAU,aAAa,EAAE,KAAK,EAAE,GAAG,eAAe,GAAG;IACvF,KAAK;IACL,KAAK;IACL,MAAM,WAAW,eAAe,QAAQ;IACxC,MAAM,EAAE,kBAAkB,EAAE,IAAI,EAAE,MAAM,EAAE,MAAM,EAAE,GAAG,WAAW,CAAC;IACjE,MAAM,aAAa,CAAC;QAChB,IAAI,eAAe,qBAAqB,EAAE;YACtC,qEAAqE;YACrE,IAAI,eAAe,YAAY,UAAU,CAAC,QAAQ;gBAC9C,MAAM,IAAI,kMAAyB,CAAC,CAAC,SAAS,EAAE,SAAS,iDAAiD,CAAC;YAC/G;QACJ;QACA,IAAI,aAAa;YACb,OAAO,YAAY,UAAU,CAAC,SAAS,aAAa;QACxD;QACA,IAAI,uBAAuB,WAAW;YAClC,8EAA8E;YAC9E,OAAO;QACX;QACA,OAAO;IACX,CAAC;IACD,WAAW;IACX,MAAM,UAAU,eAAe;IAC/B,MAAM,MAAM,eAAe,OAAO,CAAC;QAC/B;QACA,OAAO;QACP;IACJ;IACA,eAAe;IACf,MAAM,UAAU,eAAe,cAAc,CAAC;QAC1C;QACA;IACJ,GAAG,UAAU,QAAQ,CAAC,CAAC,KAAK,IAAI;IAChC,IAAI,QAAQ;QACR,OAAO,CAAC,4LAAmB,CAAC,GAAG;IACnC;IACA,4BAA4B;IAC5B,oCAAoC;IACpC,MAAM,eAAe,GAAG,sLAAY,CAAC,CAAC,EAAE,yLAAe,EAAE;IACzD,MAAM,YAAY;QAAC;QAAc,OAAO,cAAc,cAAc,UAAU,SAAS,GAAG;KAAU,CAC/F,MAAM,CAAC,CAAC,IAAM,MAAM,WACpB,IAAI,CAAC;IACV,OAAO,CAAC,aAAa,GAAG;IACxB,YAAY;IACZ,MAAM,OAAO,eAAe,QAAQ,CAAC;QACjC,MAAM;QACN,OAAO;QACP;QACA;IACJ;IACA;;KAEC,GACD,IAAI;IACJ,IAAI,OAAO,uBAAuB,UAAU;QACxC,cAAc;IAClB,OACK,IAAI,uBAAuB,MAAM;QAClC,cAAc;IAClB;IACA,MAAM,OAAO;QACT;QACA,QAAQ;QACR,MAAM;QACN,GAAI,cAAc;YAAE;QAAY,IAAI,SAAS;QAC7C;IACJ;IACA,OAAO;QAAE;QAAK;IAAK;AACvB;AACA,eAAe,iBAAiB,IAAI;IAChC,IAAI,CAAC,OAAO;QACR,QAAQ,MAAM;IAClB;IACA,MAAM,WAAW,KAAK,CAAC,KAAK;IAC5B,IAAI,CAAC,UAAU,OAAO,UAAU,CAAC,KAAK,GAAG;QACrC,MAAM,IAAI,kMAAyB,CAAC,CAAC,kCAAkC,EAAE,KAAK,qCAAqC,CAAC;IACxH;IACA,OAAO,SAAS,MAAM,CAAC,EAAE,CAAC,EAAE;AAChC;AACA,eAAe;IACX,MAAM,MAAM,GAAG,mLAAU,CAAC,UAAU,CAAC;IACrC,MAAM,MAAM,MAAM,MAAM;IACxB,IAAI,CAAC,IAAI,EAAE,EAAE;QACT,MAAM,IAAI,mMAA0B,CAAC,2DAA2D;YAAE;YAAK,QAAQ;QAAM,GAAG;YAAE,WAAW,IAAI,OAAO,CAAC,GAAG,CAAC,mBAAmB;YAAI,QAAQ,IAAI,MAAM;YAAE,MAAM,MAAM,IAAI,IAAI;QAAG;IAC3N;IACA,OAAO,MAAM,IAAI,IAAI;AACzB;AACA,SAAS,qBAAqB,KAAK,EAAE,QAAQ;IACzC,IAAI,CAAC,MAAM,UAAU,CAAC,GAAG,SAAS,CAAC,CAAC,GAAG;QACnC,MAAM,IAAI,kMAAyB,CAAC,CAAC,YAAY,EAAE,SAAS,sBAAsB,EAAE,SAAS,SAAS,EAAE,MAAM,EAAE,CAAC;IACrH;IACA,OAAO,MAAM,KAAK,CAAC,SAAS,MAAM,GAAG;AACzC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3051, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/vendor/fetch-event-source/parse.js"],"sourcesContent":["/**\n This file is a part of fetch-event-source package (as of v2.0.1)\n https://github.com/Azure/fetch-event-source/blob/v2.0.1/src/parse.ts\n\n Full package can be used after it is made compatible with nodejs:\n https://github.com/Azure/fetch-event-source/issues/20\n\n Below is the fetch-event-source package license:\n\n MIT License\n\n Copyright (c) Microsoft Corporation.\n\n Permission is hereby granted, free of charge, to any person obtaining a copy\n of this software and associated documentation files (the \"Software\"), to deal\n in the Software without restriction, including without limitation the rights\n to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n copies of the Software, and to permit persons to whom the Software is\n furnished to do so, subject to the following conditions:\n\n The above copyright notice and this permission notice shall be included in all\n copies or substantial portions of the Software.\n\n THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n SOFTWARE\n\n */\n/**\n * Converts a ReadableStream into a callback pattern.\n * @param stream The input ReadableStream.\n * @param onChunk A function that will be called on each new byte chunk in the stream.\n * @returns {Promise<void>} A promise that will be resolved when the stream closes.\n */\nexport async function getBytes(stream, onChunk) {\n    const reader = stream.getReader();\n    let result;\n    while (!(result = await reader.read()).done) {\n        onChunk(result.value);\n    }\n}\n/**\n * Parses arbitary byte chunks into EventSource line buffers.\n * Each line should be of the format \"field: value\" and ends with \\r, \\n, or \\r\\n.\n * @param onLine A function that will be called on each new EventSource line.\n * @returns A function that should be called for each incoming byte chunk.\n */\nexport function getLines(onLine) {\n    let buffer;\n    let position; // current read position\n    let fieldLength; // length of the `field` portion of the line\n    let discardTrailingNewline = false;\n    // return a function that can process each incoming byte chunk:\n    return function onChunk(arr) {\n        if (buffer === undefined) {\n            buffer = arr;\n            position = 0;\n            fieldLength = -1;\n        }\n        else {\n            // we're still parsing the old line. Append the new bytes into buffer:\n            buffer = concat(buffer, arr);\n        }\n        const bufLength = buffer.length;\n        let lineStart = 0; // index where the current line starts\n        while (position < bufLength) {\n            if (discardTrailingNewline) {\n                if (buffer[position] === 10 /* ControlChars.NewLine */) {\n                    lineStart = ++position; // skip to next char\n                }\n                discardTrailingNewline = false;\n            }\n            // start looking forward till the end of line:\n            let lineEnd = -1; // index of the \\r or \\n char\n            for (; position < bufLength && lineEnd === -1; ++position) {\n                switch (buffer[position]) {\n                    case 58 /* ControlChars.Colon */:\n                        if (fieldLength === -1) { // first colon in line\n                            fieldLength = position - lineStart;\n                        }\n                        break;\n                    case 13 /* ControlChars.CarriageReturn */:\n                        discardTrailingNewline = true;\n                    // eslint-disable-next-line no-fallthrough\n                    case 10 /* ControlChars.NewLine */:\n                        lineEnd = position;\n                        break;\n                }\n            }\n            if (lineEnd === -1) {\n                // We reached the end of the buffer but the line hasn't ended.\n                // Wait for the next arr and then continue parsing:\n                break;\n            }\n            // we've reached the line end, send it out:\n            onLine(buffer.subarray(lineStart, lineEnd), fieldLength);\n            lineStart = position; // we're now on the next line\n            fieldLength = -1;\n        }\n        if (lineStart === bufLength) {\n            buffer = undefined; // we've finished reading it\n        }\n        else if (lineStart !== 0) {\n            // Create a new view into buffer beginning at lineStart so we don't\n            // need to copy over the previous lines when we get the new arr:\n            buffer = buffer.subarray(lineStart);\n            position -= lineStart;\n        }\n    };\n}\n/**\n * Parses line buffers into EventSourceMessages.\n * @param onId A function that will be called on each `id` field.\n * @param onRetry A function that will be called on each `retry` field.\n * @param onMessage A function that will be called on each message.\n * @returns A function that should be called for each incoming line buffer.\n */\nexport function getMessages(onId, onRetry, onMessage) {\n    let message = newMessage();\n    const decoder = new TextDecoder();\n    // return a function that can process each incoming line buffer:\n    return function onLine(line, fieldLength) {\n        if (line.length === 0) {\n            // empty line denotes end of message. Trigger the callback and start a new message:\n            onMessage?.(message);\n            message = newMessage();\n        }\n        else if (fieldLength > 0) { // exclude comments and lines with no values\n            // line is of format \"<field>:<value>\" or \"<field>: <value>\"\n            // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n            const field = decoder.decode(line.subarray(0, fieldLength));\n            const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* ControlChars.Space */ ? 2 : 1);\n            const value = decoder.decode(line.subarray(valueOffset));\n            switch (field) {\n                case 'data':\n                    // if this message already has data, append the new value to the old.\n                    // otherwise, just set to the new value:\n                    message.data = message.data\n                        ? message.data + '\\n' + value\n                        : value; // otherwise, \n                    break;\n                case 'event':\n                    message.event = value;\n                    break;\n                case 'id':\n                    onId(message.id = value);\n                    break;\n                case 'retry': {\n                    const retry = parseInt(value, 10);\n                    if (!isNaN(retry)) { // per spec, ignore non-integers\n                        onRetry(message.retry = retry);\n                    }\n                    break;\n                }\n            }\n        }\n    };\n}\nfunction concat(a, b) {\n    const res = new Uint8Array(a.length + b.length);\n    res.set(a);\n    res.set(b, a.length);\n    return res;\n}\nfunction newMessage() {\n    // data, event, and id must be initialized to empty strings:\n    // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation\n    // retry should be initialized to undefined so we return a consistent shape\n    // to the js engine all the time: https://mathiasbynens.be/notes/shapes-ics#takeaways\n    return {\n        data: '',\n        event: '',\n        id: '',\n        retry: undefined,\n    };\n}\n"],"names":[],"mappings":"AAAA;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;CA+BC,GACD;;;;;CAKC;;;;;;;;AACM,eAAe,SAAS,MAAM,EAAE,OAAO;IAC1C,MAAM,SAAS,OAAO,SAAS;IAC/B,IAAI;IACJ,MAAO,CAAC,CAAC,SAAS,MAAM,OAAO,IAAI,EAAE,EAAE,IAAI,CAAE;QACzC,QAAQ,OAAO,KAAK;IACxB;AACJ;AAOO,SAAS,SAAS,MAAM;IAC3B,IAAI;IACJ,IAAI,UAAU,wBAAwB;IACtC,IAAI,aAAa,4CAA4C;IAC7D,IAAI,yBAAyB;IAC7B,+DAA+D;IAC/D,OAAO,SAAS,QAAQ,GAAG;QACvB,IAAI,WAAW,WAAW;YACtB,SAAS;YACT,WAAW;YACX,cAAc,CAAC;QACnB,OACK;YACD,sEAAsE;YACtE,SAAS,OAAO,QAAQ;QAC5B;QACA,MAAM,YAAY,OAAO,MAAM;QAC/B,IAAI,YAAY,GAAG,sCAAsC;QACzD,MAAO,WAAW,UAAW;YACzB,IAAI,wBAAwB;gBACxB,IAAI,MAAM,CAAC,SAAS,KAAK,GAAG,wBAAwB,KAAI;oBACpD,YAAY,EAAE,UAAU,oBAAoB;gBAChD;gBACA,yBAAyB;YAC7B;YACA,8CAA8C;YAC9C,IAAI,UAAU,CAAC,GAAG,6BAA6B;YAC/C,MAAO,WAAW,aAAa,YAAY,CAAC,GAAG,EAAE,SAAU;gBACvD,OAAQ,MAAM,CAAC,SAAS;oBACpB,KAAK,GAAG,sBAAsB;wBAC1B,IAAI,gBAAgB,CAAC,GAAG;4BACpB,cAAc,WAAW;wBAC7B;wBACA;oBACJ,KAAK,GAAG,+BAA+B;wBACnC,yBAAyB;oBAC7B,0CAA0C;oBAC1C,KAAK,GAAG,wBAAwB;wBAC5B,UAAU;wBACV;gBACR;YACJ;YACA,IAAI,YAAY,CAAC,GAAG;gBAGhB;YACJ;YACA,2CAA2C;YAC3C,OAAO,OAAO,QAAQ,CAAC,WAAW,UAAU;YAC5C,YAAY,UAAU,6BAA6B;YACnD,cAAc,CAAC;QACnB;QACA,IAAI,cAAc,WAAW;YACzB,SAAS,WAAW,4BAA4B;QACpD,OACK,IAAI,cAAc,GAAG;YACtB,mEAAmE;YACnE,gEAAgE;YAChE,SAAS,OAAO,QAAQ,CAAC;YACzB,YAAY;QAChB;IACJ;AACJ;AAQO,SAAS,YAAY,IAAI,EAAE,OAAO,EAAE,SAAS;IAChD,IAAI,UAAU;IACd,MAAM,UAAU,IAAI;IACpB,gEAAgE;IAChE,OAAO,SAAS,OAAO,IAAI,EAAE,WAAW;QACpC,IAAI,KAAK,MAAM,KAAK,GAAG;YACnB,mFAAmF;YACnF,YAAY;YACZ,UAAU;QACd,OACK,IAAI,cAAc,GAAG;YACtB,4DAA4D;YAC5D,6FAA6F;YAC7F,MAAM,QAAQ,QAAQ,MAAM,CAAC,KAAK,QAAQ,CAAC,GAAG;YAC9C,MAAM,cAAc,cAAc,CAAC,IAAI,CAAC,cAAc,EAAE,KAAK,GAAG,sBAAsB,MAAK,IAAI,CAAC;YAChG,MAAM,QAAQ,QAAQ,MAAM,CAAC,KAAK,QAAQ,CAAC;YAC3C,OAAQ;gBACJ,KAAK;oBACD,qEAAqE;oBACrE,wCAAwC;oBACxC,QAAQ,IAAI,GAAG,QAAQ,IAAI,GACrB,QAAQ,IAAI,GAAG,OAAO,QACtB,OAAO,cAAc;oBAC3B;gBACJ,KAAK;oBACD,QAAQ,KAAK,GAAG;oBAChB;gBACJ,KAAK;oBACD,KAAK,QAAQ,EAAE,GAAG;oBAClB;gBACJ,KAAK;oBAAS;wBACV,MAAM,QAAQ,SAAS,OAAO;wBAC9B,IAAI,CAAC,MAAM,QAAQ;4BACf,QAAQ,QAAQ,KAAK,GAAG;wBAC5B;wBACA;oBACJ;YACJ;QACJ;IACJ;AACJ;AACA,SAAS,OAAO,CAAC,EAAE,CAAC;IAChB,MAAM,MAAM,IAAI,WAAW,EAAE,MAAM,GAAG,EAAE,MAAM;IAC9C,IAAI,GAAG,CAAC;IACR,IAAI,GAAG,CAAC,GAAG,EAAE,MAAM;IACnB,OAAO;AACX;AACA,SAAS;IACL,4DAA4D;IAC5D,6FAA6F;IAC7F,2EAA2E;IAC3E,qFAAqF;IACrF,OAAO;QACH,MAAM;QACN,OAAO;QACP,IAAI;QACJ,OAAO;IACX;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3222, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/request.js"],"sourcesContent":["import { makeRequestOptions } from \"../lib/makeRequestOptions.js\";\nimport { getLines, getMessages } from \"../vendor/fetch-event-source/parse.js\";\nimport { InferenceClientProviderApiError } from \"../errors.js\";\nfunction bodyToJson(body) {\n    let data = null;\n    if (body instanceof Blob || body instanceof ArrayBuffer) {\n        data = \"[Blob or ArrayBuffer]\";\n    }\n    else if (typeof body === \"string\") {\n        try {\n            data = JSON.parse(body);\n        }\n        catch {\n            data = body;\n        }\n    }\n    if (data.accessToken) {\n        data.accessToken = \"[REDACTED]\";\n    }\n    return data;\n}\n/**\n * Primitive to make custom calls to the inference provider\n */\nexport async function innerRequest(args, providerHelper, options) {\n    const { url, info } = await makeRequestOptions(args, providerHelper, options);\n    const response = await (options?.fetch ?? fetch)(url, info);\n    const requestContext = { url, info };\n    if (options?.retry_on_error !== false && response.status === 503) {\n        return innerRequest(args, providerHelper, options);\n    }\n    if (!response.ok) {\n        const contentType = response.headers.get(\"Content-Type\");\n        if ([\"application/json\", \"application/problem+json\"].some((ct) => contentType?.startsWith(ct))) {\n            const output = await response.json();\n            if ([400, 422, 404, 500].includes(response.status) && options?.chatCompletion) {\n                throw new InferenceClientProviderApiError(`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (typeof output.error === \"string\" || typeof output.detail === \"string\" || typeof output.message === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error ?? output.detail ?? output.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            else {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n        }\n        const message = contentType?.startsWith(\"text/plain;\") ? await response.text() : undefined;\n        throw new InferenceClientProviderApiError(`Failed to perform inference: ${message ?? \"an HTTP error occurred when requesting the provider\"}`, {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: message ?? \"\" });\n    }\n    if (response.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n        const data = (await response.json());\n        return { data, requestContext };\n    }\n    const blob = (await response.blob());\n    return { data: blob, requestContext };\n}\n/**\n * Primitive to make custom inference calls that expect server-sent events, and returns the response through a generator\n */\nexport async function* innerStreamingRequest(args, providerHelper, options) {\n    const { url, info } = await makeRequestOptions({ ...args, stream: true }, providerHelper, options);\n    const response = await (options?.fetch ?? fetch)(url, info);\n    if (options?.retry_on_error !== false && response.status === 503) {\n        return yield* innerStreamingRequest(args, providerHelper, options);\n    }\n    if (!response.ok) {\n        if (response.headers.get(\"Content-Type\")?.startsWith(\"application/json\")) {\n            const output = await response.json();\n            if ([400, 422, 404, 500].includes(response.status) && options?.chatCompletion) {\n                throw new InferenceClientProviderApiError(`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (typeof output.error === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            if (output.error && \"message\" in output.error && typeof output.error.message === \"string\") {\n                /// OpenAI errors\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.error.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n            // Sambanova errors\n            if (typeof output.message === \"string\") {\n                throw new InferenceClientProviderApiError(`Failed to perform inference: ${output.message}`, {\n                    url,\n                    method: info.method ?? \"GET\",\n                    headers: info.headers,\n                    body: bodyToJson(info.body),\n                }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: output });\n            }\n        }\n        throw new InferenceClientProviderApiError(`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: \"\" });\n    }\n    if (!response.headers.get(\"content-type\")?.startsWith(\"text/event-stream\")) {\n        throw new InferenceClientProviderApiError(`Failed to perform inference: server does not support event stream content type, it returned ` +\n            response.headers.get(\"content-type\"), {\n            url,\n            method: info.method ?? \"GET\",\n            headers: info.headers,\n            body: bodyToJson(info.body),\n        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: \"\" });\n    }\n    if (!response.body) {\n        return;\n    }\n    const reader = response.body.getReader();\n    let events = [];\n    const onEvent = (event) => {\n        // accumulate events in array\n        events.push(event);\n    };\n    const onChunk = getLines(getMessages(() => { }, () => { }, onEvent));\n    try {\n        while (true) {\n            const { done, value } = await reader.read();\n            if (done) {\n                return;\n            }\n            onChunk(value);\n            for (const event of events) {\n                if (event.data.length > 0) {\n                    if (event.data === \"[DONE]\") {\n                        return;\n                    }\n                    const data = JSON.parse(event.data);\n                    if (typeof data === \"object\" && data !== null && \"error\" in data) {\n                        const errorStr = typeof data.error === \"string\"\n                            ? data.error\n                            : typeof data.error === \"object\" &&\n                                data.error &&\n                                \"message\" in data.error &&\n                                typeof data.error.message === \"string\"\n                                ? data.error.message\n                                : JSON.stringify(data.error);\n                        throw new InferenceClientProviderApiError(`Failed to perform inference: an occurred while streaming the response: ${errorStr}`, {\n                            url,\n                            method: info.method ?? \"GET\",\n                            headers: info.headers,\n                            body: bodyToJson(info.body),\n                        }, { requestId: response.headers.get(\"x-request-id\") ?? \"\", status: response.status, body: data });\n                    }\n                    yield data;\n                }\n            }\n            events = [];\n        }\n    }\n    finally {\n        reader.releaseLock();\n    }\n}\n"],"names":[],"mappings":";;;;;;AAAA;AACA;AACA;;;;AACA,SAAS,WAAW,IAAI;IACpB,IAAI,OAAO;IACX,IAAI,gBAAgB,QAAQ,gBAAgB,aAAa;QACrD,OAAO;IACX,OACK,IAAI,OAAO,SAAS,UAAU;QAC/B,IAAI;YACA,OAAO,KAAK,KAAK,CAAC;QACtB,EACA,OAAM;YACF,OAAO;QACX;IACJ;IACA,IAAI,KAAK,WAAW,EAAE;QAClB,KAAK,WAAW,GAAG;IACvB;IACA,OAAO;AACX;AAIO,eAAe,aAAa,IAAI,EAAE,cAAc,EAAE,OAAO;IAC5D,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;IACrE,MAAM,WAAW,MAAM,CAAC,SAAS,SAAS,KAAK,EAAE,KAAK;IACtD,MAAM,iBAAiB;QAAE;QAAK;IAAK;IACnC,IAAI,SAAS,mBAAmB,SAAS,SAAS,MAAM,KAAK,KAAK;QAC9D,OAAO,aAAa,MAAM,gBAAgB;IAC9C;IACA,IAAI,CAAC,SAAS,EAAE,EAAE;QACd,MAAM,cAAc,SAAS,OAAO,CAAC,GAAG,CAAC;QACzC,IAAI;YAAC;YAAoB;SAA2B,CAAC,IAAI,CAAC,CAAC,KAAO,aAAa,WAAW,MAAM;YAC5F,MAAM,SAAS,MAAM,SAAS,IAAI;YAClC,IAAI;gBAAC;gBAAK;gBAAK;gBAAK;aAAI,CAAC,QAAQ,CAAC,SAAS,MAAM,KAAK,SAAS,gBAAgB;gBAC3E,MAAM,IAAI,wMAA+B,CAAC,CAAC,SAAS,EAAE,KAAK,QAAQ,CAAC,oDAAoD,EAAE,KAAK,KAAK,CAAC,UAAU,EAAE,KAAK,SAAS,CAAC,OAAO,KAAK,GAAG,EAAE;oBAC7K;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;YACA,IAAI,OAAO,OAAO,KAAK,KAAK,YAAY,OAAO,OAAO,MAAM,KAAK,YAAY,OAAO,OAAO,OAAO,KAAK,UAAU;gBAC7G,MAAM,IAAI,wMAA+B,CAAC,CAAC,6BAA6B,EAAE,OAAO,KAAK,IAAI,OAAO,MAAM,IAAI,OAAO,OAAO,EAAE,EAAE;oBACzH;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG,OACK;gBACD,MAAM,IAAI,wMAA+B,CAAC,CAAC,iFAAiF,CAAC,EAAE;oBAC3H;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;QACJ;QACA,MAAM,UAAU,aAAa,WAAW,iBAAiB,MAAM,SAAS,IAAI,KAAK;QACjF,MAAM,IAAI,wMAA+B,CAAC,CAAC,6BAA6B,EAAE,WAAW,uDAAuD,EAAE;YAC1I;YACA,QAAQ,KAAK,MAAM,IAAI;YACvB,SAAS,KAAK,OAAO;YACrB,MAAM,WAAW,KAAK,IAAI;QAC9B,GAAG;YAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;YAAI,QAAQ,SAAS,MAAM;YAAE,MAAM,WAAW;QAAG;IAC7G;IACA,IAAI,SAAS,OAAO,CAAC,GAAG,CAAC,iBAAiB,WAAW,qBAAqB;QACtE,MAAM,OAAQ,MAAM,SAAS,IAAI;QACjC,OAAO;YAAE;YAAM;QAAe;IAClC;IACA,MAAM,OAAQ,MAAM,SAAS,IAAI;IACjC,OAAO;QAAE,MAAM;QAAM;IAAe;AACxC;AAIO,gBAAgB,sBAAsB,IAAI,EAAE,cAAc,EAAE,OAAO;IACtE,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC;QAAE,GAAG,IAAI;QAAE,QAAQ;IAAK,GAAG,gBAAgB;IAC1F,MAAM,WAAW,MAAM,CAAC,SAAS,SAAS,KAAK,EAAE,KAAK;IACtD,IAAI,SAAS,mBAAmB,SAAS,SAAS,MAAM,KAAK,KAAK;QAC9D,OAAO,OAAO,sBAAsB,MAAM,gBAAgB;IAC9D;IACA,IAAI,CAAC,SAAS,EAAE,EAAE;QACd,IAAI,SAAS,OAAO,CAAC,GAAG,CAAC,iBAAiB,WAAW,qBAAqB;YACtE,MAAM,SAAS,MAAM,SAAS,IAAI;YAClC,IAAI;gBAAC;gBAAK;gBAAK;gBAAK;aAAI,CAAC,QAAQ,CAAC,SAAS,MAAM,KAAK,SAAS,gBAAgB;gBAC3E,MAAM,IAAI,wMAA+B,CAAC,CAAC,SAAS,EAAE,KAAK,QAAQ,CAAC,oDAAoD,EAAE,KAAK,KAAK,CAAC,UAAU,EAAE,KAAK,SAAS,CAAC,OAAO,KAAK,GAAG,EAAE;oBAC7K;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;YACA,IAAI,OAAO,OAAO,KAAK,KAAK,UAAU;gBAClC,MAAM,IAAI,wMAA+B,CAAC,CAAC,6BAA6B,EAAE,OAAO,KAAK,EAAE,EAAE;oBACtF;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;YACA,IAAI,OAAO,KAAK,IAAI,aAAa,OAAO,KAAK,IAAI,OAAO,OAAO,KAAK,CAAC,OAAO,KAAK,UAAU;gBACvF,iBAAiB;gBACjB,MAAM,IAAI,wMAA+B,CAAC,CAAC,6BAA6B,EAAE,OAAO,KAAK,CAAC,OAAO,EAAE,EAAE;oBAC9F;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;YACA,mBAAmB;YACnB,IAAI,OAAO,OAAO,OAAO,KAAK,UAAU;gBACpC,MAAM,IAAI,wMAA+B,CAAC,CAAC,6BAA6B,EAAE,OAAO,OAAO,EAAE,EAAE;oBACxF;oBACA,QAAQ,KAAK,MAAM,IAAI;oBACvB,SAAS,KAAK,OAAO;oBACrB,MAAM,WAAW,KAAK,IAAI;gBAC9B,GAAG;oBAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;oBAAI,QAAQ,SAAS,MAAM;oBAAE,MAAM;gBAAO;YACtG;QACJ;QACA,MAAM,IAAI,wMAA+B,CAAC,CAAC,iFAAiF,CAAC,EAAE;YAC3H;YACA,QAAQ,KAAK,MAAM,IAAI;YACvB,SAAS,KAAK,OAAO;YACrB,MAAM,WAAW,KAAK,IAAI;QAC9B,GAAG;YAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;YAAI,QAAQ,SAAS,MAAM;YAAE,MAAM;QAAG;IAClG;IACA,IAAI,CAAC,SAAS,OAAO,CAAC,GAAG,CAAC,iBAAiB,WAAW,sBAAsB;QACxE,MAAM,IAAI,wMAA+B,CAAC,CAAC,4FAA4F,CAAC,GACpI,SAAS,OAAO,CAAC,GAAG,CAAC,iBAAiB;YACtC;YACA,QAAQ,KAAK,MAAM,IAAI;YACvB,SAAS,KAAK,OAAO;YACrB,MAAM,WAAW,KAAK,IAAI;QAC9B,GAAG;YAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;YAAI,QAAQ,SAAS,MAAM;YAAE,MAAM;QAAG;IAClG;IACA,IAAI,CAAC,SAAS,IAAI,EAAE;QAChB;IACJ;IACA,MAAM,SAAS,SAAS,IAAI,CAAC,SAAS;IACtC,IAAI,SAAS,EAAE;IACf,MAAM,UAAU,CAAC;QACb,6BAA6B;QAC7B,OAAO,IAAI,CAAC;IAChB;IACA,MAAM,UAAU,IAAA,sNAAQ,EAAC,IAAA,yNAAW,EAAC,KAAQ,GAAG,KAAQ,GAAG;IAC3D,IAAI;QACA,MAAO,KAAM;YACT,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,IAAI;YACzC,IAAI,MAAM;gBACN;YACJ;YACA,QAAQ;YACR,KAAK,MAAM,SAAS,OAAQ;gBACxB,IAAI,MAAM,IAAI,CAAC,MAAM,GAAG,GAAG;oBACvB,IAAI,MAAM,IAAI,KAAK,UAAU;wBACzB;oBACJ;oBACA,MAAM,OAAO,KAAK,KAAK,CAAC,MAAM,IAAI;oBAClC,IAAI,OAAO,SAAS,YAAY,SAAS,QAAQ,WAAW,MAAM;wBAC9D,MAAM,WAAW,OAAO,KAAK,KAAK,KAAK,WACjC,KAAK,KAAK,GACV,OAAO,KAAK,KAAK,KAAK,YACpB,KAAK,KAAK,IACV,aAAa,KAAK,KAAK,IACvB,OAAO,KAAK,KAAK,CAAC,OAAO,KAAK,WAC5B,KAAK,KAAK,CAAC,OAAO,GAClB,KAAK,SAAS,CAAC,KAAK,KAAK;wBACnC,MAAM,IAAI,wMAA+B,CAAC,CAAC,uEAAuE,EAAE,UAAU,EAAE;4BAC5H;4BACA,QAAQ,KAAK,MAAM,IAAI;4BACvB,SAAS,KAAK,OAAO;4BACrB,MAAM,WAAW,KAAK,IAAI;wBAC9B,GAAG;4BAAE,WAAW,SAAS,OAAO,CAAC,GAAG,CAAC,mBAAmB;4BAAI,QAAQ,SAAS,MAAM;4BAAE,MAAM;wBAAK;oBACpG;oBACA,MAAM;gBACV;YACJ;YACA,SAAS,EAAE;QACf;IACJ,SACQ;QACJ,OAAO,WAAW;IACtB;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3473, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/custom/request.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { getLogger } from \"../../lib/logger.js\";\n/**\n * Primitive to make custom calls to the inference provider\n * @deprecated Use specific task functions instead. This function will be removed in a future version.\n */\nexport async function request(args, options) {\n    const logger = getLogger();\n    logger.warn(\"The request method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.\");\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, options?.task);\n    const result = await innerRequest(args, providerHelper, options);\n    return result.data;\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,QAAQ,IAAI,EAAE,OAAO;IACvC,MAAM,SAAS,IAAA,yLAAS;IACxB,OAAO,IAAI,CAAC;IACZ,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU,SAAS;IAC5D,MAAM,SAAS,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;IACxD,OAAO,OAAO,IAAI;AACtB","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3497, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/custom/streamingRequest.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\nimport { getLogger } from \"../../lib/logger.js\";\n/**\n * Primitive to make custom inference calls that expect server-sent events, and returns the response through a generator\n * @deprecated Use specific task functions instead. This function will be removed in a future version.\n */\nexport async function* streamingRequest(args, options) {\n    const logger = getLogger();\n    logger.warn(\"The streamingRequest method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.\");\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, options?.task);\n    yield* innerStreamingRequest(args, providerHelper, options);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,gBAAgB,iBAAiB,IAAI,EAAE,OAAO;IACjD,MAAM,SAAS,IAAA,yLAAS;IACxB,OAAO,IAAI,CAAC;IACZ,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU,SAAS;IAC5D,OAAO,IAAA,wMAAqB,EAAC,MAAM,gBAAgB;AACvD","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3520, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/audio/utils.js"],"sourcesContent":["import { omit } from \"../../utils/omit.js\";\nexport function preparePayload(args) {\n    return \"data\" in args\n        ? args\n        : {\n            ...omit(args, \"inputs\"),\n            data: args.inputs,\n        };\n}\n"],"names":[],"mappings":";;;;AAAA;;AACO,SAAS,eAAe,IAAI;IAC/B,OAAO,UAAU,OACX,OACA;QACE,GAAG,IAAA,oLAAI,EAAC,MAAM,SAAS;QACvB,MAAM,KAAK,MAAM;IACrB;AACR","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3536, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/audio/audioClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some audio input and outputs the likelihood of classes.\n * Recommended model:  superb/hubert-large-superb-er\n */\nexport async function audioClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"audio-classification\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"audio-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,oBAAoB,IAAI,EAAE,OAAO;IACnD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,IAAA,wMAAc,EAAC;IAC/B,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3562, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/audio/audioToAudio.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some audio input and outputs one or multiple audio files.\n * Example model: speechbrain/sepformer-wham does audio source separation.\n */\nexport async function audioToAudio(args, options) {\n    const model = \"inputs\" in args ? args.model : undefined;\n    const provider = await resolveProvider(args.provider, model);\n    const providerHelper = getProviderHelper(provider, \"audio-to-audio\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"audio-to-audio\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,aAAa,IAAI,EAAE,OAAO;IAC5C,MAAM,QAAQ,YAAY,OAAO,KAAK,KAAK,GAAG;IAC9C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE;IACtD,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,IAAA,wMAAc,EAAC;IAC/B,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3589, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/audio/automaticSpeechRecognition.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task reads some audio input and outputs the said words within the audio files.\n * Recommended model (english language): facebook/wav2vec2-large-960h-lv60-self\n */\nexport async function automaticSpeechRecognition(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"automatic-speech-recognition\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"automatic-speech-recognition\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAKO,eAAe,2BAA2B,IAAI,EAAE,OAAO;IAC1D,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,MAAM,eAAe,mBAAmB,CAAC;IACzD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3613, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/audio/textToSpeech.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task synthesize an audio of a voice pronouncing a given text.\n * Recommended model: espnet/kan-bayashi_ljspeech_vits\n */\nexport async function textToSpeech(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-speech\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-speech\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAKO,eAAe,aAAa,IAAI,EAAE,OAAO;IAC5C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3636, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/utils.js"],"sourcesContent":["import { omit } from \"../../utils/omit.js\";\nexport function preparePayload(args) {\n    return \"data\" in args ? args : { ...omit(args, \"inputs\"), data: args.inputs };\n}\n"],"names":[],"mappings":";;;;AAAA;;AACO,SAAS,eAAe,IAAI;IAC/B,OAAO,UAAU,OAAO,OAAO;QAAE,GAAG,IAAA,oLAAI,EAAC,MAAM,SAAS;QAAE,MAAM,KAAK,MAAM;IAAC;AAChF","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3652, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/imageClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes.\n * Recommended model: google/vit-base-patch16-224\n */\nexport async function imageClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-classification\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,oBAAoB,IAAI,EAAE,OAAO;IACnD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,IAAA,qMAAc,EAAC;IAC/B,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3678, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/imageSegmentation.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes & bounding boxes of detected objects.\n * Recommended model: facebook/detr-resnet-50-panoptic\n */\nexport async function imageSegmentation(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-segmentation\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-segmentation\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-segmentation\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,kBAAkB,IAAI,EAAE,OAAO;IACjD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,MAAM,eAAe,mBAAmB,CAAC;IACzD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;QAAE,GAAG,OAAO;QAAE,MAAM;IAAqB;IAC9G,OAAO,eAAe,WAAW,CAAC,KAAK,KAAK,KAAK,OAAO;AAC5D","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3708, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/imageToImage.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some text input and outputs an image.\n * Recommended model: lllyasviel/sd-controlnet-depth\n */\nexport async function imageToImage(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-image\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-image\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-to-image\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,aAAa,IAAI,EAAE,OAAO;IAC5C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,MAAM,eAAe,mBAAmB,CAAC;IACzD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;QAAE,GAAG,OAAO;QAAE,MAAM;IAAiB;IAC1G,OAAO,eAAe,WAAW,CAAC,KAAK,KAAK,KAAK,OAAO;AAC5D","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3738, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/imageToText.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the text caption.\n */\nexport async function imageToText(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-text\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-text\",\n    });\n    return providerHelper.getResponse(res[0]);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAIO,eAAe,YAAY,IAAI,EAAE,OAAO;IAC3C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,IAAA,qMAAc,EAAC;IAC/B,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC,GAAG,CAAC,EAAE;AAC5C","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3764, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/imageToVideo.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\n/**\n * This task reads some text input and outputs an image.\n * Recommended model: Wan-AI/Wan2.1-I2V-14B-720P\n */\nexport async function imageToVideo(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"image-to-video\");\n    const payload = await providerHelper.preparePayloadAsync(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"image-to-video\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"image-to-video\" });\n    return providerHelper.getResponse(res, url, info.headers);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,aAAa,IAAI,EAAE,OAAO;IAC5C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,MAAM,eAAe,mBAAmB,CAAC;IACzD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;QAAE,GAAG,OAAO;QAAE,MAAM;IAAiB;IAC1G,OAAO,eAAe,WAAW,CAAC,KAAK,KAAK,KAAK,OAAO;AAC5D","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3794, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/objectDetection.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nimport { preparePayload } from \"./utils.js\";\n/**\n * This task reads some image input and outputs the likelihood of classes & bounding boxes of detected objects.\n * Recommended model: facebook/detr-resnet-50\n */\nexport async function objectDetection(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"object-detection\");\n    const payload = preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"object-detection\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAKO,eAAe,gBAAgB,IAAI,EAAE,OAAO;IAC/C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,IAAA,qMAAc,EAAC;IAC/B,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3820, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/textToImage.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nexport async function textToImage(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-image\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-image\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"text-to-image\" });\n    return providerHelper.getResponse(res, url, info.headers, options?.outputType);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AACO,eAAe,YAAY,IAAI,EAAE,OAAO;IAC3C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;QAAE,GAAG,OAAO;QAAE,MAAM;IAAgB;IACzG,OAAO,eAAe,WAAW,CAAC,KAAK,KAAK,KAAK,OAAO,EAAE,SAAS;AACvE","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3849, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/textToVideo.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { makeRequestOptions } from \"../../lib/makeRequestOptions.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nexport async function textToVideo(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-to-video\");\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-to-video\",\n    });\n    const { url, info } = await makeRequestOptions(args, providerHelper, { ...options, task: \"text-to-video\" });\n    return providerHelper.getResponse(response, url, info.headers);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AACO,eAAe,YAAY,IAAI,EAAE,OAAO;IAC3C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,QAAQ,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAChE,GAAG,OAAO;QACV,MAAM;IACV;IACA,MAAM,EAAE,GAAG,EAAE,IAAI,EAAE,GAAG,MAAM,IAAA,8MAAkB,EAAC,MAAM,gBAAgB;QAAE,GAAG,OAAO;QAAE,MAAM;IAAgB;IACzG,OAAO,eAAe,WAAW,CAAC,UAAU,KAAK,KAAK,OAAO;AACjE","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3878, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/cv/zeroShotImageClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\nasync function preparePayload(args) {\n    if (args.inputs instanceof Blob) {\n        return {\n            ...args,\n            inputs: {\n                image: base64FromBytes(new Uint8Array(await args.inputs.arrayBuffer())),\n            },\n        };\n    }\n    else {\n        return {\n            ...args,\n            inputs: {\n                image: base64FromBytes(new Uint8Array(args.inputs.image instanceof ArrayBuffer ? args.inputs.image : await args.inputs.image.arrayBuffer())),\n            },\n        };\n    }\n}\n/**\n * Classify an image to specified classes.\n * Recommended model: openai/clip-vit-large-patch14-336\n */\nexport async function zeroShotImageClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"zero-shot-image-classification\");\n    const payload = await preparePayload(args);\n    const { data: res } = await innerRequest(payload, providerHelper, {\n        ...options,\n        task: \"zero-shot-image-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AACA,eAAe,eAAe,IAAI;IAC9B,IAAI,KAAK,MAAM,YAAY,MAAM;QAC7B,OAAO;YACH,GAAG,IAAI;YACP,QAAQ;gBACJ,OAAO,IAAA,0MAAe,EAAC,IAAI,WAAW,MAAM,KAAK,MAAM,CAAC,WAAW;YACvE;QACJ;IACJ,OACK;QACD,OAAO;YACH,GAAG,IAAI;YACP,QAAQ;gBACJ,OAAO,IAAA,0MAAe,EAAC,IAAI,WAAW,KAAK,MAAM,CAAC,KAAK,YAAY,cAAc,KAAK,MAAM,CAAC,KAAK,GAAG,MAAM,KAAK,MAAM,CAAC,KAAK,CAAC,WAAW;YAC5I;QACJ;IACJ;AACJ;AAKO,eAAe,4BAA4B,IAAI,EAAE,OAAO;IAC3D,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU,MAAM,eAAe;IACrC,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3921, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/chatCompletion.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Use the chat completion endpoint to generate a response to a prompt, using OpenAI message completion API no stream\n */\nexport async function chatCompletion(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"conversational\");\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"conversational\",\n    });\n    return providerHelper.getResponse(response);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,eAAe,IAAI,EAAE,OAAO;IAC9C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,QAAQ,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAChE,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3944, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/chatCompletionStream.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\n/**\n * Use to continue text from a prompt. Same as `textGeneration` but returns generator that can be read one token at a time\n */\nexport async function* chatCompletionStream(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"conversational\");\n    yield* innerStreamingRequest(args, providerHelper, {\n        ...options,\n        task: \"conversational\",\n    });\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,gBAAgB,qBAAqB,IAAI,EAAE,OAAO;IACrD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,OAAO,IAAA,wMAAqB,EAAC,MAAM,gBAAgB;QAC/C,GAAG,OAAO;QACV,MAAM;IACV;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3966, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/featureExtraction.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task reads some text and outputs raw float values, that are usually consumed as part of a semantic database/semantic search.\n */\nexport async function featureExtraction(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"feature-extraction\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"feature-extraction\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,kBAAkB,IAAI,EAAE,OAAO;IACjD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 3989, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/fillMask.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Tries to fill in a hole with a missing word (token to be precise). That’s the base task for BERT models.\n */\nexport async function fillMask(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"fill-mask\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"fill-mask\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,SAAS,IAAI,EAAE,OAAO;IACxC,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4012, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/questionAnswering.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Want to have a nice know-it-all bot that can answer any question?. Recommended model: deepset/roberta-base-squad2\n */\nexport async function questionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"question-answering\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,kBAAkB,IAAI,EAAE,OAAO;IACjD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4035, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/sentenceSimilarity.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Calculate the semantic similarity between one text and a list of other sentences by comparing their embeddings.\n */\nexport async function sentenceSimilarity(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"sentence-similarity\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"sentence-similarity\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,mBAAmB,IAAI,EAAE,OAAO;IAClD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4058, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/summarization.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is well known to summarize longer text into shorter text. Be careful, some models have a maximum length of input. That means that the summary cannot handle full books for instance. Be careful when choosing your model.\n */\nexport async function summarization(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"summarization\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"summarization\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,cAAc,IAAI,EAAE,OAAO;IAC7C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4081, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/tableQuestionAnswering.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Don’t know SQL? Don’t want to dive into a large spreadsheet? Ask questions in plain english! Recommended model: google/tapas-base-finetuned-wtq.\n */\nexport async function tableQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"table-question-answering\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"table-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,uBAAuB,IAAI,EAAE,OAAO;IACtD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4104, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/textClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Usually used for sentiment-analysis this will output the likelihood of classes of an input. Recommended model: distilbert-base-uncased-finetuned-sst-2-english\n */\nexport async function textClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,mBAAmB,IAAI,EAAE,OAAO;IAClD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4127, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/textGeneration.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Use to continue text from a prompt. This is a very generic task. Recommended model: gpt2 (it’s a simple model, but fun to play with).\n */\nexport async function textGeneration(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-generation\");\n    const { data: response } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"text-generation\",\n    });\n    return providerHelper.getResponse(response);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,eAAe,IAAI,EAAE,OAAO;IAC9C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,QAAQ,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAChE,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4150, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/textGenerationStream.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerStreamingRequest } from \"../../utils/request.js\";\n/**\n * Use to continue text from a prompt. Same as `textGeneration` but returns generator that can be read one token at a time\n */\nexport async function* textGenerationStream(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"text-generation\");\n    yield* innerStreamingRequest(args, providerHelper, {\n        ...options,\n        task: \"text-generation\",\n    });\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,gBAAgB,qBAAqB,IAAI,EAAE,OAAO;IACrD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,OAAO,IAAA,wMAAqB,EAAC,MAAM,gBAAgB;QAC/C,GAAG,OAAO;QACV,MAAM;IACV;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4172, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/tokenClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Usually used for sentence parsing, either grammatical, or Named Entity Recognition (NER) to understand keywords contained within text. Recommended model: dbmdz/bert-large-cased-finetuned-conll03-english\n */\nexport async function tokenClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"token-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"token-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,oBAAoB,IAAI,EAAE,OAAO;IACnD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4195, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/translation.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is well known to translate text from one language to another. Recommended model: Helsinki-NLP/opus-mt-ru-en.\n */\nexport async function translation(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"translation\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"translation\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,YAAY,IAAI,EAAE,OAAO;IAC3C,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4218, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/nlp/zeroShotClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * This task is super useful to try out classification with zero code, you simply pass a sentence/paragraph and the possible labels for that sentence, and you get a result. Recommended model: facebook/bart-large-mnli.\n */\nexport async function zeroShotClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"zero-shot-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"zero-shot-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAIO,eAAe,uBAAuB,IAAI,EAAE,OAAO;IACtD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4241, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/multimodal/documentQuestionAnswering.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Answers a question on a document image. Recommended model: impira/layoutlm-document-qa.\n */\nexport async function documentQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"document-question-answering\");\n    const reqArgs = {\n        ...args,\n        inputs: {\n            question: args.inputs.question,\n            // convert Blob or ArrayBuffer to base64\n            image: base64FromBytes(new Uint8Array(await args.inputs.image.arrayBuffer())),\n        },\n    };\n    const { data: res } = await innerRequest(reqArgs, providerHelper, {\n        ...options,\n        task: \"document-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAIO,eAAe,0BAA0B,IAAI,EAAE,OAAO;IACzD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU;QACZ,GAAG,IAAI;QACP,QAAQ;YACJ,UAAU,KAAK,MAAM,CAAC,QAAQ;YAC9B,wCAAwC;YACxC,OAAO,IAAA,0MAAe,EAAC,IAAI,WAAW,MAAM,KAAK,MAAM,CAAC,KAAK,CAAC,WAAW;QAC7E;IACJ;IACA,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4274, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/multimodal/visualQuestionAnswering.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { base64FromBytes } from \"../../utils/base64FromBytes.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Answers a question on an image. Recommended model: dandelin/vilt-b32-finetuned-vqa.\n */\nexport async function visualQuestionAnswering(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"visual-question-answering\");\n    const reqArgs = {\n        ...args,\n        inputs: {\n            question: args.inputs.question,\n            // convert Blob or ArrayBuffer to base64\n            image: base64FromBytes(new Uint8Array(await args.inputs.image.arrayBuffer())),\n        },\n    };\n    const { data: res } = await innerRequest(reqArgs, providerHelper, {\n        ...options,\n        task: \"visual-question-answering\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;AACA;;;;;AAIO,eAAe,wBAAwB,IAAI,EAAE,OAAO;IACvD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,UAAU;QACZ,GAAG,IAAI;QACP,QAAQ;YACJ,UAAU,KAAK,MAAM,CAAC,QAAQ;YAC9B,wCAAwC;YACxC,OAAO,IAAA,0MAAe,EAAC,IAAI,WAAW,MAAM,KAAK,MAAM,CAAC,KAAK,CAAC,WAAW;QAC7E;IACJ;IACA,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,SAAS,gBAAgB;QAC9D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4307, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/tabular/tabularClassification.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Predicts target label for a given set of features in tabular form.\n * Typically, you will want to train a classification model on your training data and use it with your new data of the same format.\n * Example model: vvmnnnkv/wine-quality\n */\nexport async function tabularClassification(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"tabular-classification\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"tabular-classification\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAMO,eAAe,sBAAsB,IAAI,EAAE,OAAO;IACrD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4330, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/tabular/tabularRegression.js"],"sourcesContent":["import { resolveProvider } from \"../../lib/getInferenceProviderMapping.js\";\nimport { getProviderHelper } from \"../../lib/getProviderHelper.js\";\nimport { innerRequest } from \"../../utils/request.js\";\n/**\n * Predicts target value for a given set of features in tabular form.\n * Typically, you will want to train a regression model on your training data and use it with your new data of the same format.\n * Example model: scikit-learn/Fish-Weight\n */\nexport async function tabularRegression(args, options) {\n    const provider = await resolveProvider(args.provider, args.model, args.endpointUrl);\n    const providerHelper = getProviderHelper(provider, \"tabular-regression\");\n    const { data: res } = await innerRequest(args, providerHelper, {\n        ...options,\n        task: \"tabular-regression\",\n    });\n    return providerHelper.getResponse(res);\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AACA;;;;AAMO,eAAe,kBAAkB,IAAI,EAAE,OAAO;IACjD,MAAM,WAAW,MAAM,IAAA,oNAAe,EAAC,KAAK,QAAQ,EAAE,KAAK,KAAK,EAAE,KAAK,WAAW;IAClF,MAAM,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;IACnD,MAAM,EAAE,MAAM,GAAG,EAAE,GAAG,MAAM,IAAA,+LAAY,EAAC,MAAM,gBAAgB;QAC3D,GAAG,OAAO;QACV,MAAM;IACV;IACA,OAAO,eAAe,WAAW,CAAC;AACtC","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4353, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/tasks/index.js"],"sourcesContent":["// Custom tasks with arbitrary inputs and outputs\nexport * from \"./custom/request.js\";\nexport * from \"./custom/streamingRequest.js\";\n// Audio tasks\nexport * from \"./audio/audioClassification.js\";\nexport * from \"./audio/audioToAudio.js\";\nexport * from \"./audio/automaticSpeechRecognition.js\";\nexport * from \"./audio/textToSpeech.js\";\n// Computer Vision tasks\nexport * from \"./cv/imageClassification.js\";\nexport * from \"./cv/imageSegmentation.js\";\nexport * from \"./cv/imageToImage.js\";\nexport * from \"./cv/imageToText.js\";\nexport * from \"./cv/imageToVideo.js\";\nexport * from \"./cv/objectDetection.js\";\nexport * from \"./cv/textToImage.js\";\nexport * from \"./cv/textToVideo.js\";\nexport * from \"./cv/zeroShotImageClassification.js\";\n// Natural Language Processing tasks\nexport * from \"./nlp/chatCompletion.js\";\nexport * from \"./nlp/chatCompletionStream.js\";\nexport * from \"./nlp/featureExtraction.js\";\nexport * from \"./nlp/fillMask.js\";\nexport * from \"./nlp/questionAnswering.js\";\nexport * from \"./nlp/sentenceSimilarity.js\";\nexport * from \"./nlp/summarization.js\";\nexport * from \"./nlp/tableQuestionAnswering.js\";\nexport * from \"./nlp/textClassification.js\";\nexport * from \"./nlp/textGeneration.js\";\nexport * from \"./nlp/textGenerationStream.js\";\nexport * from \"./nlp/tokenClassification.js\";\nexport * from \"./nlp/translation.js\";\nexport * from \"./nlp/zeroShotClassification.js\";\n// Multimodal tasks\nexport * from \"./multimodal/documentQuestionAnswering.js\";\nexport * from \"./multimodal/visualQuestionAnswering.js\";\n// Tabular tasks\nexport * from \"./tabular/tabularClassification.js\";\nexport * from \"./tabular/tabularRegression.js\";\n"],"names":[],"mappings":"AAAA,iDAAiD;;AACjD;AACA;AACA,cAAc;AACd;AACA;AACA;AACA;AACA,wBAAwB;AACxB;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,oCAAoC;AACpC;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA,mBAAmB;AACnB;AACA;AACA,gBAAgB;AAChB;AACA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4536, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/utils/typedEntries.js"],"sourcesContent":["export function typedEntries(obj) {\n    return Object.entries(obj);\n}\n"],"names":[],"mappings":";;;;AAAO,SAAS,aAAa,GAAG;IAC5B,OAAO,OAAO,OAAO,CAAC;AAC1B","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4547, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/InferenceClient.js"],"sourcesContent":["import * as tasks from \"./tasks/index.js\";\nimport { omit } from \"./utils/omit.js\";\nimport { typedEntries } from \"./utils/typedEntries.js\";\nexport class InferenceClient {\n    accessToken;\n    defaultOptions;\n    constructor(accessToken = \"\", defaultOptions = {}) {\n        this.accessToken = accessToken;\n        this.defaultOptions = defaultOptions;\n        for (const [name, fn] of typedEntries(tasks)) {\n            Object.defineProperty(this, name, {\n                enumerable: false,\n                value: (params, options) => \n                // eslint-disable-next-line @typescript-eslint/no-explicit-any\n                fn(\n                /// ^ The cast of fn to any is necessary, otherwise TS can't compile because the generated union type is too complex\n                { endpointUrl: defaultOptions.endpointUrl, accessToken, ...params }, {\n                    ...omit(defaultOptions, [\"endpointUrl\"]),\n                    ...options,\n                }),\n            });\n        }\n    }\n    /**\n     * Returns a new instance of InferenceClient tied to a specified endpoint.\n     *\n     * For backward compatibility mostly.\n     */\n    endpoint(endpointUrl) {\n        return new InferenceClient(this.accessToken, { ...this.defaultOptions, endpointUrl });\n    }\n}\n/**\n * For backward compatibility only, will remove soon.\n * @deprecated replace with InferenceClient\n */\nexport class HfInference extends InferenceClient {\n}\n/**\n * For backward compatibility only, will remove soon.\n * @deprecated replace with InferenceClient\n */\nexport class InferenceClientEndpoint extends InferenceClient {\n}\n"],"names":[],"mappings":";;;;;;;;AAAA;AAAA;AACA;AACA;;;;AACO,MAAM;IACT,YAAY;IACZ,eAAe;IACf,YAAY,cAAc,EAAE,EAAE,iBAAiB,CAAC,CAAC,CAAE;QAC/C,IAAI,CAAC,WAAW,GAAG;QACnB,IAAI,CAAC,cAAc,GAAG;QACtB,KAAK,MAAM,CAAC,MAAM,GAAG,IAAI,IAAA,oMAAY,EAAC,+KAAQ;YAC1C,OAAO,cAAc,CAAC,IAAI,EAAE,MAAM;gBAC9B,YAAY;gBACZ,OAAO,CAAC,QAAQ,UAChB,8DAA8D;oBAC9D,GACA,oHAAoH;oBACpH;wBAAE,aAAa,eAAe,WAAW;wBAAE;wBAAa,GAAG,MAAM;oBAAC,GAAG;wBACjE,GAAG,IAAA,oLAAI,EAAC,gBAAgB;4BAAC;yBAAc,CAAC;wBACxC,GAAG,OAAO;oBACd;YACJ;QACJ;IACJ;IACA;;;;KAIC,GACD,SAAS,WAAW,EAAE;QAClB,OAAO,IAAI,gBAAgB,IAAI,CAAC,WAAW,EAAE;YAAE,GAAG,IAAI,CAAC,cAAc;YAAE;QAAY;IACvF;AACJ;AAKO,MAAM,oBAAoB;AACjC;AAKO,MAAM,gCAAgC;AAC7C","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4605, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/types.js"],"sourcesContent":["export const INFERENCE_PROVIDERS = [\n    \"baseten\",\n    \"black-forest-labs\",\n    \"cerebras\",\n    \"cohere\",\n    \"fal-ai\",\n    \"featherless-ai\",\n    \"fireworks-ai\",\n    \"groq\",\n    \"hf-inference\",\n    \"hyperbolic\",\n    \"nebius\",\n    \"novita\",\n    \"nscale\",\n    \"openai\",\n    \"ovhcloud\",\n    \"publicai\",\n    \"replicate\",\n    \"sambanova\",\n    \"scaleway\",\n    \"together\",\n    \"zai-org\",\n];\nexport const PROVIDERS_OR_POLICIES = [...INFERENCE_PROVIDERS, \"auto\"];\n"],"names":[],"mappings":";;;;;;AAAO,MAAM,sBAAsB;IAC/B;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;IACA;CACH;AACM,MAAM,wBAAwB;OAAI;IAAqB;CAAO","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4642, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/snippets/templates.exported.js"],"sourcesContent":["// Generated file - do not edit directly\nexport const templates = {\n    \"js\": {\n        \"fetch\": {\n            \"basic\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"basicAudio\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"audio/flac\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"basicImage\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"conversational\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ \\n{{ autoInputs.asTsString }}\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"imageToImage\": \"const image = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: {\\n\\t\\t\\t\\t\\\"inputs\\\": `data:image/png;base64,${data.inputs.encode(\\\"base64\\\")}`,\\n\\t\\t\\t\\t\\\"parameters\\\": data.parameters,\\n\\t\\t\\t}\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({ \\n\\tinputs: image,\\n\\tparameters: {\\n\\t\\tprompt: \\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n\\t}\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\",\n            \"imageToVideo\": \"const image = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"image/jpeg\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: {\\n\\t\\t\\t\\t\\\"image_url\\\": `data:image/png;base64,${data.image.encode(\\\"base64\\\")}`,\\n\\t\\t\\t\\t\\\"prompt\\\": data.prompt,\\n\\t\\t\\t}\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.json();\\n\\treturn result;\\n}\\n\\nquery({\\n\\t\\\"image\\\": image,\\n\\t\\\"prompt\\\": \\\"{{inputs.asObj.parameters.prompt}}\\\",\\n}).then((response) => {\\n    // Use video\\n});\",\n            \"textToAudio\": \"{% if model.library_name == \\\"transformers\\\" %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n    return result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    // Returns a byte object of the Audio wavform. Use it directly!\\n});\\n{% else %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\\n{% endif %} \",\n            \"textToImage\": \"async function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n\\treturn result;\\n}\\n\\n\\nquery({ {{ providerInputs.asTsString }} }).then((response) => {\\n    // Use image\\n});\",\n            \"textToSpeech\": \"{% if model.library_name == \\\"transformers\\\" %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n\\t\\t\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n\\tconst result = await response.blob();\\n    return result;\\n}\\n\\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\\n    // Returns a byte object of the Audio wavform. Use it directly!\\n});\\n{% else %}\\nasync function query(data) {\\n\\tconst response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n\\t\\t{\\n\\t\\t\\theaders: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n\\t\\t\\t\\t\\\"Content-Type\\\": \\\"application/json\\\",\\n\\t\\t\\t},\\n\\t\\t\\tmethod: \\\"POST\\\",\\n\\t\\t\\tbody: JSON.stringify(data),\\n\\t\\t}\\n\\t);\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\\n{% endif %} \",\n            \"zeroShotClassification\": \"async function query(data) {\\n    const response = await fetch(\\n\\t\\t\\\"{{ fullUrl }}\\\",\\n        {\\n            headers: {\\n\\t\\t\\t\\tAuthorization: \\\"{{ authorizationHeader }}\\\",\\n                \\\"Content-Type\\\": \\\"application/json\\\",\\n{% if billTo %}\\n                \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\",\\n{% endif %}         },\\n            method: \\\"POST\\\",\\n            body: JSON.stringify(data),\\n        }\\n    );\\n    const result = await response.json();\\n    return result;\\n}\\n\\nquery({\\n    inputs: {{ providerInputs.asObj.inputs }},\\n    parameters: { candidate_labels: [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"] }\\n}).then((response) => {\\n    console.log(JSON.stringify(response));\\n});\"\n        },\n        \"huggingface.js\": {\n            \"basic\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"basicAudio\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tdata,\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"basicImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\\n\\nconst output = await client.{{ methodName }}({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tdata,\\n\\tmodel: \\\"{{ model.id }}\\\",\\n\\tprovider: \\\"{{ provider }}\\\",\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(output);\",\n            \"conversational\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst chatCompletion = await client.chatCompletion({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n{{ inputs.asTsString }}\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nconsole.log(chatCompletion.choices[0].message);\",\n            \"conversationalStream\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nlet out = \\\"\\\";\\n\\nconst stream = client.chatCompletionStream({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n{{ inputs.asTsString }}\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\nfor await (const chunk of stream) {\\n\\tif (chunk.choices && chunk.choices.length > 0) {\\n\\t\\tconst newContent = chunk.choices[0].delta.content;\\n\\t\\tout += newContent;\\n\\t\\tconsole.log(newContent);\\n\\t}\\n}\",\n            \"imageToImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nconst image = await client.imageToImage({\\n{% if endpointUrl %}\\n\\tendpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tprovider: \\\"{{provider}}\\\",\\n\\tmodel: \\\"{{model.id}}\\\",\\n\\tinputs: data,\\n\\tparameters: { prompt: \\\"{{inputs.asObj.parameters.prompt}}\\\", },\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n/// Use the generated image (it's a Blob)\\n// For example, you can save it to a file or display it in an image element\\n\",\n            \"imageToVideo\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst data = fs.readFileSync(\\\"{{inputs.asObj.inputs}}\\\");\\n\\nconst video = await client.imageToVideo({\\n{% if endpointUrl %}\\n\\tendpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n\\tprovider: \\\"{{provider}}\\\",\\n\\tmodel: \\\"{{model.id}}\\\",\\n\\tinputs: data,\\n\\tparameters: { prompt: \\\"{{inputs.asObj.parameters.prompt}}\\\", },\\n}{% if billTo %}, {\\n\\tbillTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n\\n/// Use the generated video (it's a Blob)\\n// For example, you can save it to a file or display it in a video element\\n\",\n            \"textToImage\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst image = await client.textToImage({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n\\tparameters: { num_inference_steps: 5 },\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n/// Use the generated image (it's a Blob)\",\n            \"textToSpeech\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst audio = await client.textToSpeech({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n// Use the generated audio (it's a Blob)\",\n            \"textToVideo\": \"import { InferenceClient } from \\\"@huggingface/inference\\\";\\n\\nconst client = new InferenceClient(\\\"{{ accessToken }}\\\");\\n\\nconst video = await client.textToVideo({\\n{% if endpointUrl %}\\n    endpointUrl: \\\"{{ endpointUrl }}\\\",\\n{% endif %}\\n    provider: \\\"{{ provider }}\\\",\\n    model: \\\"{{ model.id }}\\\",\\n\\tinputs: {{ inputs.asObj.inputs }},\\n}{% if billTo %}, {\\n    billTo: \\\"{{ billTo }}\\\",\\n}{% endif %});\\n// Use the generated video (it's a Blob)\"\n        },\n        \"openai\": {\n            \"conversational\": \"import { OpenAI } from \\\"openai\\\";\\n\\nconst client = new OpenAI({\\n\\tbaseURL: \\\"{{ baseUrl }}\\\",\\n\\tapiKey: \\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n\\tdefaultHeaders: {\\n\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\" \\n\\t}\\n{% endif %}\\n});\\n\\nconst chatCompletion = await client.chat.completions.create({\\n\\tmodel: \\\"{{ providerModelId }}\\\",\\n{{ inputs.asTsString }}\\n});\\n\\nconsole.log(chatCompletion.choices[0].message);\",\n            \"conversationalStream\": \"import { OpenAI } from \\\"openai\\\";\\n\\nconst client = new OpenAI({\\n\\tbaseURL: \\\"{{ baseUrl }}\\\",\\n\\tapiKey: \\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    defaultHeaders: {\\n\\t\\t\\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\" \\n\\t}\\n{% endif %}\\n});\\n\\nconst stream = await client.chat.completions.create({\\n    model: \\\"{{ providerModelId }}\\\",\\n{{ inputs.asTsString }}\\n    stream: true,\\n});\\n\\nfor await (const chunk of stream) {\\n    process.stdout.write(chunk.choices[0]?.delta?.content || \\\"\\\");\\n}\"\n        }\n    },\n    \"python\": {\n        \"fal_client\": {\n            \"imageToImage\": \"{%if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\nimport base64\\n\\ndef on_queue_update(update):\\n    if isinstance(update, fal_client.InProgress):\\n        for log in update.logs:\\n           print(log[\\\"message\\\"])\\n\\nwith open(\\\"{{inputs.asObj.inputs}}\\\", \\\"rb\\\") as image_file:\\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\\n\\nresult = fal_client.subscribe(\\n    \\\"fal-ai/flux-kontext/dev\\\",\\n    arguments={\\n        \\\"prompt\\\": f\\\"data:image/png;base64,{image_base_64}\\\",\\n        \\\"image_url\\\": \\\"{{ providerInputs.asObj.inputs }}\\\",\\n    },\\n    with_logs=True,\\n    on_queue_update=on_queue_update,\\n)\\nprint(result)\\n{%endif%}\\n\",\n            \"imageToVideo\": \"{%if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\nimport base64\\n\\ndef on_queue_update(update):\\n    if isinstance(update, fal_client.InProgress):\\n        for log in update.logs:\\n           print(log[\\\"message\\\"])\\n\\nwith open(\\\"{{inputs.asObj.inputs}}\\\", \\\"rb\\\") as image_file:\\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\\n\\nresult = fal_client.subscribe(\\n    \\\"{{model.id}}\\\",\\n    arguments={\\n        \\\"image_url\\\": f\\\"data:image/png;base64,{image_base_64}\\\",\\n        \\\"prompt\\\": \\\"{{inputs.asObj.parameters.prompt}}\\\",\\n    },\\n    with_logs=True,\\n    on_queue_update=on_queue_update,\\n)\\nprint(result)\\n{%endif%}\\n\",\n            \"textToImage\": \"{% if provider == \\\"fal-ai\\\" %}\\nimport fal_client\\n\\n{% if providerInputs.asObj.loras is defined and providerInputs.asObj.loras != none %}\\nresult = fal_client.subscribe(\\n    \\\"{{ providerModelId }}\\\",\\n    arguments={\\n        \\\"prompt\\\": {{ inputs.asObj.inputs }},\\n        \\\"loras\\\":{{ providerInputs.asObj.loras | tojson }},\\n    },\\n)\\n{% else %}\\nresult = fal_client.subscribe(\\n    \\\"{{ providerModelId }}\\\",\\n    arguments={\\n        \\\"prompt\\\": {{ inputs.asObj.inputs }},\\n    },\\n)\\n{% endif %} \\nprint(result)\\n{% endif %} \"\n        },\n        \"huggingface_hub\": {\n            \"basic\": \"result = client.{{ methodName }}(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n)\",\n            \"basicAudio\": \"output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\\\"{{ model.id }}\\\")\",\n            \"basicImage\": \"output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\\\"{{ model.id }}\\\")\",\n            \"conversational\": \"completion = client.chat.completions.create(\\n    model=\\\"{{ model.id }}\\\",\\n{{ inputs.asPythonString }}\\n)\\n\\nprint(completion.choices[0].message) \",\n            \"conversationalStream\": \"stream = client.chat.completions.create(\\n    model=\\\"{{ model.id }}\\\",\\n{{ inputs.asPythonString }}\\n    stream=True,\\n)\\n\\nfor chunk in stream:\\n    print(chunk.choices[0].delta.content, end=\\\"\\\") \",\n            \"documentQuestionAnswering\": \"output = client.document_question_answering(\\n    \\\"{{ inputs.asObj.image }}\\\",\\n    question=\\\"{{ inputs.asObj.question }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"imageToImage\": \"with open(\\\"{{ inputs.asObj.inputs }}\\\", \\\"rb\\\") as image_file:\\n   input_image = image_file.read()\\n\\n# output is a PIL.Image object\\nimage = client.image_to_image(\\n    input_image,\\n    prompt=\\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n)\\n\",\n            \"imageToVideo\": \"with open(\\\"{{ inputs.asObj.inputs }}\\\", \\\"rb\\\") as image_file:\\n   input_image = image_file.read()\\n\\nvideo = client.image_to_video(\\n    input_image,\\n    prompt=\\\"{{ inputs.asObj.parameters.prompt }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \\n\",\n            \"importInferenceClient\": \"from huggingface_hub import InferenceClient\\n\\nclient = InferenceClient(\\n{% if endpointUrl %}\\n    base_url=\\\"{{ baseUrl }}\\\",\\n{% endif %}\\n    provider=\\\"{{ provider }}\\\",\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    bill_to=\\\"{{ billTo }}\\\",\\n{% endif %}\\n)\",\n            \"questionAnswering\": \"answer = client.question_answering(\\n    question=\\\"{{ inputs.asObj.question }}\\\",\\n    context=\\\"{{ inputs.asObj.context }}\\\",\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"tableQuestionAnswering\": \"answer = client.table_question_answering(\\n    query=\\\"{{ inputs.asObj.query }}\\\",\\n    table={{ inputs.asObj.table }},\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"textToImage\": \"# output is a PIL.Image object\\nimage = client.text_to_image(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \",\n            \"textToSpeech\": \"# audio is returned as bytes\\naudio = client.text_to_speech(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \\n\",\n            \"textToVideo\": \"video = client.text_to_video(\\n    {{ inputs.asObj.inputs }},\\n    model=\\\"{{ model.id }}\\\",\\n) \"\n        },\n        \"openai\": {\n            \"conversational\": \"from openai import OpenAI\\n\\nclient = OpenAI(\\n    base_url=\\\"{{ baseUrl }}\\\",\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    default_headers={\\n        \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n    }\\n{% endif %}\\n)\\n\\ncompletion = client.chat.completions.create(\\n    model=\\\"{{ providerModelId }}\\\",\\n{{ inputs.asPythonString }}\\n)\\n\\nprint(completion.choices[0].message) \",\n            \"conversationalStream\": \"from openai import OpenAI\\n\\nclient = OpenAI(\\n    base_url=\\\"{{ baseUrl }}\\\",\\n    api_key=\\\"{{ accessToken }}\\\",\\n{% if billTo %}\\n    default_headers={\\n        \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n    }\\n{% endif %}\\n)\\n\\nstream = client.chat.completions.create(\\n    model=\\\"{{ providerModelId }}\\\",\\n{{ inputs.asPythonString }}\\n    stream=True,\\n)\\n\\nfor chunk in stream:\\n    print(chunk.choices[0].delta.content, end=\\\"\\\")\"\n        },\n        \"requests\": {\n            \"basic\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n}) \",\n            \"basicAudio\": \"def query(filename):\\n    with open(filename, \\\"rb\\\") as f:\\n        data = f.read()\\n    response = requests.post(API_URL, headers={\\\"Content-Type\\\": \\\"audio/flac\\\", **headers}, data=data)\\n    return response.json()\\n\\noutput = query({{ providerInputs.asObj.inputs }})\",\n            \"basicImage\": \"def query(filename):\\n    with open(filename, \\\"rb\\\") as f:\\n        data = f.read()\\n    response = requests.post(API_URL, headers={\\\"Content-Type\\\": \\\"image/jpeg\\\", **headers}, data=data)\\n    return response.json()\\n\\noutput = query({{ providerInputs.asObj.inputs }})\",\n            \"conversational\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\nresponse = query({\\n{{ autoInputs.asJsonString }}\\n})\\n\\nprint(response[\\\"choices\\\"][0][\\\"message\\\"])\",\n            \"conversationalStream\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload, stream=True)\\n    for line in response.iter_lines():\\n        if not line.startswith(b\\\"data:\\\"):\\n            continue\\n        if line.strip() == b\\\"data: [DONE]\\\":\\n            return\\n        yield json.loads(line.decode(\\\"utf-8\\\").lstrip(\\\"data:\\\").rstrip(\\\"/n\\\"))\\n\\nchunks = query({\\n{{ autoInputs.asJsonString }},\\n    \\\"stream\\\": True,\\n})\\n\\nfor chunk in chunks:\\n    print(chunk[\\\"choices\\\"][0][\\\"delta\\\"][\\\"content\\\"], end=\\\"\\\")\",\n            \"documentQuestionAnswering\": \"def query(payload):\\n    with open(payload[\\\"image\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"image\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {\\n        \\\"image\\\": \\\"{{ inputs.asObj.image }}\\\",\\n        \\\"question\\\": \\\"{{ inputs.asObj.question }}\\\",\\n    },\\n}) \",\n            \"imageToImage\": \"\\ndef query(payload):\\n    with open(payload[\\\"inputs\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"inputs\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nimage_bytes = query({\\n{{ providerInputs.asJsonString }}\\n})\\n\\n# You can access the image with PIL.Image for example\\nimport io\\nfrom PIL import Image\\nimage = Image.open(io.BytesIO(image_bytes)) \",\n            \"imageToVideo\": \"\\ndef query(payload):\\n    with open(payload[\\\"inputs\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n        payload[\\\"inputs\\\"] = base64.b64encode(img).decode(\\\"utf-8\\\")\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nvideo_bytes = query({\\n{{ inputs.asJsonString }}\\n})\\n\",\n            \"importRequests\": \"{% if importBase64 %}\\nimport base64\\n{% endif %}\\n{% if importJson %}\\nimport json\\n{% endif %}\\nimport requests\\n\\nAPI_URL = \\\"{{ fullUrl }}\\\"\\nheaders = {\\n    \\\"Authorization\\\": \\\"{{ authorizationHeader }}\\\",\\n{% if billTo %}\\n    \\\"X-HF-Bill-To\\\": \\\"{{ billTo }}\\\"\\n{% endif %}\\n}\",\n            \"tabular\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nresponse = query({\\n    \\\"inputs\\\": {\\n        \\\"data\\\": {{ providerInputs.asObj.inputs }}\\n    },\\n}) \",\n            \"textToAudio\": \"{% if model.library_name == \\\"transformers\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\naudio_bytes = query({\\n    \\\"inputs\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio_bytes)\\n{% else %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\naudio, sampling_rate = query({\\n    \\\"inputs\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio, rate=sampling_rate)\\n{% endif %} \",\n            \"textToImage\": \"{% if provider == \\\"hf-inference\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\nimage_bytes = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n})\\n\\n# You can access the image with PIL.Image for example\\nimport io\\nfrom PIL import Image\\nimage = Image.open(io.BytesIO(image_bytes))\\n{% endif %}\",\n            \"textToSpeech\": \"{% if model.library_name == \\\"transformers\\\" %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.content\\n\\naudio_bytes = query({\\n    \\\"text\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio_bytes)\\n{% else %}\\ndef query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\naudio, sampling_rate = query({\\n    \\\"text\\\": {{ inputs.asObj.inputs }},\\n})\\n# You can access the audio with IPython.display for example\\nfrom IPython.display import Audio\\nAudio(audio, rate=sampling_rate)\\n{% endif %} \",\n            \"zeroShotClassification\": \"def query(payload):\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"inputs\\\": {{ providerInputs.asObj.inputs }},\\n    \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"]},\\n}) \",\n            \"zeroShotImageClassification\": \"def query(data):\\n    with open(data[\\\"image_path\\\"], \\\"rb\\\") as f:\\n        img = f.read()\\n    payload={\\n        \\\"parameters\\\": data[\\\"parameters\\\"],\\n        \\\"inputs\\\": base64.b64encode(img).decode(\\\"utf-8\\\")\\n    }\\n    response = requests.post(API_URL, headers=headers, json=payload)\\n    return response.json()\\n\\noutput = query({\\n    \\\"image_path\\\": {{ providerInputs.asObj.inputs }},\\n    \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"cat\\\", \\\"dog\\\", \\\"llama\\\"]},\\n}) \"\n        }\n    },\n    \"sh\": {\n        \"curl\": {\n            \"basic\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ providerInputs.asCurlString }}\\n    }'\",\n            \"basicAudio\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: audio/flac' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    --data-binary @{{ providerInputs.asObj.inputs }}\",\n            \"basicImage\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: image/jpeg' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    --data-binary @{{ providerInputs.asObj.inputs }}\",\n            \"conversational\": \"curl {{ fullUrl }} \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ autoInputs.asCurlString }},\\n        \\\"stream\\\": false\\n    }'\",\n            \"conversationalStream\": \"curl {{ fullUrl }} \\\\\\n    -H 'Authorization: {{ authorizationHeader }}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n{% if billTo %}\\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\\\\n{% endif %}\\n    -d '{\\n{{ autoInputs.asCurlString }},\\n        \\\"stream\\\": true\\n    }'\",\n            \"zeroShotClassification\": \"curl {{ fullUrl }} \\\\\\n    -X POST \\\\\\n    -d '{\\\"inputs\\\": {{ providerInputs.asObj.inputs }}, \\\"parameters\\\": {\\\"candidate_labels\\\": [\\\"refund\\\", \\\"legal\\\", \\\"faq\\\"]}}' \\\\\\n    -H 'Content-Type: application/json' \\\\\\n    -H 'Authorization: {{ authorizationHeader }}'\\n{% if billTo %} \\\\\\n    -H 'X-HF-Bill-To: {{ billTo }}'\\n{% endif %}\"\n        }\n    }\n};\n"],"names":[],"mappings":"AAAA,wCAAwC;;;;;AACjC,MAAM,YAAY;IACrB,MAAM;QACF,SAAS;YACL,SAAS;YACT,cAAc;YACd,cAAc;YACd,kBAAkB;YAClB,gBAAgB;YAChB,gBAAgB;YAChB,eAAe;YACf,eAAe;YACf,gBAAgB;YAChB,0BAA0B;QAC9B;QACA,kBAAkB;YACd,SAAS;YACT,cAAc;YACd,cAAc;YACd,kBAAkB;YAClB,wBAAwB;YACxB,gBAAgB;YAChB,gBAAgB;YAChB,eAAe;YACf,gBAAgB;YAChB,eAAe;QACnB;QACA,UAAU;YACN,kBAAkB;YAClB,wBAAwB;QAC5B;IACJ;IACA,UAAU;QACN,cAAc;YACV,gBAAgB;YAChB,gBAAgB;YAChB,eAAe;QACnB;QACA,mBAAmB;YACf,SAAS;YACT,cAAc;YACd,cAAc;YACd,kBAAkB;YAClB,wBAAwB;YACxB,6BAA6B;YAC7B,gBAAgB;YAChB,gBAAgB;YAChB,yBAAyB;YACzB,qBAAqB;YACrB,0BAA0B;YAC1B,eAAe;YACf,gBAAgB;YAChB,eAAe;QACnB;QACA,UAAU;YACN,kBAAkB;YAClB,wBAAwB;QAC5B;QACA,YAAY;YACR,SAAS;YACT,cAAc;YACd,cAAc;YACd,kBAAkB;YAClB,wBAAwB;YACxB,6BAA6B;YAC7B,gBAAgB;YAChB,gBAAgB;YAChB,kBAAkB;YAClB,WAAW;YACX,eAAe;YACf,eAAe;YACf,gBAAgB;YAChB,0BAA0B;YAC1B,+BAA+B;QACnC;IACJ;IACA,MAAM;QACF,QAAQ;YACJ,SAAS;YACT,cAAc;YACd,cAAc;YACd,kBAAkB;YAClB,wBAAwB;YACxB,0BAA0B;QAC9B;IACJ;AACJ","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 4737, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/snippets/getInferenceSnippets.js"],"sourcesContent":["import { Template } from \"@huggingface/jinja\";\nimport { getModelInputSnippet, inferenceSnippetLanguages, } from \"@huggingface/tasks\";\nimport { getProviderHelper } from \"../lib/getProviderHelper.js\";\nimport { makeRequestOptionsFromResolvedModel } from \"../lib/makeRequestOptions.js\";\nimport { templates } from \"./templates.exported.js\";\nimport { getLogger } from \"../lib/logger.js\";\nimport { HF_ROUTER_AUTO_ENDPOINT } from \"../config.js\";\nconst PYTHON_CLIENTS = [\"huggingface_hub\", \"fal_client\", \"requests\", \"openai\"];\nconst JS_CLIENTS = [\"fetch\", \"huggingface.js\", \"openai\"];\nconst SH_CLIENTS = [\"curl\"];\nconst CLIENTS = {\n    js: [...JS_CLIENTS],\n    python: [...PYTHON_CLIENTS],\n    sh: [...SH_CLIENTS],\n};\n// The \"auto\"-provider policy is only available through the HF SDKs (huggingface.js / huggingface_hub)\n// except for conversational tasks for which we have https://router.huggingface.co/v1/chat/completions\nconst CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY = {\n    js: [\"huggingface.js\"],\n    python: [\"huggingface_hub\"],\n};\n// Helpers to find + load templates\nconst hasTemplate = (language, client, templateName) => templates[language]?.[client]?.[templateName] !== undefined;\nconst loadTemplate = (language, client, templateName) => {\n    const template = templates[language]?.[client]?.[templateName];\n    if (!template) {\n        throw new Error(`Template not found: ${language}/${client}/${templateName}`);\n    }\n    return (data) => new Template(template).render({ ...data });\n};\nconst snippetImportPythonInferenceClient = loadTemplate(\"python\", \"huggingface_hub\", \"importInferenceClient\");\nconst snippetImportRequests = loadTemplate(\"python\", \"requests\", \"importRequests\");\n// Needed for huggingface_hub basic snippets\nconst HF_PYTHON_METHODS = {\n    \"audio-classification\": \"audio_classification\",\n    \"audio-to-audio\": \"audio_to_audio\",\n    \"automatic-speech-recognition\": \"automatic_speech_recognition\",\n    \"document-question-answering\": \"document_question_answering\",\n    \"feature-extraction\": \"feature_extraction\",\n    \"fill-mask\": \"fill_mask\",\n    \"image-classification\": \"image_classification\",\n    \"image-segmentation\": \"image_segmentation\",\n    \"image-to-image\": \"image_to_image\",\n    \"image-to-text\": \"image_to_text\",\n    \"object-detection\": \"object_detection\",\n    \"question-answering\": \"question_answering\",\n    \"sentence-similarity\": \"sentence_similarity\",\n    summarization: \"summarization\",\n    \"table-question-answering\": \"table_question_answering\",\n    \"tabular-classification\": \"tabular_classification\",\n    \"tabular-regression\": \"tabular_regression\",\n    \"text-classification\": \"text_classification\",\n    \"text-generation\": \"text_generation\",\n    \"text-to-image\": \"text_to_image\",\n    \"text-to-speech\": \"text_to_speech\",\n    \"text-to-video\": \"text_to_video\",\n    \"token-classification\": \"token_classification\",\n    translation: \"translation\",\n    \"visual-question-answering\": \"visual_question_answering\",\n    \"zero-shot-classification\": \"zero_shot_classification\",\n    \"zero-shot-image-classification\": \"zero_shot_image_classification\",\n};\n// Needed for huggingface.js basic snippets\nconst HF_JS_METHODS = {\n    \"automatic-speech-recognition\": \"automaticSpeechRecognition\",\n    \"feature-extraction\": \"featureExtraction\",\n    \"fill-mask\": \"fillMask\",\n    \"image-classification\": \"imageClassification\",\n    \"question-answering\": \"questionAnswering\",\n    \"sentence-similarity\": \"sentenceSimilarity\",\n    summarization: \"summarization\",\n    \"table-question-answering\": \"tableQuestionAnswering\",\n    \"text-classification\": \"textClassification\",\n    \"text-generation\": \"textGeneration\",\n    \"token-classification\": \"tokenClassification\",\n    \"text-to-speech\": \"textToSpeech\",\n    translation: \"translation\",\n};\n// Placeholders to replace with env variable in snippets\n// little hack to support both direct requests and routing => routed requests should start with \"hf_\"\nconst ACCESS_TOKEN_ROUTING_PLACEHOLDER = \"hf_token_placeholder\";\nconst ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER = \"not_hf_token_placeholder\";\n// Snippet generators\nconst snippetGenerator = (templateName, inputPreparationFn) => {\n    return (model, provider, inferenceProviderMapping, opts) => {\n        const logger = getLogger();\n        const providerModelId = inferenceProviderMapping?.providerId ?? model.id;\n        /// Hacky: hard-code conversational templates here\n        let task = model.pipeline_tag;\n        if (model.pipeline_tag &&\n            [\"text-generation\", \"image-text-to-text\"].includes(model.pipeline_tag) &&\n            model.tags.includes(\"conversational\")) {\n            templateName = opts?.streaming ? \"conversationalStream\" : \"conversational\";\n            inputPreparationFn = prepareConversationalInput;\n            task = \"conversational\";\n        }\n        let providerHelper;\n        try {\n            providerHelper = getProviderHelper(provider, task);\n        }\n        catch (e) {\n            logger.error(`Failed to get provider helper for ${provider} (${task})`, e);\n            return [];\n        }\n        const placeholder = opts?.directRequest\n            ? ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER\n            : ACCESS_TOKEN_ROUTING_PLACEHOLDER;\n        const accessTokenOrPlaceholder = opts?.accessToken ?? placeholder;\n        /// Prepare inputs + make request\n        const inputs = opts?.inputs\n            ? { inputs: opts.inputs }\n            : inputPreparationFn\n                ? inputPreparationFn(model, opts)\n                : { inputs: getModelInputSnippet(model) };\n        const request = makeRequestOptionsFromResolvedModel(providerModelId, providerHelper, {\n            accessToken: accessTokenOrPlaceholder,\n            provider,\n            endpointUrl: opts?.endpointUrl ?? (provider === \"auto\" ? HF_ROUTER_AUTO_ENDPOINT : undefined),\n            ...inputs,\n        }, inferenceProviderMapping, {\n            task,\n            billTo: opts?.billTo,\n        });\n        /// Parse request.info.body if not a binary.\n        /// This is the body sent to the provider. Important for snippets with raw payload (e.g curl, requests, etc.)\n        let providerInputs = inputs;\n        const bodyAsObj = request.info.body;\n        if (typeof bodyAsObj === \"string\") {\n            try {\n                providerInputs = JSON.parse(bodyAsObj);\n            }\n            catch (e) {\n                logger.error(\"Failed to parse body as JSON\", e);\n            }\n        }\n        // Inputs for the \"auto\" route is strictly the same as \"inputs\", except the model includes the provider\n        // If not \"auto\" route, use the providerInputs\n        const autoInputs = !opts?.endpointUrl && !opts?.directRequest\n            ? provider !== \"auto\"\n                ? {\n                    ...inputs,\n                    model: `${model.id}:${provider}`,\n                }\n                : {\n                    ...inputs,\n                    model: `${model.id}`, // if no :provider => auto\n                }\n            : providerInputs;\n        /// Prepare template injection data\n        const params = {\n            accessToken: accessTokenOrPlaceholder,\n            authorizationHeader: request.info.headers?.Authorization,\n            baseUrl: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? HF_ROUTER_AUTO_ENDPOINT\n                : removeSuffix(request.url, \"/chat/completions\"),\n            fullUrl: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? HF_ROUTER_AUTO_ENDPOINT + \"/chat/completions\"\n                : request.url,\n            inputs: {\n                asObj: inputs,\n                asCurlString: formatBody(inputs, \"curl\"),\n                asJsonString: formatBody(inputs, \"json\"),\n                asPythonString: formatBody(inputs, \"python\"),\n                asTsString: formatBody(inputs, \"ts\"),\n            },\n            providerInputs: {\n                asObj: providerInputs,\n                asCurlString: formatBody(providerInputs, \"curl\"),\n                asJsonString: formatBody(providerInputs, \"json\"),\n                asPythonString: formatBody(providerInputs, \"python\"),\n                asTsString: formatBody(providerInputs, \"ts\"),\n            },\n            autoInputs: {\n                asObj: autoInputs,\n                asCurlString: formatBody(autoInputs, \"curl\"),\n                asJsonString: formatBody(autoInputs, \"json\"),\n                asPythonString: formatBody(autoInputs, \"python\"),\n                asTsString: formatBody(autoInputs, \"ts\"),\n            },\n            model,\n            provider,\n            providerModelId: task === \"conversational\" && !opts?.endpointUrl && !opts?.directRequest\n                ? provider !== \"auto\"\n                    ? `${model.id}:${provider}` // e.g. \"moonshotai/Kimi-K2-Instruct:groq\"\n                    : model.id\n                : providerModelId ?? model.id,\n            billTo: opts?.billTo,\n            endpointUrl: opts?.endpointUrl,\n        };\n        /// Iterate over clients => check if a snippet exists => generate\n        const clients = provider === \"auto\" && task !== \"conversational\" ? CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY : CLIENTS;\n        return inferenceSnippetLanguages\n            .map((language) => {\n            const langClients = clients[language] ?? [];\n            return langClients\n                .map((client) => {\n                if (!hasTemplate(language, client, templateName)) {\n                    return;\n                }\n                const template = loadTemplate(language, client, templateName);\n                if (client === \"huggingface_hub\" && templateName.includes(\"basic\")) {\n                    if (!(model.pipeline_tag && model.pipeline_tag in HF_PYTHON_METHODS)) {\n                        return;\n                    }\n                    params[\"methodName\"] = HF_PYTHON_METHODS[model.pipeline_tag];\n                }\n                if (client === \"huggingface.js\" && templateName.includes(\"basic\")) {\n                    if (!(model.pipeline_tag && model.pipeline_tag in HF_JS_METHODS)) {\n                        return;\n                    }\n                    params[\"methodName\"] = HF_JS_METHODS[model.pipeline_tag];\n                }\n                /// Generate snippet\n                let snippet = template(params).trim();\n                if (!snippet) {\n                    return;\n                }\n                /// Add import section separately\n                if (client === \"huggingface_hub\") {\n                    const importSection = snippetImportPythonInferenceClient({ ...params });\n                    snippet = `${importSection}\\n\\n${snippet}`;\n                }\n                else if (client === \"requests\") {\n                    const importSection = snippetImportRequests({\n                        ...params,\n                        importBase64: snippet.includes(\"base64\"),\n                        importJson: snippet.includes(\"json.\"),\n                    });\n                    snippet = `${importSection}\\n\\n${snippet}`;\n                }\n                /// Replace access token placeholder\n                if (snippet.includes(placeholder)) {\n                    snippet = replaceAccessTokenPlaceholder(opts?.directRequest, placeholder, snippet, language, provider, opts?.endpointUrl);\n                }\n                /// Snippet is ready!\n                return { language, client: client, content: snippet };\n            })\n                .filter((snippet) => snippet !== undefined);\n        })\n            .flat();\n    };\n};\nconst prepareDocumentQuestionAnsweringInput = (model) => {\n    return JSON.parse(getModelInputSnippet(model));\n};\nconst prepareImageToImageInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { inputs: data.image, parameters: { prompt: data.prompt } };\n};\nconst prepareConversationalInput = (model, opts) => {\n    return {\n        messages: opts?.messages ?? getModelInputSnippet(model),\n        ...(opts?.temperature ? { temperature: opts?.temperature } : undefined),\n        ...(opts?.max_tokens ? { max_tokens: opts?.max_tokens } : undefined),\n        ...(opts?.top_p ? { top_p: opts?.top_p } : undefined),\n    };\n};\nconst prepareQuestionAnsweringInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { question: data.question, context: data.context };\n};\nconst prepareTableQuestionAnsweringInput = (model) => {\n    const data = JSON.parse(getModelInputSnippet(model));\n    return { query: data.query, table: JSON.stringify(data.table) };\n};\nconst snippets = {\n    \"audio-classification\": snippetGenerator(\"basicAudio\"),\n    \"audio-to-audio\": snippetGenerator(\"basicAudio\"),\n    \"automatic-speech-recognition\": snippetGenerator(\"basicAudio\"),\n    \"document-question-answering\": snippetGenerator(\"documentQuestionAnswering\", prepareDocumentQuestionAnsweringInput),\n    \"feature-extraction\": snippetGenerator(\"basic\"),\n    \"fill-mask\": snippetGenerator(\"basic\"),\n    \"image-classification\": snippetGenerator(\"basicImage\"),\n    \"image-segmentation\": snippetGenerator(\"basicImage\"),\n    \"image-text-to-text\": snippetGenerator(\"conversational\"),\n    \"image-to-image\": snippetGenerator(\"imageToImage\", prepareImageToImageInput),\n    \"image-to-text\": snippetGenerator(\"basicImage\"),\n    \"image-to-video\": snippetGenerator(\"imageToVideo\", prepareImageToImageInput),\n    \"object-detection\": snippetGenerator(\"basicImage\"),\n    \"question-answering\": snippetGenerator(\"questionAnswering\", prepareQuestionAnsweringInput),\n    \"sentence-similarity\": snippetGenerator(\"basic\"),\n    summarization: snippetGenerator(\"basic\"),\n    \"tabular-classification\": snippetGenerator(\"tabular\"),\n    \"tabular-regression\": snippetGenerator(\"tabular\"),\n    \"table-question-answering\": snippetGenerator(\"tableQuestionAnswering\", prepareTableQuestionAnsweringInput),\n    \"text-classification\": snippetGenerator(\"basic\"),\n    \"text-generation\": snippetGenerator(\"basic\"),\n    \"text-to-audio\": snippetGenerator(\"textToAudio\"),\n    \"text-to-image\": snippetGenerator(\"textToImage\"),\n    \"text-to-speech\": snippetGenerator(\"textToSpeech\"),\n    \"text-to-video\": snippetGenerator(\"textToVideo\"),\n    \"token-classification\": snippetGenerator(\"basic\"),\n    translation: snippetGenerator(\"basic\"),\n    \"zero-shot-classification\": snippetGenerator(\"zeroShotClassification\"),\n    \"zero-shot-image-classification\": snippetGenerator(\"zeroShotImageClassification\"),\n};\nexport function getInferenceSnippets(model, provider, inferenceProviderMapping, opts) {\n    return model.pipeline_tag && model.pipeline_tag in snippets\n        ? snippets[model.pipeline_tag]?.(model, provider, inferenceProviderMapping, opts) ?? []\n        : [];\n}\n// String manipulation helpers\nfunction formatBody(obj, format) {\n    switch (format) {\n        case \"curl\":\n            return indentString(formatBody(obj, \"json\"));\n        case \"json\":\n            /// Hacky: remove outer brackets to make is extendable in templates\n            return JSON.stringify(obj, null, 4).split(\"\\n\").slice(1, -1).join(\"\\n\");\n        case \"python\":\n            return indentString(Object.entries(obj)\n                .map(([key, value]) => {\n                const formattedValue = JSON.stringify(value, null, 4).replace(/\"/g, '\"');\n                return `${key}=${formattedValue},`;\n            })\n                .join(\"\\n\"));\n        case \"ts\":\n            /// Hacky: remove outer brackets to make is extendable in templates\n            return formatTsObject(obj).split(\"\\n\").slice(1, -1).join(\"\\n\");\n        default:\n            throw new Error(`Unsupported format: ${format}`);\n    }\n}\nfunction formatTsObject(obj, depth) {\n    depth = depth ?? 0;\n    /// Case int, boolean, string, etc.\n    if (typeof obj !== \"object\" || obj === null) {\n        return JSON.stringify(obj);\n    }\n    /// Case array\n    if (Array.isArray(obj)) {\n        const items = obj\n            .map((item) => {\n            const formatted = formatTsObject(item, depth + 1);\n            return `${\" \".repeat(4 * (depth + 1))}${formatted},`;\n        })\n            .join(\"\\n\");\n        return `[\\n${items}\\n${\" \".repeat(4 * depth)}]`;\n    }\n    /// Case mapping\n    const entries = Object.entries(obj);\n    const lines = entries\n        .map(([key, value]) => {\n        const formattedValue = formatTsObject(value, depth + 1);\n        const keyStr = /^[a-zA-Z_$][a-zA-Z0-9_$]*$/.test(key) ? key : `\"${key}\"`;\n        return `${\" \".repeat(4 * (depth + 1))}${keyStr}: ${formattedValue},`;\n    })\n        .join(\"\\n\");\n    return `{\\n${lines}\\n${\" \".repeat(4 * depth)}}`;\n}\nfunction indentString(str) {\n    return str\n        .split(\"\\n\")\n        .map((line) => \" \".repeat(4) + line)\n        .join(\"\\n\");\n}\nfunction removeSuffix(str, suffix) {\n    return str.endsWith(suffix) ? str.slice(0, -suffix.length) : str;\n}\nfunction replaceAccessTokenPlaceholder(directRequest, placeholder, snippet, language, provider, endpointUrl) {\n    // If \"opts.accessToken\" is not set, the snippets are generated with a placeholder.\n    // Once snippets are rendered, we replace the placeholder with code to fetch the access token from an environment variable.\n    // Determine if HF_TOKEN or specific provider token should be used\n    const useHfToken = !endpointUrl && // custom endpointUrl => use a generic API_TOKEN\n        (provider == \"hf-inference\" || // hf-inference provider => use $HF_TOKEN\n            (!directRequest && // if explicit directRequest => use provider-specific token\n                (snippet.includes(\"InferenceClient\") || // using a client => use $HF_TOKEN\n                    snippet.includes(\"https://router.huggingface.co\")))); // explicit routed request => use $HF_TOKEN\n    const accessTokenEnvVar = useHfToken\n        ? \"HF_TOKEN\" // e.g. routed request or hf-inference\n        : endpointUrl\n            ? \"API_TOKEN\"\n            : provider.toUpperCase().replace(\"-\", \"_\") + \"_API_KEY\"; // e.g. \"REPLICATE_API_KEY\"\n    // Replace the placeholder with the env variable\n    if (language === \"sh\") {\n        snippet = snippet.replace(`'Authorization: Bearer ${placeholder}'`, `\"Authorization: Bearer $${accessTokenEnvVar}\"` // e.g. \"Authorization: Bearer $HF_TOKEN\"\n        );\n    }\n    else if (language === \"python\") {\n        snippet = \"import os\\n\" + snippet;\n        snippet = snippet.replace(`\"${placeholder}\"`, `os.environ[\"${accessTokenEnvVar}\"]` // e.g. os.environ[\"HF_TOKEN\")\n        );\n        snippet = snippet.replace(`\"Bearer ${placeholder}\"`, `f\"Bearer {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"Bearer {os.environ['HF_TOKEN']}\"\n        );\n        snippet = snippet.replace(`\"Key ${placeholder}\"`, `f\"Key {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"Key {os.environ['FAL_AI_API_KEY']}\"\n        );\n        snippet = snippet.replace(`\"X-Key ${placeholder}\"`, `f\"X-Key {os.environ['${accessTokenEnvVar}']}\"` // e.g. f\"X-Key {os.environ['BLACK_FOREST_LABS_API_KEY']}\"\n        );\n    }\n    else if (language === \"js\") {\n        snippet = snippet.replace(`\"${placeholder}\"`, `process.env.${accessTokenEnvVar}` // e.g. process.env.HF_TOKEN\n        );\n        snippet = snippet.replace(`Authorization: \"Bearer ${placeholder}\",`, `Authorization: \\`Bearer $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `Bearer ${process.env.HF_TOKEN}`,\n        );\n        snippet = snippet.replace(`Authorization: \"Key ${placeholder}\",`, `Authorization: \\`Key $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `Key ${process.env.FAL_AI_API_KEY}`,\n        );\n        snippet = snippet.replace(`Authorization: \"X-Key ${placeholder}\",`, `Authorization: \\`X-Key $\\{process.env.${accessTokenEnvVar}}\\`,` // e.g. Authorization: `X-Key ${process.env.BLACK_FOREST_LABS_AI_API_KEY}`,\n        );\n    }\n    return snippet;\n}\n"],"names":[],"mappings":";;;;AAAA;AACA;AAAA;AAAA;AACA;AACA;AACA;AACA;AACA;;;;;;;;AACA,MAAM,iBAAiB;IAAC;IAAmB;IAAc;IAAY;CAAS;AAC9E,MAAM,aAAa;IAAC;IAAS;IAAkB;CAAS;AACxD,MAAM,aAAa;IAAC;CAAO;AAC3B,MAAM,UAAU;IACZ,IAAI;WAAI;KAAW;IACnB,QAAQ;WAAI;KAAe;IAC3B,IAAI;WAAI;KAAW;AACvB;AACA,sGAAsG;AACtG,sGAAsG;AACtG,MAAM,yCAAyC;IAC3C,IAAI;QAAC;KAAiB;IACtB,QAAQ;QAAC;KAAkB;AAC/B;AACA,mCAAmC;AACnC,MAAM,cAAc,CAAC,UAAU,QAAQ,eAAiB,6MAAS,CAAC,SAAS,EAAE,CAAC,OAAO,EAAE,CAAC,aAAa,KAAK;AAC1G,MAAM,eAAe,CAAC,UAAU,QAAQ;IACpC,MAAM,WAAW,6MAAS,CAAC,SAAS,EAAE,CAAC,OAAO,EAAE,CAAC,aAAa;IAC9D,IAAI,CAAC,UAAU;QACX,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,SAAS,CAAC,EAAE,OAAO,CAAC,EAAE,cAAc;IAC/E;IACA,OAAO,CAAC,OAAS,IAAI,qKAAQ,CAAC,UAAU,MAAM,CAAC;YAAE,GAAG,IAAI;QAAC;AAC7D;AACA,MAAM,qCAAqC,aAAa,UAAU,mBAAmB;AACrF,MAAM,wBAAwB,aAAa,UAAU,YAAY;AACjE,4CAA4C;AAC5C,MAAM,oBAAoB;IACtB,wBAAwB;IACxB,kBAAkB;IAClB,gCAAgC;IAChC,+BAA+B;IAC/B,sBAAsB;IACtB,aAAa;IACb,wBAAwB;IACxB,sBAAsB;IACtB,kBAAkB;IAClB,iBAAiB;IACjB,oBAAoB;IACpB,sBAAsB;IACtB,uBAAuB;IACvB,eAAe;IACf,4BAA4B;IAC5B,0BAA0B;IAC1B,sBAAsB;IACtB,uBAAuB;IACvB,mBAAmB;IACnB,iBAAiB;IACjB,kBAAkB;IAClB,iBAAiB;IACjB,wBAAwB;IACxB,aAAa;IACb,6BAA6B;IAC7B,4BAA4B;IAC5B,kCAAkC;AACtC;AACA,2CAA2C;AAC3C,MAAM,gBAAgB;IAClB,gCAAgC;IAChC,sBAAsB;IACtB,aAAa;IACb,wBAAwB;IACxB,sBAAsB;IACtB,uBAAuB;IACvB,eAAe;IACf,4BAA4B;IAC5B,uBAAuB;IACvB,mBAAmB;IACnB,wBAAwB;IACxB,kBAAkB;IAClB,aAAa;AACjB;AACA,wDAAwD;AACxD,qGAAqG;AACrG,MAAM,mCAAmC;AACzC,MAAM,0CAA0C;AAChD,qBAAqB;AACrB,MAAM,mBAAmB,CAAC,cAAc;IACpC,OAAO,CAAC,OAAO,UAAU,0BAA0B;QAC/C,MAAM,SAAS,IAAA,yLAAS;QACxB,MAAM,kBAAkB,0BAA0B,cAAc,MAAM,EAAE;QACxE,kDAAkD;QAClD,IAAI,OAAO,MAAM,YAAY;QAC7B,IAAI,MAAM,YAAY,IAClB;YAAC;YAAmB;SAAqB,CAAC,QAAQ,CAAC,MAAM,YAAY,KACrE,MAAM,IAAI,CAAC,QAAQ,CAAC,mBAAmB;YACvC,eAAe,MAAM,YAAY,yBAAyB;YAC1D,qBAAqB;YACrB,OAAO;QACX;QACA,IAAI;QACJ,IAAI;YACA,iBAAiB,IAAA,4MAAiB,EAAC,UAAU;QACjD,EACA,OAAO,GAAG;YACN,OAAO,KAAK,CAAC,CAAC,kCAAkC,EAAE,SAAS,EAAE,EAAE,KAAK,CAAC,CAAC,EAAE;YACxE,OAAO,EAAE;QACb;QACA,MAAM,cAAc,MAAM,gBACpB,0CACA;QACN,MAAM,2BAA2B,MAAM,eAAe;QACtD,iCAAiC;QACjC,MAAM,SAAS,MAAM,SACf;YAAE,QAAQ,KAAK,MAAM;QAAC,IACtB,qBACI,mBAAmB,OAAO,QAC1B;YAAE,QAAQ,IAAA,qMAAoB,EAAC;QAAO;QAChD,MAAM,UAAU,IAAA,+NAAmC,EAAC,iBAAiB,gBAAgB;YACjF,aAAa;YACb;YACA,aAAa,MAAM,eAAe,CAAC,aAAa,SAAS,gMAAuB,GAAG,SAAS;YAC5F,GAAG,MAAM;QACb,GAAG,0BAA0B;YACzB;YACA,QAAQ,MAAM;QAClB;QACA,4CAA4C;QAC5C,6GAA6G;QAC7G,IAAI,iBAAiB;QACrB,MAAM,YAAY,QAAQ,IAAI,CAAC,IAAI;QACnC,IAAI,OAAO,cAAc,UAAU;YAC/B,IAAI;gBACA,iBAAiB,KAAK,KAAK,CAAC;YAChC,EACA,OAAO,GAAG;gBACN,OAAO,KAAK,CAAC,gCAAgC;YACjD;QACJ;QACA,uGAAuG;QACvG,8CAA8C;QAC9C,MAAM,aAAa,CAAC,MAAM,eAAe,CAAC,MAAM,gBAC1C,aAAa,SACT;YACE,GAAG,MAAM;YACT,OAAO,GAAG,MAAM,EAAE,CAAC,CAAC,EAAE,UAAU;QACpC,IACE;YACE,GAAG,MAAM;YACT,OAAO,GAAG,MAAM,EAAE,EAAE;QACxB,IACF;QACN,mCAAmC;QACnC,MAAM,SAAS;YACX,aAAa;YACb,qBAAqB,QAAQ,IAAI,CAAC,OAAO,EAAE;YAC3C,SAAS,SAAS,oBAAoB,CAAC,MAAM,eAAe,CAAC,MAAM,gBAC7D,gMAAuB,GACvB,aAAa,QAAQ,GAAG,EAAE;YAChC,SAAS,SAAS,oBAAoB,CAAC,MAAM,eAAe,CAAC,MAAM,gBAC7D,gMAAuB,GAAG,sBAC1B,QAAQ,GAAG;YACjB,QAAQ;gBACJ,OAAO;gBACP,cAAc,WAAW,QAAQ;gBACjC,cAAc,WAAW,QAAQ;gBACjC,gBAAgB,WAAW,QAAQ;gBACnC,YAAY,WAAW,QAAQ;YACnC;YACA,gBAAgB;gBACZ,OAAO;gBACP,cAAc,WAAW,gBAAgB;gBACzC,cAAc,WAAW,gBAAgB;gBACzC,gBAAgB,WAAW,gBAAgB;gBAC3C,YAAY,WAAW,gBAAgB;YAC3C;YACA,YAAY;gBACR,OAAO;gBACP,cAAc,WAAW,YAAY;gBACrC,cAAc,WAAW,YAAY;gBACrC,gBAAgB,WAAW,YAAY;gBACvC,YAAY,WAAW,YAAY;YACvC;YACA;YACA;YACA,iBAAiB,SAAS,oBAAoB,CAAC,MAAM,eAAe,CAAC,MAAM,gBACrE,aAAa,SACT,GAAG,MAAM,EAAE,CAAC,CAAC,EAAE,UAAU,CAAC,0CAA0C;eACpE,MAAM,EAAE,GACZ,mBAAmB,MAAM,EAAE;YACjC,QAAQ,MAAM;YACd,aAAa,MAAM;QACvB;QACA,iEAAiE;QACjE,MAAM,UAAU,aAAa,UAAU,SAAS,mBAAmB,yCAAyC;QAC5G,OAAO,yMAAyB,CAC3B,GAAG,CAAC,CAAC;YACN,MAAM,cAAc,OAAO,CAAC,SAAS,IAAI,EAAE;YAC3C,OAAO,YACF,GAAG,CAAC,CAAC;gBACN,IAAI,CAAC,YAAY,UAAU,QAAQ,eAAe;oBAC9C;gBACJ;gBACA,MAAM,WAAW,aAAa,UAAU,QAAQ;gBAChD,IAAI,WAAW,qBAAqB,aAAa,QAAQ,CAAC,UAAU;oBAChE,IAAI,CAAC,CAAC,MAAM,YAAY,IAAI,MAAM,YAAY,IAAI,iBAAiB,GAAG;wBAClE;oBACJ;oBACA,MAAM,CAAC,aAAa,GAAG,iBAAiB,CAAC,MAAM,YAAY,CAAC;gBAChE;gBACA,IAAI,WAAW,oBAAoB,aAAa,QAAQ,CAAC,UAAU;oBAC/D,IAAI,CAAC,CAAC,MAAM,YAAY,IAAI,MAAM,YAAY,IAAI,aAAa,GAAG;wBAC9D;oBACJ;oBACA,MAAM,CAAC,aAAa,GAAG,aAAa,CAAC,MAAM,YAAY,CAAC;gBAC5D;gBACA,oBAAoB;gBACpB,IAAI,UAAU,SAAS,QAAQ,IAAI;gBACnC,IAAI,CAAC,SAAS;oBACV;gBACJ;gBACA,iCAAiC;gBACjC,IAAI,WAAW,mBAAmB;oBAC9B,MAAM,gBAAgB,mCAAmC;wBAAE,GAAG,MAAM;oBAAC;oBACrE,UAAU,GAAG,cAAc,IAAI,EAAE,SAAS;gBAC9C,OACK,IAAI,WAAW,YAAY;oBAC5B,MAAM,gBAAgB,sBAAsB;wBACxC,GAAG,MAAM;wBACT,cAAc,QAAQ,QAAQ,CAAC;wBAC/B,YAAY,QAAQ,QAAQ,CAAC;oBACjC;oBACA,UAAU,GAAG,cAAc,IAAI,EAAE,SAAS;gBAC9C;gBACA,oCAAoC;gBACpC,IAAI,QAAQ,QAAQ,CAAC,cAAc;oBAC/B,UAAU,8BAA8B,MAAM,eAAe,aAAa,SAAS,UAAU,UAAU,MAAM;gBACjH;gBACA,qBAAqB;gBACrB,OAAO;oBAAE;oBAAU,QAAQ;oBAAQ,SAAS;gBAAQ;YACxD,GACK,MAAM,CAAC,CAAC,UAAY,YAAY;QACzC,GACK,IAAI;IACb;AACJ;AACA,MAAM,wCAAwC,CAAC;IAC3C,OAAO,KAAK,KAAK,CAAC,IAAA,qMAAoB,EAAC;AAC3C;AACA,MAAM,2BAA2B,CAAC;IAC9B,MAAM,OAAO,KAAK,KAAK,CAAC,IAAA,qMAAoB,EAAC;IAC7C,OAAO;QAAE,QAAQ,KAAK,KAAK;QAAE,YAAY;YAAE,QAAQ,KAAK,MAAM;QAAC;IAAE;AACrE;AACA,MAAM,6BAA6B,CAAC,OAAO;IACvC,OAAO;QACH,UAAU,MAAM,YAAY,IAAA,qMAAoB,EAAC;QACjD,GAAI,MAAM,cAAc;YAAE,aAAa,MAAM;QAAY,IAAI,SAAS;QACtE,GAAI,MAAM,aAAa;YAAE,YAAY,MAAM;QAAW,IAAI,SAAS;QACnE,GAAI,MAAM,QAAQ;YAAE,OAAO,MAAM;QAAM,IAAI,SAAS;IACxD;AACJ;AACA,MAAM,gCAAgC,CAAC;IACnC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAA,qMAAoB,EAAC;IAC7C,OAAO;QAAE,UAAU,KAAK,QAAQ;QAAE,SAAS,KAAK,OAAO;IAAC;AAC5D;AACA,MAAM,qCAAqC,CAAC;IACxC,MAAM,OAAO,KAAK,KAAK,CAAC,IAAA,qMAAoB,EAAC;IAC7C,OAAO;QAAE,OAAO,KAAK,KAAK;QAAE,OAAO,KAAK,SAAS,CAAC,KAAK,KAAK;IAAE;AAClE;AACA,MAAM,WAAW;IACb,wBAAwB,iBAAiB;IACzC,kBAAkB,iBAAiB;IACnC,gCAAgC,iBAAiB;IACjD,+BAA+B,iBAAiB,6BAA6B;IAC7E,sBAAsB,iBAAiB;IACvC,aAAa,iBAAiB;IAC9B,wBAAwB,iBAAiB;IACzC,sBAAsB,iBAAiB;IACvC,sBAAsB,iBAAiB;IACvC,kBAAkB,iBAAiB,gBAAgB;IACnD,iBAAiB,iBAAiB;IAClC,kBAAkB,iBAAiB,gBAAgB;IACnD,oBAAoB,iBAAiB;IACrC,sBAAsB,iBAAiB,qBAAqB;IAC5D,uBAAuB,iBAAiB;IACxC,eAAe,iBAAiB;IAChC,0BAA0B,iBAAiB;IAC3C,sBAAsB,iBAAiB;IACvC,4BAA4B,iBAAiB,0BAA0B;IACvE,uBAAuB,iBAAiB;IACxC,mBAAmB,iBAAiB;IACpC,iBAAiB,iBAAiB;IAClC,iBAAiB,iBAAiB;IAClC,kBAAkB,iBAAiB;IACnC,iBAAiB,iBAAiB;IAClC,wBAAwB,iBAAiB;IACzC,aAAa,iBAAiB;IAC9B,4BAA4B,iBAAiB;IAC7C,kCAAkC,iBAAiB;AACvD;AACO,SAAS,qBAAqB,KAAK,EAAE,QAAQ,EAAE,wBAAwB,EAAE,IAAI;IAChF,OAAO,MAAM,YAAY,IAAI,MAAM,YAAY,IAAI,WAC7C,QAAQ,CAAC,MAAM,YAAY,CAAC,GAAG,OAAO,UAAU,0BAA0B,SAAS,EAAE,GACrF,EAAE;AACZ;AACA,8BAA8B;AAC9B,SAAS,WAAW,GAAG,EAAE,MAAM;IAC3B,OAAQ;QACJ,KAAK;YACD,OAAO,aAAa,WAAW,KAAK;QACxC,KAAK;YACD,mEAAmE;YACnE,OAAO,KAAK,SAAS,CAAC,KAAK,MAAM,GAAG,KAAK,CAAC,MAAM,KAAK,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC;QACtE,KAAK;YACD,OAAO,aAAa,OAAO,OAAO,CAAC,KAC9B,GAAG,CAAC,CAAC,CAAC,KAAK,MAAM;gBAClB,MAAM,iBAAiB,KAAK,SAAS,CAAC,OAAO,MAAM,GAAG,OAAO,CAAC,MAAM;gBACpE,OAAO,GAAG,IAAI,CAAC,EAAE,eAAe,CAAC,CAAC;YACtC,GACK,IAAI,CAAC;QACd,KAAK;YACD,mEAAmE;YACnE,OAAO,eAAe,KAAK,KAAK,CAAC,MAAM,KAAK,CAAC,GAAG,CAAC,GAAG,IAAI,CAAC;QAC7D;YACI,MAAM,IAAI,MAAM,CAAC,oBAAoB,EAAE,QAAQ;IACvD;AACJ;AACA,SAAS,eAAe,GAAG,EAAE,KAAK;IAC9B,QAAQ,SAAS;IACjB,mCAAmC;IACnC,IAAI,OAAO,QAAQ,YAAY,QAAQ,MAAM;QACzC,OAAO,KAAK,SAAS,CAAC;IAC1B;IACA,cAAc;IACd,IAAI,MAAM,OAAO,CAAC,MAAM;QACpB,MAAM,QAAQ,IACT,GAAG,CAAC,CAAC;YACN,MAAM,YAAY,eAAe,MAAM,QAAQ;YAC/C,OAAO,GAAG,IAAI,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,UAAU,CAAC,CAAC;QACxD,GACK,IAAI,CAAC;QACV,OAAO,CAAC,GAAG,EAAE,MAAM,EAAE,EAAE,IAAI,MAAM,CAAC,IAAI,OAAO,CAAC,CAAC;IACnD;IACA,gBAAgB;IAChB,MAAM,UAAU,OAAO,OAAO,CAAC;IAC/B,MAAM,QAAQ,QACT,GAAG,CAAC,CAAC,CAAC,KAAK,MAAM;QAClB,MAAM,iBAAiB,eAAe,OAAO,QAAQ;QACrD,MAAM,SAAS,6BAA6B,IAAI,CAAC,OAAO,MAAM,CAAC,CAAC,EAAE,IAAI,CAAC,CAAC;QACxE,OAAO,GAAG,IAAI,MAAM,CAAC,IAAI,CAAC,QAAQ,CAAC,KAAK,OAAO,EAAE,EAAE,eAAe,CAAC,CAAC;IACxE,GACK,IAAI,CAAC;IACV,OAAO,CAAC,GAAG,EAAE,MAAM,EAAE,EAAE,IAAI,MAAM,CAAC,IAAI,OAAO,CAAC,CAAC;AACnD;AACA,SAAS,aAAa,GAAG;IACrB,OAAO,IACF,KAAK,CAAC,MACN,GAAG,CAAC,CAAC,OAAS,IAAI,MAAM,CAAC,KAAK,MAC9B,IAAI,CAAC;AACd;AACA,SAAS,aAAa,GAAG,EAAE,MAAM;IAC7B,OAAO,IAAI,QAAQ,CAAC,UAAU,IAAI,KAAK,CAAC,GAAG,CAAC,OAAO,MAAM,IAAI;AACjE;AACA,SAAS,8BAA8B,aAAa,EAAE,WAAW,EAAE,OAAO,EAAE,QAAQ,EAAE,QAAQ,EAAE,WAAW;IACvG,mFAAmF;IACnF,2HAA2H;IAC3H,kEAAkE;IAClE,MAAM,aAAa,CAAC,eAAe,gDAAgD;IAC/E,CAAC,YAAY,kBACR,CAAC,iBAAiB,2DAA2D;IAC1E,CAAC,QAAQ,QAAQ,CAAC,sBAAsB,kCAAkC;IACtE,QAAQ,QAAQ,CAAC,gCAAgC,CAAE,GAAG,2CAA2C;IACjH,MAAM,oBAAoB,aACpB,WAAW,sCAAsC;OACjD,cACI,cACA,SAAS,WAAW,GAAG,OAAO,CAAC,KAAK,OAAO,YAAY,2BAA2B;IAC5F,gDAAgD;IAChD,IAAI,aAAa,MAAM;QACnB,UAAU,QAAQ,OAAO,CAAC,CAAC,uBAAuB,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,wBAAwB,EAAE,kBAAkB,CAAC,CAAC,CAAC,yCAAyC;;IAEjK,OACK,IAAI,aAAa,UAAU;QAC5B,UAAU,gBAAgB;QAC1B,UAAU,QAAQ,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,YAAY,EAAE,kBAAkB,EAAE,CAAC,CAAC,8BAA8B;;QAEjH,UAAU,QAAQ,OAAO,CAAC,CAAC,QAAQ,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,sBAAsB,EAAE,kBAAkB,IAAI,CAAC,CAAC,0CAA0C;;QAEhJ,UAAU,QAAQ,OAAO,CAAC,CAAC,KAAK,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,mBAAmB,EAAE,kBAAkB,IAAI,CAAC,CAAC,6CAA6C;;QAE7I,UAAU,QAAQ,OAAO,CAAC,CAAC,OAAO,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,qBAAqB,EAAE,kBAAkB,IAAI,CAAC,CAAC,0DAA0D;;IAElK,OACK,IAAI,aAAa,MAAM;QACxB,UAAU,QAAQ,OAAO,CAAC,CAAC,CAAC,EAAE,YAAY,CAAC,CAAC,EAAE,CAAC,YAAY,EAAE,mBAAmB,CAAC,4BAA4B;;QAE7G,UAAU,QAAQ,OAAO,CAAC,CAAC,uBAAuB,EAAE,YAAY,EAAE,CAAC,EAAE,CAAC,uCAAuC,EAAE,kBAAkB,IAAI,CAAC,CAAC,wDAAwD;;QAE/L,UAAU,QAAQ,OAAO,CAAC,CAAC,oBAAoB,EAAE,YAAY,EAAE,CAAC,EAAE,CAAC,oCAAoC,EAAE,kBAAkB,IAAI,CAAC,CAAC,2DAA2D;;QAE5L,UAAU,QAAQ,OAAO,CAAC,CAAC,sBAAsB,EAAE,YAAY,EAAE,CAAC,EAAE,CAAC,sCAAsC,EAAE,kBAAkB,IAAI,CAAC,CAAC,2EAA2E;;IAEpN;IACA,OAAO;AACX","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 5165, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/snippets/index.js"],"sourcesContent":["export { getInferenceSnippets } from \"./getInferenceSnippets.js\";\n"],"names":[],"mappings":";AAAA","ignoreList":[0],"debugId":null}},
    {"offset": {"line": 5182, "column": 0}, "map": {"version":3,"sources":["file:///Users/nikhil/Downloads/App/node_modules/%40huggingface/inference/dist/esm/index.js"],"sourcesContent":["export { InferenceClient, InferenceClientEndpoint, HfInference } from \"./InferenceClient.js\";\nexport * from \"./errors.js\";\nexport * from \"./types.js\";\nexport * from \"./tasks/index.js\";\nimport * as snippets from \"./snippets/index.js\";\nexport * from \"./lib/getProviderHelper.js\";\nexport * from \"./lib/makeRequestOptions.js\";\nexport { setLogger } from \"./lib/logger.js\";\nexport { snippets };\n"],"names":[],"mappings":";AAAA;AACA;AACA;AACA;AACA;AAAA;AACA;AACA;AACA","ignoreList":[0],"debugId":null}}]
}