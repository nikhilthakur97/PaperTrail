module.exports = [
"[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "HF_HEADER_X_BILL_TO",
    ()=>HF_HEADER_X_BILL_TO,
    "HF_HUB_URL",
    ()=>HF_HUB_URL,
    "HF_ROUTER_AUTO_ENDPOINT",
    ()=>HF_ROUTER_AUTO_ENDPOINT,
    "HF_ROUTER_URL",
    ()=>HF_ROUTER_URL
]);
const HF_HUB_URL = "https://huggingface.co";
const HF_ROUTER_URL = "https://router.huggingface.co";
const HF_ROUTER_AUTO_ENDPOINT = `${HF_ROUTER_URL}/v1`;
const HF_HEADER_X_BILL_TO = "X-HF-Bill-To";
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/consts.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co
 * for a given Inference Provider,
 * you can add it to the following dictionary, for dev purposes.
 *
 * We also inject into this dictionary from tests.
 */ __turbopack_context__.s([
    "HARDCODED_MODEL_INFERENCE_MAPPING",
    ()=>HARDCODED_MODEL_INFERENCE_MAPPING
]);
const HARDCODED_MODEL_INFERENCE_MAPPING = {
    /**
     * "HF model ID" => "Model ID on Inference Provider's side"
     *
     * Example:
     * "Qwen/Qwen2.5-Coder-32B-Instruct": "Qwen2.5-Coder-32B-Instruct",
     */ baseten: {},
    "black-forest-labs": {},
    cerebras: {},
    cohere: {},
    "fal-ai": {},
    "featherless-ai": {},
    "fireworks-ai": {},
    groq: {},
    "hf-inference": {},
    hyperbolic: {},
    nebius: {},
    novita: {},
    nscale: {},
    openai: {},
    publicai: {},
    ovhcloud: {},
    replicate: {},
    sambanova: {},
    scaleway: {},
    together: {},
    "zai-org": {}
};
}),
"[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * Base class for all inference-related errors.
 */ __turbopack_context__.s([
    "InferenceClientError",
    ()=>InferenceClientError,
    "InferenceClientHubApiError",
    ()=>InferenceClientHubApiError,
    "InferenceClientInputError",
    ()=>InferenceClientInputError,
    "InferenceClientProviderApiError",
    ()=>InferenceClientProviderApiError,
    "InferenceClientProviderOutputError",
    ()=>InferenceClientProviderOutputError
]);
class InferenceClientError extends Error {
    constructor(message){
        super(message);
        this.name = "InferenceClientError";
    }
}
class InferenceClientInputError extends InferenceClientError {
    constructor(message){
        super(message);
        this.name = "InputError";
    }
}
class InferenceClientHttpRequestError extends InferenceClientError {
    httpRequest;
    httpResponse;
    constructor(message, httpRequest, httpResponse){
        super(message);
        this.httpRequest = {
            ...httpRequest,
            ...httpRequest.headers ? {
                headers: {
                    ...httpRequest.headers,
                    ..."Authorization" in httpRequest.headers ? {
                        Authorization: `Bearer [redacted]`
                    } : undefined
                }
            } : undefined
        };
        this.httpResponse = httpResponse;
    }
}
class InferenceClientProviderApiError extends InferenceClientHttpRequestError {
    constructor(message, httpRequest, httpResponse){
        super(message, httpRequest, httpResponse);
        this.name = "ProviderApiError";
    }
}
class InferenceClientHubApiError extends InferenceClientHttpRequestError {
    constructor(message, httpRequest, httpResponse){
        super(message, httpRequest, httpResponse);
        this.name = "HubApiError";
    }
}
class InferenceClientProviderOutputError extends InferenceClientError {
    constructor(message){
        super(message);
        this.name = "ProviderOutputError";
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/toArray.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "toArray",
    ()=>toArray
]);
function toArray(obj) {
    if (Array.isArray(obj)) {
        return obj;
    }
    return [
        obj
    ];
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "BaseConversationalTask",
    ()=>BaseConversationalTask,
    "BaseTextGenerationTask",
    ()=>BaseTextGenerationTask,
    "TaskProviderHelper",
    ()=>TaskProviderHelper
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$toArray$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/toArray.js [app-route] (ecmascript)");
;
;
;
class TaskProviderHelper {
    provider;
    baseUrl;
    clientSideRoutingOnly;
    constructor(provider, baseUrl, clientSideRoutingOnly = false){
        this.provider = provider;
        this.baseUrl = baseUrl;
        this.clientSideRoutingOnly = clientSideRoutingOnly;
    }
    /**
     * Prepare the base URL for the request
     */ makeBaseUrl(params) {
        return params.authMethod !== "provider-key" ? `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_ROUTER_URL"]}/${this.provider}` : this.baseUrl;
    }
    /**
     * Prepare the body for the request
     */ makeBody(params) {
        if ("data" in params.args && !!params.args.data) {
            return params.args.data;
        }
        return JSON.stringify(this.preparePayload(params));
    }
    /**
     * Prepare the URL for the request
     */ makeUrl(params) {
        const baseUrl = this.makeBaseUrl(params);
        const route = this.makeRoute(params).replace(/^\/+/, "");
        return `${baseUrl}/${route}`;
    }
    /**
     * Prepare the headers for the request
     */ prepareHeaders(params, isBinary) {
        const headers = {};
        if (params.authMethod !== "none") {
            headers["Authorization"] = `Bearer ${params.accessToken}`;
        }
        if (!isBinary) {
            headers["Content-Type"] = "application/json";
        }
        return headers;
    }
}
class BaseConversationalTask extends TaskProviderHelper {
    constructor(provider, baseUrl, clientSideRoutingOnly = false){
        super(provider, baseUrl, clientSideRoutingOnly);
    }
    makeRoute() {
        return "v1/chat/completions";
    }
    preparePayload(params) {
        return {
            ...params.args,
            model: params.model
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && Array.isArray(response?.choices) && typeof response?.created === "number" && typeof response?.id === "string" && typeof response?.model === "string" && /// Together.ai and Nebius do not output a system_fingerprint
        (response.system_fingerprint === undefined || response.system_fingerprint === null || typeof response.system_fingerprint === "string") && typeof response?.usage === "object") {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Expected ChatCompletionOutput");
    }
}
class BaseTextGenerationTask extends TaskProviderHelper {
    constructor(provider, baseUrl, clientSideRoutingOnly = false){
        super(provider, baseUrl, clientSideRoutingOnly);
    }
    preparePayload(params) {
        return {
            ...params.args,
            model: params.model
        };
    }
    makeRoute() {
        return "v1/completions";
    }
    async getResponse(response) {
        const res = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$toArray$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toArray"])(response);
        if (Array.isArray(res) && res.length > 0 && res.every((x)=>typeof x === "object" && !!x && "generated_text" in x && typeof x.generated_text === "string")) {
            return res[0];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Expected Array<{generated_text: string}>");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "base64FromBytes",
    ()=>base64FromBytes
]);
function base64FromBytes(arr) {
    if (globalThis.Buffer) {
        return globalThis.Buffer.from(arr).toString("base64");
    } else {
        const bin = [];
        arr.forEach((byte)=>{
            bin.push(String.fromCharCode(byte));
        });
        return globalThis.btoa(bin.join(""));
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/pick.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * Return copy of object, only keeping allowlisted properties.
 */ __turbopack_context__.s([
    "pick",
    ()=>pick
]);
function pick(o, props) {
    return Object.assign({}, ...props.map((prop)=>{
        if (o[prop] !== undefined) {
            return {
                [prop]: o[prop]
            };
        }
    }));
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/typedInclude.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "typedInclude",
    ()=>typedInclude
]);
function typedInclude(arr, v) {
    return arr.includes(v);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "omit",
    ()=>omit
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$pick$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/pick.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedInclude$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/typedInclude.js [app-route] (ecmascript)");
;
;
function omit(o, props) {
    const propsArr = Array.isArray(props) ? props : [
        props
    ];
    const letsKeep = Object.keys(o).filter((prop)=>!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedInclude$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["typedInclude"])(propsArr, prop));
    return (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$pick$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["pick"])(o, letsKeep);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/hf-inference.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS",
    ()=>EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS,
    "HFInferenceAudioClassificationTask",
    ()=>HFInferenceAudioClassificationTask,
    "HFInferenceAudioToAudioTask",
    ()=>HFInferenceAudioToAudioTask,
    "HFInferenceAutomaticSpeechRecognitionTask",
    ()=>HFInferenceAutomaticSpeechRecognitionTask,
    "HFInferenceConversationalTask",
    ()=>HFInferenceConversationalTask,
    "HFInferenceDocumentQuestionAnsweringTask",
    ()=>HFInferenceDocumentQuestionAnsweringTask,
    "HFInferenceFeatureExtractionTask",
    ()=>HFInferenceFeatureExtractionTask,
    "HFInferenceFillMaskTask",
    ()=>HFInferenceFillMaskTask,
    "HFInferenceImageClassificationTask",
    ()=>HFInferenceImageClassificationTask,
    "HFInferenceImageSegmentationTask",
    ()=>HFInferenceImageSegmentationTask,
    "HFInferenceImageToImageTask",
    ()=>HFInferenceImageToImageTask,
    "HFInferenceImageToTextTask",
    ()=>HFInferenceImageToTextTask,
    "HFInferenceObjectDetectionTask",
    ()=>HFInferenceObjectDetectionTask,
    "HFInferenceQuestionAnsweringTask",
    ()=>HFInferenceQuestionAnsweringTask,
    "HFInferenceSentenceSimilarityTask",
    ()=>HFInferenceSentenceSimilarityTask,
    "HFInferenceSummarizationTask",
    ()=>HFInferenceSummarizationTask,
    "HFInferenceTableQuestionAnsweringTask",
    ()=>HFInferenceTableQuestionAnsweringTask,
    "HFInferenceTabularClassificationTask",
    ()=>HFInferenceTabularClassificationTask,
    "HFInferenceTabularRegressionTask",
    ()=>HFInferenceTabularRegressionTask,
    "HFInferenceTask",
    ()=>HFInferenceTask,
    "HFInferenceTextClassificationTask",
    ()=>HFInferenceTextClassificationTask,
    "HFInferenceTextGenerationTask",
    ()=>HFInferenceTextGenerationTask,
    "HFInferenceTextToAudioTask",
    ()=>HFInferenceTextToAudioTask,
    "HFInferenceTextToImageTask",
    ()=>HFInferenceTextToImageTask,
    "HFInferenceTextToSpeechTask",
    ()=>HFInferenceTextToSpeechTask,
    "HFInferenceTokenClassificationTask",
    ()=>HFInferenceTokenClassificationTask,
    "HFInferenceTranslationTask",
    ()=>HFInferenceTranslationTask,
    "HFInferenceVisualQuestionAnsweringTask",
    ()=>HFInferenceVisualQuestionAnsweringTask,
    "HFInferenceZeroShotClassificationTask",
    ()=>HFInferenceZeroShotClassificationTask,
    "HFInferenceZeroShotImageClassificationTask",
    ()=>HFInferenceZeroShotImageClassificationTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$toArray$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/toArray.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
;
;
;
;
;
;
const EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS = [
    "feature-extraction",
    "sentence-similarity"
];
class HFInferenceTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("hf-inference", `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_ROUTER_URL"]}/hf-inference`);
    }
    preparePayload(params) {
        return params.args;
    }
    makeUrl(params) {
        if (params.model.startsWith("http://") || params.model.startsWith("https://")) {
            return params.model;
        }
        return super.makeUrl(params);
    }
    makeRoute(params) {
        if (params.task && [
            "feature-extraction",
            "sentence-similarity"
        ].includes(params.task)) {
            // when deployed on hf-inference, those two tasks are automatically compatible with one another.
            return `models/${params.model}/pipeline/${params.task}`;
        }
        return `models/${params.model}`;
    }
    async getResponse(response) {
        return response;
    }
}
class HFInferenceTextToImageTask extends HFInferenceTask {
    async getResponse(response, url, headers, outputType) {
        if (!response) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference text-to-image API: response is undefined");
        }
        if (typeof response == "object") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            if ("data" in response && Array.isArray(response.data) && response.data[0].b64_json) {
                const base64Data = response.data[0].b64_json;
                if (outputType === "url") {
                    return `data:image/jpeg;base64,${base64Data}`;
                }
                const base64Response = await fetch(`data:image/jpeg;base64,${base64Data}`);
                return await base64Response.blob();
            }
            if ("output" in response && Array.isArray(response.output)) {
                if (outputType === "url") {
                    return response.output[0];
                }
                const urlResponse = await fetch(response.output[0]);
                const blob = await urlResponse.blob();
                return blob;
            }
        }
        if (response instanceof Blob) {
            if (outputType === "url" || outputType === "json") {
                const b64 = await response.arrayBuffer().then((buf)=>Buffer.from(buf).toString("base64"));
                return outputType === "url" ? `data:image/jpeg;base64,${b64}` : {
                    output: `data:image/jpeg;base64,${b64}`
                };
            }
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference text-to-image API: expected a Blob");
    }
}
class HFInferenceConversationalTask extends HFInferenceTask {
    makeUrl(params) {
        let url;
        if (params.model.startsWith("http://") || params.model.startsWith("https://")) {
            url = params.model.trim();
        } else {
            url = `${this.makeBaseUrl(params)}/models/${params.model}`;
        }
        url = url.replace(/\/+$/, "");
        if (url.endsWith("/v1")) {
            url += "/chat/completions";
        } else if (!url.endsWith("/chat/completions")) {
            url += "/v1/chat/completions";
        }
        return url;
    }
    preparePayload(params) {
        return {
            ...params.args,
            model: params.model
        };
    }
    async getResponse(response) {
        return response;
    }
}
class HFInferenceTextGenerationTask extends HFInferenceTask {
    async getResponse(response) {
        const res = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$toArray$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["toArray"])(response);
        if (Array.isArray(res) && res.every((x)=>"generated_text" in x && typeof x?.generated_text === "string")) {
            return res?.[0];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference text generation API: expected Array<{generated_text: string}>");
    }
}
class HFInferenceAudioClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x === "object" && x !== null && typeof x.label === "string" && typeof x.score === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference audio-classification API: expected Array<{label: string, score: number}> but received different format");
    }
}
class HFInferenceAutomaticSpeechRecognitionTask extends HFInferenceTask {
    async getResponse(response) {
        return response;
    }
    async preparePayloadAsync(args) {
        return "data" in args ? args : {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "inputs"),
            data: args.inputs
        };
    }
}
class HFInferenceAudioToAudioTask extends HFInferenceTask {
    async getResponse(response) {
        if (!Array.isArray(response)) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference audio-to-audio API: expected Array");
        }
        if (!response.every((elem)=>{
            return typeof elem === "object" && elem && "label" in elem && typeof elem.label === "string" && "content-type" in elem && typeof elem["content-type"] === "string" && "blob" in elem && typeof elem.blob === "string";
        })) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference audio-to-audio API: expected Array<{label: string, audio: Blob}>");
        }
        return response;
    }
}
class HFInferenceDocumentQuestionAnsweringTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((elem)=>typeof elem === "object" && !!elem && typeof elem?.answer === "string" && (typeof elem.end === "number" || typeof elem.end === "undefined") && (typeof elem.score === "number" || typeof elem.score === "undefined") && (typeof elem.start === "number" || typeof elem.start === "undefined"))) {
            return response[0];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference document-question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>");
    }
}
class HFInferenceFeatureExtractionTask extends HFInferenceTask {
    async getResponse(response) {
        const isNumArrayRec = (arr, maxDepth, curDepth = 0)=>{
            if (curDepth > maxDepth) return false;
            if (arr.every((x)=>Array.isArray(x))) {
                return arr.every((x)=>isNumArrayRec(x, maxDepth, curDepth + 1));
            } else {
                return arr.every((x)=>typeof x === "number");
            }
        };
        if (Array.isArray(response) && isNumArrayRec(response, 3, 0)) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference feature-extraction API: expected Array<number[][][] | number[][] | number[] | number>");
    }
}
class HFInferenceImageClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.label === "string" && typeof x.score === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference image-classification API: expected Array<{label: string, score: number}>");
    }
}
class HFInferenceImageSegmentationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.label === "string" && typeof x.mask === "string" && (x.score === undefined || typeof x.score === "number"))) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference image-segmentation API: expected Array<{label: string, mask: string, score: number}>");
    }
    async preparePayloadAsync(args) {
        return {
            ...args,
            inputs: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))
        };
    }
}
class HFInferenceImageToTextTask extends HFInferenceTask {
    async getResponse(response) {
        if (typeof response?.generated_text !== "string") {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference image-to-text API: expected {generated_text: string}");
        }
        return response;
    }
}
class HFInferenceImageToImageTask extends HFInferenceTask {
    async preparePayloadAsync(args) {
        if (!args.parameters) {
            return {
                ...args,
                model: args.model,
                data: args.inputs
            };
        } else {
            return {
                ...args,
                inputs: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))
            };
        }
    }
    async getResponse(response) {
        if (response instanceof Blob) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference image-to-image API: expected Blob");
    }
}
class HFInferenceObjectDetectionTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.label === "string" && typeof x.score === "number" && typeof x.box.xmin === "number" && typeof x.box.ymin === "number" && typeof x.box.xmax === "number" && typeof x.box.ymax === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference object-detection API: expected Array<{label: string, score: number, box: {xmin: number, ymin: number, xmax: number, ymax: number}}>");
    }
}
class HFInferenceZeroShotImageClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.label === "string" && typeof x.score === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference zero-shot-image-classification API: expected Array<{label: string, score: number}>");
    }
}
class HFInferenceTextClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        const output = response?.[0];
        if (Array.isArray(output) && output.every((x)=>typeof x?.label === "string" && typeof x.score === "number")) {
            return output;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference text-classification API: expected Array<{label: string, score: number}>");
    }
}
class HFInferenceQuestionAnsweringTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) ? response.every((elem)=>typeof elem === "object" && !!elem && typeof elem.answer === "string" && typeof elem.end === "number" && typeof elem.score === "number" && typeof elem.start === "number") : typeof response === "object" && !!response && typeof response.answer === "string" && typeof response.end === "number" && typeof response.score === "number" && typeof response.start === "number") {
            return Array.isArray(response) ? response[0] : response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference question-answering API: expected Array<{answer: string, end: number, score: number, start: number}>");
    }
}
class HFInferenceFillMaskTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.score === "number" && typeof x.sequence === "string" && typeof x.token === "number" && typeof x.token_str === "string")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference fill-mask API: expected Array<{score: number, sequence: string, token: number, token_str: string}>");
    }
}
class HFInferenceZeroShotClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        /// Handle Legacy response format from Inference API
        if (typeof response === "object" && response !== null && "labels" in response && "scores" in response && Array.isArray(response.labels) && Array.isArray(response.scores) && response.labels.length === response.scores.length && response.labels.every((label)=>typeof label === "string") && response.scores.every((score)=>typeof score === "number")) {
            const scores = response.scores;
            return response.labels.map((label, index)=>({
                    label,
                    score: scores[index]
                }));
        }
        if (Array.isArray(response) && response.every(HFInferenceZeroShotClassificationTask.validateOutputElement)) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference zero-shot-classification API: expected Array<{label: string, score: number}>");
    }
    static validateOutputElement(elem) {
        return typeof elem === "object" && !!elem && "label" in elem && "score" in elem && typeof elem.label === "string" && typeof elem.score === "number";
    }
}
class HFInferenceSentenceSimilarityTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference sentence-similarity API: expected Array<number>");
    }
}
class HFInferenceTableQuestionAnsweringTask extends HFInferenceTask {
    static validate(elem) {
        return typeof elem === "object" && !!elem && "aggregator" in elem && typeof elem.aggregator === "string" && "answer" in elem && typeof elem.answer === "string" && "cells" in elem && Array.isArray(elem.cells) && elem.cells.every((x)=>typeof x === "string") && "coordinates" in elem && Array.isArray(elem.coordinates) && elem.coordinates.every((coord)=>Array.isArray(coord) && coord.every((x)=>typeof x === "number"));
    }
    async getResponse(response) {
        if (Array.isArray(response) && Array.isArray(response) ? response.every((elem)=>HFInferenceTableQuestionAnsweringTask.validate(elem)) : HFInferenceTableQuestionAnsweringTask.validate(response)) {
            return Array.isArray(response) ? response[0] : response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference table-question-answering API: expected {aggregator: string, answer: string, cells: string[], coordinates: number[][]}");
    }
}
class HFInferenceTokenClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x.end === "number" && typeof x.entity_group === "string" && typeof x.score === "number" && typeof x.start === "number" && typeof x.word === "string")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference token-classification API: expected Array<{end: number, entity_group: string, score: number, start: number, word: string}>");
    }
}
class HFInferenceTranslationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x?.translation_text === "string")) {
            return response?.length === 1 ? response?.[0] : response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference translation API: expected Array<{translation_text: string}>");
    }
}
class HFInferenceSummarizationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x?.summary_text === "string")) {
            return response?.[0];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference summarization API: expected Array<{summary_text: string}>");
    }
}
class HFInferenceTextToSpeechTask extends HFInferenceTask {
    async getResponse(response) {
        return response;
    }
}
class HFInferenceTabularClassificationTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference tabular-classification API: expected Array<number>");
    }
}
class HFInferenceVisualQuestionAnsweringTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((elem)=>typeof elem === "object" && !!elem && typeof elem?.answer === "string" && typeof elem.score === "number")) {
            return response[0];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference visual-question-answering API: expected Array<{answer: string, score: number}>");
    }
}
class HFInferenceTabularRegressionTask extends HFInferenceTask {
    async getResponse(response) {
        if (Array.isArray(response) && response.every((x)=>typeof x === "number")) {
            return response;
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from HF-Inference tabular-regression API: expected Array<number>");
    }
}
class HFInferenceTextToAudioTask extends HFInferenceTask {
    async getResponse(response) {
        return response;
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getLogger",
    ()=>getLogger,
    "setLogger",
    ()=>setLogger
]);
let globalLogger = console;
function setLogger(logger) {
    globalLogger = logger;
}
function getLogger() {
    return globalLogger;
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "fetchInferenceProviderMappingForModel",
    ()=>fetchInferenceProviderMappingForModel,
    "getInferenceProviderMapping",
    ()=>getInferenceProviderMapping,
    "inferenceProviderMappingCache",
    ()=>inferenceProviderMappingCache,
    "resolveProvider",
    ()=>resolveProvider
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$consts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/consts.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/hf-inference.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedInclude$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/typedInclude.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
;
;
;
;
;
;
const inferenceProviderMappingCache = new Map();
/**
 * Normalize inferenceProviderMapping to always return an array format.
 * This provides backward and forward compatibility for the API changes.
 *
 * Vendored from @huggingface/hub to avoid extra dependency.
 */ function normalizeInferenceProviderMapping(modelId, inferenceProviderMapping) {
    if (!inferenceProviderMapping) {
        return [];
    }
    // If it's already an array, return it as is
    if (Array.isArray(inferenceProviderMapping)) {
        return inferenceProviderMapping;
    }
    // Convert mapping to array format
    return Object.entries(inferenceProviderMapping).map(([provider, mapping])=>({
            provider,
            hfModelId: modelId,
            providerId: mapping.providerId,
            status: mapping.status,
            task: mapping.task,
            adapter: mapping.adapter,
            adapterWeightsPath: mapping.adapterWeightsPath
        }));
}
async function fetchInferenceProviderMappingForModel(modelId, accessToken, options) {
    let inferenceProviderMapping;
    if (inferenceProviderMappingCache.has(modelId)) {
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        inferenceProviderMapping = inferenceProviderMappingCache.get(modelId);
    } else {
        const url = `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_HUB_URL"]}/api/models/${modelId}?expand[]=inferenceProviderMapping`;
        const resp = await (options?.fetch ?? fetch)(url, {
            headers: accessToken?.startsWith("hf_") ? {
                Authorization: `Bearer ${accessToken}`
            } : {}
        });
        if (!resp.ok) {
            if (resp.headers.get("Content-Type")?.startsWith("application/json")) {
                const error = await resp.json();
                if ("error" in error && typeof error.error === "string") {
                    throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientHubApiError"](`Failed to fetch inference provider mapping for model ${modelId}: ${error.error}`, {
                        url,
                        method: "GET"
                    }, {
                        requestId: resp.headers.get("x-request-id") ?? "",
                        status: resp.status,
                        body: error
                    });
                }
            } else {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientHubApiError"](`Failed to fetch inference provider mapping for model ${modelId}`, {
                    url,
                    method: "GET"
                }, {
                    requestId: resp.headers.get("x-request-id") ?? "",
                    status: resp.status,
                    body: await resp.text()
                });
            }
        }
        let payload = null;
        try {
            payload = await resp.json();
        } catch  {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientHubApiError"](`Failed to fetch inference provider mapping for model ${modelId}: malformed API response, invalid JSON`, {
                url,
                method: "GET"
            }, {
                requestId: resp.headers.get("x-request-id") ?? "",
                status: resp.status,
                body: await resp.text()
            });
        }
        if (!payload?.inferenceProviderMapping) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientHubApiError"](`We have not been able to find inference provider information for model ${modelId}.`, {
                url,
                method: "GET"
            }, {
                requestId: resp.headers.get("x-request-id") ?? "",
                status: resp.status,
                body: await resp.text()
            });
        }
        inferenceProviderMapping = normalizeInferenceProviderMapping(modelId, payload.inferenceProviderMapping);
        inferenceProviderMappingCache.set(modelId, inferenceProviderMapping);
    }
    return inferenceProviderMapping;
}
async function getInferenceProviderMapping(params, options) {
    const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
    if (__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$consts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HARDCODED_MODEL_INFERENCE_MAPPING"][params.provider][params.modelId]) {
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$consts$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HARDCODED_MODEL_INFERENCE_MAPPING"][params.provider][params.modelId];
    }
    const mappings = await fetchInferenceProviderMappingForModel(params.modelId, params.accessToken, options);
    const providerMapping = mappings.find((mapping)=>mapping.provider === params.provider);
    if (providerMapping) {
        const equivalentTasks = params.provider === "hf-inference" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedInclude$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["typedInclude"])(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS"], params.task) ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["EQUIVALENT_SENTENCE_TRANSFORMERS_TASKS"] : [
            params.task
        ];
        if (!(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedInclude$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["typedInclude"])(equivalentTasks, providerMapping.task)) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Model ${params.modelId} is not supported for task ${params.task} and provider ${params.provider}. Supported task: ${providerMapping.task}.`);
        }
        if (providerMapping.status === "staging") {
            logger.warn(`Model ${params.modelId} is in staging mode for provider ${params.provider}. Meant for test purposes only.`);
        }
        return providerMapping;
    }
    return null;
}
async function resolveProvider(provider, modelId, endpointUrl) {
    const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
    if (endpointUrl) {
        if (provider) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("Specifying both endpointUrl and provider is not supported.");
        }
        /// Defaulting to hf-inference helpers / API
        return "hf-inference";
    }
    if (!provider) {
        logger.log("Defaulting to 'auto' which will select the first provider available for the model, sorted by the user's order in https://hf.co/settings/inference-providers.");
        provider = "auto";
    }
    if (provider === "auto") {
        if (!modelId) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("Specifying a model is required when provider is 'auto'");
        }
        const mappings = await fetchInferenceProviderMappingForModel(modelId);
        provider = mappings[0]?.provider;
        logger.log("Auto selected provider:", provider);
    }
    if (!provider) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`No Inference Provider available for model ${modelId}.`);
    }
    return provider;
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/baseten.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Baseten model ID here:
 *
 * https://huggingface.co/api/partners/baseten/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Baseten and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Baseten, please open an issue on the present repo
 * and we will tag Baseten team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "BasetenConversationalTask",
    ()=>BasetenConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
const BASETEN_API_BASE_URL = "https://inference.baseten.co";
class BasetenConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("baseten", BASETEN_API_BASE_URL);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/delay.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "delay",
    ()=>delay
]);
function delay(ms) {
    return new Promise((resolve)=>{
        setTimeout(()=>resolve(), ms);
    });
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/black-forest-labs.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Black Forest Labs model ID here:
 *
 * https://huggingface.co/api/partners/blackforestlabs/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Black Forest Labs and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Black Forest Labs, please open an issue on the present repo
 * and we will tag Black Forest Labs team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "BlackForestLabsTextToImageTask",
    ()=>BlackForestLabsTextToImageTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/delay.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
;
;
;
;
const BLACK_FOREST_LABS_AI_API_BASE_URL = "https://api.us1.bfl.ai";
class BlackForestLabsTextToImageTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("black-forest-labs", BLACK_FOREST_LABS_AI_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            prompt: params.args.inputs
        };
    }
    prepareHeaders(params, binary) {
        const headers = {
            Authorization: params.authMethod !== "provider-key" ? `Bearer ${params.accessToken}` : `X-Key ${params.accessToken}`
        };
        if (!binary) {
            headers["Content-Type"] = "application/json";
        }
        return headers;
    }
    makeRoute(params) {
        if (!params) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("Params are required");
        }
        return `/v1/${params.model}`;
    }
    async getResponse(response, url, headers, outputType) {
        const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
        const urlObj = new URL(response.polling_url);
        for(let step = 0; step < 5; step++){
            await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["delay"])(1000);
            logger.debug(`Polling Black Forest Labs API for the result... ${step + 1}/5`);
            urlObj.searchParams.set("attempt", step.toString(10));
            const resp = await fetch(urlObj, {
                headers: {
                    "Content-Type": "application/json"
                }
            });
            if (!resp.ok) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"]("Failed to fetch result from black forest labs API", {
                    url: urlObj.toString(),
                    method: "GET",
                    headers: {
                        "Content-Type": "application/json"
                    }
                }, {
                    requestId: resp.headers.get("x-request-id") ?? "",
                    status: resp.status,
                    body: await resp.text()
                });
            }
            const payload = await resp.json();
            if (typeof payload === "object" && payload && "status" in payload && typeof payload.status === "string" && payload.status === "Ready" && "result" in payload && typeof payload.result === "object" && payload.result && "sample" in payload.result && typeof payload.result.sample === "string") {
                if (outputType === "json") {
                    return payload.result;
                }
                if (outputType === "url") {
                    return payload.result.sample;
                }
                const image = await fetch(payload.result.sample);
                return await image.blob();
            }
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Timed out while waiting for the result from black forest labs API - aborting after 5 attempts`);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/cerebras.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Cerebras model ID here:
 *
 * https://huggingface.co/api/partners/cerebras/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Cerebras and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Cerebras, please open an issue on the present repo
 * and we will tag Cerebras team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "CerebrasConversationalTask",
    ()=>CerebrasConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
class CerebrasConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("cerebras", "https://api.cerebras.ai");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/cohere.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Cohere model ID here:
 *
 * https://huggingface.co/api/partners/cohere/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Cohere and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Cohere, please open an issue on the present repo
 * and we will tag Cohere team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "CohereConversationalTask",
    ()=>CohereConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
class CohereConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("cohere", "https://api.cohere.com");
    }
    makeRoute() {
        return "/compatibility/v1/chat/completions";
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/lib/isUrl.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "isUrl",
    ()=>isUrl
]);
function isUrl(modelOrUrl) {
    return /^http(s?):/.test(modelOrUrl) || modelOrUrl.startsWith("/");
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/fal-ai.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Fal model ID here:
 *
 * https://huggingface.co/api/partners/fal-ai/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Fal and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Fal, please open an issue on the present repo
 * and we will tag Fal team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "FAL_AI_SUPPORTED_BLOB_TYPES",
    ()=>FAL_AI_SUPPORTED_BLOB_TYPES,
    "FalAIAutomaticSpeechRecognitionTask",
    ()=>FalAIAutomaticSpeechRecognitionTask,
    "FalAIImageSegmentationTask",
    ()=>FalAIImageSegmentationTask,
    "FalAIImageToImageTask",
    ()=>FalAIImageToImageTask,
    "FalAIImageToVideoTask",
    ()=>FalAIImageToVideoTask,
    "FalAITextToImageTask",
    ()=>FalAITextToImageTask,
    "FalAITextToSpeechTask",
    ()=>FalAITextToSpeechTask,
    "FalAITextToVideoTask",
    ()=>FalAITextToVideoTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/isUrl.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/delay.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
const FAL_AI_SUPPORTED_BLOB_TYPES = [
    "audio/mpeg",
    "audio/mp4",
    "audio/wav",
    "audio/x-wav"
];
class FalAITask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(url){
        super("fal-ai", url || "https://fal.run");
    }
    preparePayload(params) {
        return params.args;
    }
    makeRoute(params) {
        return `/${params.model}`;
    }
    prepareHeaders(params, binary) {
        const headers = {
            Authorization: params.authMethod !== "provider-key" ? `Bearer ${params.accessToken}` : `Key ${params.accessToken}`
        };
        if (!binary) {
            headers["Content-Type"] = "application/json";
        }
        return headers;
    }
}
class FalAiQueueTask extends FalAITask {
    async getResponseFromQueueApi(response, url, headers) {
        if (!url || !headers) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`URL and headers are required for ${this.task} task`);
        }
        const requestId = response.request_id;
        if (!requestId) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai ${this.task} API: no request ID found in the response`);
        }
        let status = response.status;
        const parsedUrl = new URL(url);
        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === "router.huggingface.co" ? "/fal-ai" : ""}`;
        // extracting the provider model id for status and result urls
        // from the response as it might be different from the mapped model in `url`
        const modelId = new URL(response.response_url).pathname;
        const queryParams = parsedUrl.search;
        const statusUrl = `${baseUrl}${modelId}/status${queryParams}`;
        const resultUrl = `${baseUrl}${modelId}${queryParams}`;
        while(status !== "COMPLETED"){
            await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["delay"])(500);
            const statusResponse = await fetch(statusUrl, {
                headers
            });
            if (!statusResponse.ok) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"]("Failed to fetch response status from fal-ai API", {
                    url: statusUrl,
                    method: "GET"
                }, {
                    requestId: statusResponse.headers.get("x-request-id") ?? "",
                    status: statusResponse.status,
                    body: await statusResponse.text()
                });
            }
            try {
                status = (await statusResponse.json()).status;
            } catch (error) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Failed to parse status response from fal-ai API: received malformed response");
            }
        }
        const resultResponse = await fetch(resultUrl, {
            headers
        });
        let result;
        try {
            result = await resultResponse.json();
        } catch (error) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Failed to parse result response from fal-ai API: received malformed response");
        }
        return result;
    }
}
function buildLoraPath(modelId, adapterWeightsPath) {
    return `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_HUB_URL"]}/${modelId}/resolve/main/${adapterWeightsPath}`;
}
class FalAITextToImageTask extends FalAITask {
    preparePayload(params) {
        const payload = {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            sync_mode: true,
            prompt: params.args.inputs
        };
        if (params.mapping?.adapter === "lora" && params.mapping.adapterWeightsPath) {
            payload.loras = [
                {
                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),
                    scale: 1
                }
            ];
            if (params.mapping.providerId === "fal-ai/lora") {
                payload.model_name = "stabilityai/stable-diffusion-xl-base-1.0";
            }
        }
        return payload;
    }
    async getResponse(response, url, headers, outputType) {
        if (typeof response === "object" && "images" in response && Array.isArray(response.images) && response.images.length > 0 && "url" in response.images[0] && typeof response.images[0].url === "string") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            if (outputType === "url") {
                return response.images[0].url;
            }
            const urlResponse = await fetch(response.images[0].url);
            return await urlResponse.blob();
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Fal.ai text-to-image API");
    }
}
class FalAIImageToImageTask extends FalAiQueueTask {
    task;
    constructor(){
        super("https://queue.fal.run");
        this.task = "image-to-image";
    }
    makeRoute(params) {
        if (params.authMethod !== "provider-key") {
            return `/${params.model}?_subdomain=queue`;
        }
        return `/${params.model}`;
    }
    preparePayload(params) {
        const payload = params.args;
        if (params.mapping?.adapter === "lora" && params.mapping.adapterWeightsPath) {
            payload.loras = [
                {
                    path: buildLoraPath(params.mapping.hfModelId, params.mapping.adapterWeightsPath),
                    scale: 1
                }
            ];
        }
        return payload;
    }
    async preparePayloadAsync(args) {
        const mimeType = args.inputs instanceof Blob ? args.inputs.type : "image/png";
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, [
                "inputs",
                "parameters"
            ]),
            image_url: `data:${mimeType};base64,${(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`,
            ...args.parameters,
            ...args
        };
    }
    async getResponse(response, url, headers) {
        const result = await this.getResponseFromQueueApi(response, url, headers);
        if (typeof result === "object" && !!result && "images" in result && Array.isArray(result.images) && result.images.length > 0 && typeof result.images[0] === "object" && !!result.images[0] && "url" in result.images[0] && typeof result.images[0].url === "string" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(result.images[0].url)) {
            const urlResponse = await fetch(result.images[0].url);
            return await urlResponse.blob();
        } else {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai image-to-image API: expected { images: Array<{ url: string }> } result format, got instead: ${JSON.stringify(result)}`);
        }
    }
}
class FalAITextToVideoTask extends FalAiQueueTask {
    task;
    constructor(){
        super("https://queue.fal.run");
        this.task = "text-to-video";
    }
    makeRoute(params) {
        if (params.authMethod !== "provider-key") {
            return `/${params.model}?_subdomain=queue`;
        }
        return `/${params.model}`;
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            prompt: params.args.inputs
        };
    }
    async getResponse(response, url, headers) {
        const result = await this.getResponseFromQueueApi(response, url, headers);
        if (typeof result === "object" && !!result && "video" in result && typeof result.video === "object" && !!result.video && "url" in result.video && typeof result.video.url === "string" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(result.video.url)) {
            const urlResponse = await fetch(result.video.url);
            return await urlResponse.blob();
        } else {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai text-to-video API: expected { video: { url: string } } result format, got instead: ${JSON.stringify(result)}`);
        }
    }
}
class FalAIImageToVideoTask extends FalAiQueueTask {
    task;
    constructor(){
        super("https://queue.fal.run");
        this.task = "image-to-video";
    }
    /** Same queue routing rule as the other Fal queue tasks */ makeRoute(params) {
        return params.authMethod !== "provider-key" ? `/${params.model}?_subdomain=queue` : `/${params.model}`;
    }
    /** Synchronous case – caller already gave us base64 or a URL */ preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            // args.inputs is expected to be a base64 data URI or an URL
            image_url: params.args.image_url
        };
    }
    /** Asynchronous helper – caller gave us a Blob */ async preparePayloadAsync(args) {
        const mimeType = args.inputs instanceof Blob ? args.inputs.type : "image/png";
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, [
                "inputs",
                "parameters"
            ]),
            image_url: `data:${mimeType};base64,${(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(args.inputs instanceof ArrayBuffer ? args.inputs : await args.inputs.arrayBuffer()))}`,
            ...args.parameters,
            ...args
        };
    }
    /** Queue polling + final download – mirrors Text‑to‑Video */ async getResponse(response, url, headers) {
        const result = await this.getResponseFromQueueApi(response, url, headers);
        if (typeof result === "object" && result !== null && "video" in result && typeof result.video === "object" && result.video !== null && "url" in result.video && typeof result.video.url === "string" && "url" in result.video && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(result.video.url)) {
            const urlResponse = await fetch(result.video.url);
            return await urlResponse.blob();
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai image‑to‑video API: expected { video: { url: string } }, got: ${JSON.stringify(result)}`);
    }
}
class FalAIAutomaticSpeechRecognitionTask extends FalAITask {
    prepareHeaders(params, binary) {
        const headers = super.prepareHeaders(params, binary);
        headers["Content-Type"] = "application/json";
        return headers;
    }
    async getResponse(response) {
        const res = response;
        if (typeof res?.text !== "string") {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai Automatic Speech Recognition API: expected { text: string } format, got instead: ${JSON.stringify(response)}`);
        }
        return {
            text: res.text
        };
    }
    async preparePayloadAsync(args) {
        const blob = "data" in args && args.data instanceof Blob ? args.data : "inputs" in args ? args.inputs : undefined;
        const contentType = blob?.type;
        if (!contentType) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Unable to determine the input's content-type. Make sure your are passing a Blob when using provider fal-ai.`);
        }
        if (!FAL_AI_SUPPORTED_BLOB_TYPES.includes(contentType)) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Provider fal-ai does not support blob type ${contentType} - supported content types are: ${FAL_AI_SUPPORTED_BLOB_TYPES.join(", ")}`);
        }
        const base64audio = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(await blob.arrayBuffer()));
        return {
            ..."data" in args ? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "data") : (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "inputs"),
            audio_url: `data:${contentType};base64,${base64audio}`
        };
    }
}
class FalAITextToSpeechTask extends FalAITask {
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            text: params.args.inputs
        };
    }
    async getResponse(response) {
        const res = response;
        if (typeof res?.audio?.url !== "string") {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai Text-to-Speech API: expected { audio: { url: string } } format, got instead: ${JSON.stringify(response)}`);
        }
        const urlResponse = await fetch(res.audio.url);
        if (!urlResponse.ok) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to fetch audio from ${res.audio.url}: ${urlResponse.statusText}`, {
                url: res.audio.url,
                method: "GET",
                headers: {
                    "Content-Type": "application/json"
                }
            }, {
                requestId: urlResponse.headers.get("x-request-id") ?? "",
                status: urlResponse.status,
                body: await urlResponse.text()
            });
        }
        try {
            return await urlResponse.blob();
        } catch (error) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to fetch audio from ${res.audio.url}: ${error instanceof Error ? error.message : String(error)}`, {
                url: res.audio.url,
                method: "GET",
                headers: {
                    "Content-Type": "application/json"
                }
            }, {
                requestId: urlResponse.headers.get("x-request-id") ?? "",
                status: urlResponse.status,
                body: await urlResponse.text()
            });
        }
    }
}
class FalAIImageSegmentationTask extends FalAiQueueTask {
    task;
    constructor(){
        super("https://queue.fal.run");
        this.task = "image-segmentation";
    }
    makeRoute(params) {
        if (params.authMethod !== "provider-key") {
            return `/${params.model}?_subdomain=queue`;
        }
        return `/${params.model}`;
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            sync_mode: true
        };
    }
    async preparePayloadAsync(args) {
        const blob = "data" in args && args.data instanceof Blob ? args.data : "inputs" in args ? args.inputs : undefined;
        const mimeType = blob instanceof Blob ? blob.type : "image/png";
        const base64Image = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(blob instanceof ArrayBuffer ? blob : await blob.arrayBuffer()));
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, [
                "inputs",
                "parameters",
                "data"
            ]),
            ...args.parameters,
            ...args,
            image_url: `data:${mimeType};base64,${base64Image}`,
            sync_mode: true
        };
    }
    async getResponse(response, url, headers) {
        const result = await this.getResponseFromQueueApi(response, url, headers);
        if (typeof result === "object" && result !== null && "image" in result && typeof result.image === "object" && result.image !== null && "url" in result.image && typeof result.image.url === "string") {
            const maskResponse = await fetch(result.image.url);
            if (!maskResponse.ok) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to fetch segmentation mask from ${result.image.url}`, {
                    url: result.image.url,
                    method: "GET"
                }, {
                    requestId: maskResponse.headers.get("x-request-id") ?? "",
                    status: maskResponse.status,
                    body: await maskResponse.text()
                });
            }
            const maskBlob = await maskResponse.blob();
            const maskArrayBuffer = await maskBlob.arrayBuffer();
            const maskBase64 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(maskArrayBuffer));
            return [
                {
                    label: "mask",
                    score: 1.0,
                    mask: maskBase64
                }
            ];
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Fal.ai image-segmentation API: expected { image: { url: string } } format, got instead: ${JSON.stringify(response)}`);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/featherless-ai.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "FeatherlessAIConversationalTask",
    ()=>FeatherlessAIConversationalTask,
    "FeatherlessAITextGenerationTask",
    ()=>FeatherlessAITextGenerationTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const FEATHERLESS_API_BASE_URL = "https://api.featherless.ai";
class FeatherlessAIConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("featherless-ai", FEATHERLESS_API_BASE_URL);
    }
}
class FeatherlessAITextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("featherless-ai", FEATHERLESS_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            model: params.model,
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters ? {
                max_tokens: params.args.parameters.max_new_tokens,
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args.parameters, "max_new_tokens")
            } : undefined,
            prompt: params.args.inputs
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && "choices" in response && Array.isArray(response?.choices) && typeof response?.model === "string") {
            const completion = response.choices[0];
            return {
                generated_text: completion.text
            };
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Featherless AI text generation API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/fireworks-ai.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Fireworks model ID here:
 *
 * https://huggingface.co/api/partners/fireworks/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Fireworks and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Fireworks, please open an issue on the present repo
 * and we will tag Fireworks team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "FireworksConversationalTask",
    ()=>FireworksConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
class FireworksConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("fireworks-ai", "https://api.fireworks.ai");
    }
    makeRoute() {
        return "/inference/v1/chat/completions";
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/groq.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "GroqConversationalTask",
    ()=>GroqConversationalTask,
    "GroqTextGenerationTask",
    ()=>GroqTextGenerationTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
/**
 * See the registered mapping of HF model ID => Groq model ID here:
 *
 * https://huggingface.co/api/partners/groq/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Groq and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Groq, please open an issue on the present repo
 * and we will tag Groq team members.
 *
 * Thanks!
 */ const GROQ_API_BASE_URL = "https://api.groq.com";
class GroqTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("groq", GROQ_API_BASE_URL);
    }
    makeRoute() {
        return "/openai/v1/chat/completions";
    }
}
class GroqConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("groq", GROQ_API_BASE_URL);
    }
    makeRoute() {
        return "/openai/v1/chat/completions";
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/hyperbolic.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "HyperbolicConversationalTask",
    ()=>HyperbolicConversationalTask,
    "HyperbolicTextGenerationTask",
    ()=>HyperbolicTextGenerationTask,
    "HyperbolicTextToImageTask",
    ()=>HyperbolicTextToImageTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const HYPERBOLIC_API_BASE_URL = "https://api.hyperbolic.xyz";
class HyperbolicConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("hyperbolic", HYPERBOLIC_API_BASE_URL);
    }
}
class HyperbolicTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("hyperbolic", HYPERBOLIC_API_BASE_URL);
    }
    makeRoute() {
        return "v1/chat/completions";
    }
    preparePayload(params) {
        return {
            messages: [
                {
                    content: params.args.inputs,
                    role: "user"
                }
            ],
            ...params.args.parameters ? {
                max_tokens: params.args.parameters.max_new_tokens,
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args.parameters, "max_new_tokens")
            } : undefined,
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            model: params.model
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && "choices" in response && Array.isArray(response?.choices) && typeof response?.model === "string") {
            const completion = response.choices[0];
            return {
                generated_text: completion.message.content
            };
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Hyperbolic text generation API");
    }
}
class HyperbolicTextToImageTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("hyperbolic", HYPERBOLIC_API_BASE_URL);
    }
    makeRoute(params) {
        void params;
        return `/v1/images/generations`;
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            prompt: params.args.inputs,
            model_name: params.model
        };
    }
    async getResponse(response, url, headers, outputType) {
        if (typeof response === "object" && "images" in response && Array.isArray(response.images) && response.images[0] && typeof response.images[0].image === "string") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            if (outputType === "url") {
                return `data:image/jpeg;base64,${response.images[0].image}`;
            }
            return fetch(`data:image/jpeg;base64,${response.images[0].image}`).then((res)=>res.blob());
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Hyperbolic text-to-image API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/nebius.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "NebiusConversationalTask",
    ()=>NebiusConversationalTask,
    "NebiusFeatureExtractionTask",
    ()=>NebiusFeatureExtractionTask,
    "NebiusTextGenerationTask",
    ()=>NebiusTextGenerationTask,
    "NebiusTextToImageTask",
    ()=>NebiusTextToImageTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const NEBIUS_API_BASE_URL = "https://api.studio.nebius.ai";
class NebiusConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("nebius", NEBIUS_API_BASE_URL);
    }
    preparePayload(params) {
        const payload = super.preparePayload(params);
        const responseFormat = params.args.response_format;
        if (responseFormat?.type === "json_schema" && responseFormat.json_schema?.schema) {
            payload["guided_json"] = responseFormat.json_schema.schema;
        }
        return payload;
    }
}
class NebiusTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("nebius", NEBIUS_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            ...params.args,
            model: params.model,
            prompt: params.args.inputs
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && "choices" in response && Array.isArray(response?.choices) && response.choices.length > 0 && typeof response.choices[0]?.text === "string") {
            return {
                generated_text: response.choices[0].text
            };
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Nebius text generation API");
    }
}
class NebiusTextToImageTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("nebius", NEBIUS_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            response_format: "b64_json",
            prompt: params.args.inputs,
            model: params.model
        };
    }
    makeRoute() {
        return "v1/images/generations";
    }
    async getResponse(response, url, headers, outputType) {
        if (typeof response === "object" && "data" in response && Array.isArray(response.data) && response.data.length > 0 && "b64_json" in response.data[0] && typeof response.data[0].b64_json === "string") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            const base64Data = response.data[0].b64_json;
            if (outputType === "url") {
                return `data:image/jpeg;base64,${base64Data}`;
            }
            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res)=>res.blob());
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Nebius text-to-image API");
    }
}
class NebiusFeatureExtractionTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("nebius", NEBIUS_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            input: params.args.inputs,
            model: params.model
        };
    }
    makeRoute() {
        return "v1/embeddings";
    }
    async getResponse(response) {
        return response.data.map((item)=>item.embedding);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/novita.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Novita model ID here:
 *
 * https://huggingface.co/api/partners/novita/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Novita and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Novita, please open an issue on the present repo
 * and we will tag Novita team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "NovitaConversationalTask",
    ()=>NovitaConversationalTask,
    "NovitaTextGenerationTask",
    ()=>NovitaTextGenerationTask,
    "NovitaTextToVideoTask",
    ()=>NovitaTextToVideoTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/isUrl.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/delay.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
;
;
const NOVITA_API_BASE_URL = "https://api.novita.ai";
class NovitaTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("novita", NOVITA_API_BASE_URL);
    }
    makeRoute() {
        return "/v3/openai/chat/completions";
    }
}
class NovitaConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("novita", NOVITA_API_BASE_URL);
    }
    makeRoute() {
        return "/v3/openai/chat/completions";
    }
}
class NovitaTextToVideoTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("novita", NOVITA_API_BASE_URL);
    }
    makeRoute(params) {
        return `/v3/async/${params.model}`;
    }
    preparePayload(params) {
        const { num_inference_steps, ...restParameters } = params.args.parameters ?? {};
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...restParameters,
            steps: num_inference_steps,
            prompt: params.args.inputs
        };
    }
    async getResponse(response, url, headers) {
        if (!url || !headers) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("URL and headers are required for text-to-video task");
        }
        const taskId = response.task_id;
        if (!taskId) {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Novita text-to-video API: no task ID found in the response");
        }
        const parsedUrl = new URL(url);
        const baseUrl = `${parsedUrl.protocol}//${parsedUrl.host}${parsedUrl.host === "router.huggingface.co" ? "/novita" : ""}`;
        const resultUrl = `${baseUrl}/v3/async/task-result?task_id=${taskId}`;
        let status = "";
        let taskResult;
        while(status !== "TASK_STATUS_SUCCEED" && status !== "TASK_STATUS_FAILED"){
            await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$delay$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["delay"])(500);
            const resultResponse = await fetch(resultUrl, {
                headers
            });
            if (!resultResponse.ok) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"]("Failed to fetch task result", {
                    url: resultUrl,
                    method: "GET",
                    headers
                }, {
                    requestId: resultResponse.headers.get("x-request-id") ?? "",
                    status: resultResponse.status,
                    body: await resultResponse.text()
                });
            }
            try {
                taskResult = await resultResponse.json();
                if (taskResult && typeof taskResult === "object" && "task" in taskResult && taskResult.task && typeof taskResult.task === "object" && "status" in taskResult.task && typeof taskResult.task.status === "string") {
                    status = taskResult.task.status;
                } else {
                    throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Novita text-to-video API: failed to get task status");
                }
            } catch (error) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Novita text-to-video API: failed to parse task result");
            }
        }
        if (status === "TASK_STATUS_FAILED") {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Novita text-to-video task failed");
        }
        if (typeof taskResult === "object" && !!taskResult && "videos" in taskResult && typeof taskResult.videos === "object" && !!taskResult.videos && Array.isArray(taskResult.videos) && taskResult.videos.length > 0 && "video_url" in taskResult.videos[0] && typeof taskResult.videos[0].video_url === "string" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(taskResult.videos[0].video_url)) {
            const urlResponse = await fetch(taskResult.videos[0].video_url);
            return await urlResponse.blob();
        } else {
            throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"](`Received malformed response from Novita text-to-video API: expected { videos: [{ video_url: string }] } format, got instead: ${JSON.stringify(taskResult)}`);
        }
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/nscale.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "NscaleConversationalTask",
    ()=>NscaleConversationalTask,
    "NscaleTextToImageTask",
    ()=>NscaleTextToImageTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const NSCALE_API_BASE_URL = "https://inference.api.nscale.com";
class NscaleConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("nscale", NSCALE_API_BASE_URL);
    }
}
class NscaleTextToImageTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("nscale", NSCALE_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            response_format: "b64_json",
            prompt: params.args.inputs,
            model: params.model
        };
    }
    makeRoute() {
        return "v1/images/generations";
    }
    async getResponse(response, url, headers, outputType) {
        if (typeof response === "object" && "data" in response && Array.isArray(response.data) && response.data.length > 0 && "b64_json" in response.data[0] && typeof response.data[0].b64_json === "string") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            const base64Data = response.data[0].b64_json;
            if (outputType === "url") {
                return `data:image/jpeg;base64,${base64Data}`;
            }
            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res)=>res.blob());
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Nscale text-to-image API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/openai.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * Special case: provider configuration for a private models provider (OpenAI in this case).
 */ __turbopack_context__.s([
    "OpenAIConversationalTask",
    ()=>OpenAIConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
const OPENAI_API_BASE_URL = "https://api.openai.com";
class OpenAIConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        // Pass clientSideRoutingOnly: true to the constructor
        super("openai", OPENAI_API_BASE_URL, true);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/ovhcloud.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => OVHcloud model ID here:
 *
 * https://huggingface.co/api/partners/ovhcloud/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at OVHcloud and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to OVHcloud, please open an issue on the present repo
 * and we will tag OVHcloud team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "OvhCloudConversationalTask",
    ()=>OvhCloudConversationalTask,
    "OvhCloudTextGenerationTask",
    ()=>OvhCloudTextGenerationTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const OVHCLOUD_API_BASE_URL = "https://oai.endpoints.kepler.ai.cloud.ovh.net";
class OvhCloudConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("ovhcloud", OVHCLOUD_API_BASE_URL);
    }
}
class OvhCloudTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("ovhcloud", OVHCLOUD_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            model: params.model,
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters ? {
                max_tokens: params.args.parameters.max_new_tokens,
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args.parameters, "max_new_tokens")
            } : undefined,
            prompt: params.args.inputs
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && "choices" in response && Array.isArray(response?.choices) && typeof response?.model === "string") {
            const completion = response.choices[0];
            return {
                generated_text: completion.text
            };
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from OVHcloud text generation API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/publicai.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "PublicAIConversationalTask",
    ()=>PublicAIConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
class PublicAIConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("publicai", "https://api.publicai.co");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/replicate.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => Replicate model ID here:
 *
 * https://huggingface.co/api/partners/replicate/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at Replicate and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to Replicate, please open an issue on the present repo
 * and we will tag Replicate team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "ReplicateAutomaticSpeechRecognitionTask",
    ()=>ReplicateAutomaticSpeechRecognitionTask,
    "ReplicateImageToImageTask",
    ()=>ReplicateImageToImageTask,
    "ReplicateTextToImageTask",
    ()=>ReplicateTextToImageTask,
    "ReplicateTextToSpeechTask",
    ()=>ReplicateTextToSpeechTask,
    "ReplicateTextToVideoTask",
    ()=>ReplicateTextToVideoTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/isUrl.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
;
;
;
;
;
class ReplicateTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(url){
        super("replicate", url || "https://api.replicate.com");
    }
    makeRoute(params) {
        if (params.model.includes(":")) {
            return "v1/predictions";
        }
        return `v1/models/${params.model}/predictions`;
    }
    preparePayload(params) {
        return {
            input: {
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                    "inputs",
                    "parameters"
                ]),
                ...params.args.parameters,
                prompt: params.args.inputs
            },
            version: params.model.includes(":") ? params.model.split(":")[1] : undefined
        };
    }
    prepareHeaders(params, binary) {
        const headers = {
            Authorization: `Bearer ${params.accessToken}`,
            Prefer: "wait"
        };
        if (!binary) {
            headers["Content-Type"] = "application/json";
        }
        return headers;
    }
    makeUrl(params) {
        const baseUrl = this.makeBaseUrl(params);
        if (params.model.includes(":")) {
            return `${baseUrl}/v1/predictions`;
        }
        return `${baseUrl}/v1/models/${params.model}/predictions`;
    }
}
class ReplicateTextToImageTask extends ReplicateTask {
    preparePayload(params) {
        return {
            input: {
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                    "inputs",
                    "parameters"
                ]),
                ...params.args.parameters,
                prompt: params.args.inputs,
                lora_weights: params.mapping?.adapter === "lora" && params.mapping.adapterWeightsPath ? `https://huggingface.co/${params.mapping.hfModelId}` : undefined
            },
            version: params.model.includes(":") ? params.model.split(":")[1] : undefined
        };
    }
    async getResponse(res, url, headers, outputType) {
        void url;
        void headers;
        if (typeof res === "object" && "output" in res && Array.isArray(res.output) && res.output.length > 0 && typeof res.output[0] === "string") {
            if (outputType === "json") {
                return {
                    ...res
                };
            }
            if (outputType === "url") {
                return res.output[0];
            }
            const urlResponse = await fetch(res.output[0]);
            return await urlResponse.blob();
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Replicate text-to-image API");
    }
}
class ReplicateTextToSpeechTask extends ReplicateTask {
    preparePayload(params) {
        const payload = super.preparePayload(params);
        const input = payload["input"];
        if (typeof input === "object" && input !== null && "prompt" in input) {
            const inputObj = input;
            inputObj["text"] = inputObj["prompt"];
            delete inputObj["prompt"];
        }
        return payload;
    }
    async getResponse(response) {
        if (response instanceof Blob) {
            return response;
        }
        if (response && typeof response === "object") {
            if ("output" in response) {
                if (typeof response.output === "string") {
                    const urlResponse = await fetch(response.output);
                    return await urlResponse.blob();
                } else if (Array.isArray(response.output)) {
                    const urlResponse = await fetch(response.output[0]);
                    return await urlResponse.blob();
                }
            }
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Replicate text-to-speech API");
    }
}
class ReplicateTextToVideoTask extends ReplicateTask {
    async getResponse(response) {
        if (typeof response === "object" && !!response && "output" in response && typeof response.output === "string" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(response.output)) {
            const urlResponse = await fetch(response.output);
            return await urlResponse.blob();
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Replicate text-to-video API");
    }
}
class ReplicateAutomaticSpeechRecognitionTask extends ReplicateTask {
    preparePayload(params) {
        return {
            input: {
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                    "inputs",
                    "parameters"
                ]),
                ...params.args.parameters,
                audio: params.args.inputs
            },
            version: params.model.includes(":") ? params.model.split(":")[1] : undefined
        };
    }
    async preparePayloadAsync(args) {
        const blob = "data" in args && args.data instanceof Blob ? args.data : "inputs" in args ? args.inputs : undefined;
        if (!blob || !(blob instanceof Blob)) {
            throw new Error("Audio input must be a Blob");
        }
        // Convert Blob to base64 data URL
        const bytes = new Uint8Array(await blob.arrayBuffer());
        const base64 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(bytes);
        const audioInput = `data:${blob.type || "audio/wav"};base64,${base64}`;
        return {
            ..."data" in args ? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "data") : (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "inputs"),
            inputs: audioInput
        };
    }
    async getResponse(response) {
        if (typeof response?.output === "string") return {
            text: response.output
        };
        if (Array.isArray(response?.output) && typeof response.output[0] === "string") return {
            text: response.output[0]
        };
        const out = response?.output;
        if (out && typeof out === "object") {
            if (typeof out.transcription === "string") return {
                text: out.transcription
            };
            if (typeof out.translation === "string") return {
                text: out.translation
            };
            if (typeof out.txt_file === "string") {
                const r = await fetch(out.txt_file);
                return {
                    text: await r.text()
                };
            }
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Replicate automatic-speech-recognition API");
    }
}
class ReplicateImageToImageTask extends ReplicateTask {
    preparePayload(params) {
        return {
            input: {
                ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                    "inputs",
                    "parameters"
                ]),
                ...params.args.parameters,
                input_image: params.args.inputs,
                lora_weights: params.mapping?.adapter === "lora" && params.mapping.adapterWeightsPath ? `https://huggingface.co/${params.mapping.hfModelId}` : undefined
            },
            version: params.model.includes(":") ? params.model.split(":")[1] : undefined
        };
    }
    async preparePayloadAsync(args) {
        const { inputs, ...restArgs } = args;
        // Convert Blob to base64 data URL
        const bytes = new Uint8Array(await inputs.arrayBuffer());
        const base64 = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(bytes);
        const imageInput = `data:${inputs.type || "image/jpeg"};base64,${base64}`;
        return {
            ...restArgs,
            inputs: imageInput
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && !!response && "output" in response && Array.isArray(response.output) && response.output.length > 0 && typeof response.output[0] === "string") {
            const urlResponse = await fetch(response.output[0]);
            return await urlResponse.blob();
        }
        if (typeof response === "object" && !!response && "output" in response && typeof response.output === "string" && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(response.output)) {
            const urlResponse = await fetch(response.output);
            return await urlResponse.blob();
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Replicate image-to-image API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/sambanova.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "SambanovaConversationalTask",
    ()=>SambanovaConversationalTask,
    "SambanovaFeatureExtractionTask",
    ()=>SambanovaFeatureExtractionTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
class SambanovaConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("sambanova", "https://api.sambanova.ai");
    }
    preparePayload(params) {
        const responseFormat = params.args.response_format;
        if (responseFormat?.type === "json_schema" && responseFormat.json_schema) {
            if (responseFormat.json_schema.strict ?? true) {
                responseFormat.json_schema.strict = false;
            }
        }
        const payload = super.preparePayload(params);
        return payload;
    }
}
class SambanovaFeatureExtractionTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("sambanova", "https://api.sambanova.ai");
    }
    makeRoute() {
        return `/v1/embeddings`;
    }
    async getResponse(response) {
        if (typeof response === "object" && "data" in response && Array.isArray(response.data)) {
            return response.data.map((item)=>item.embedding);
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Sambanova feature-extraction (embeddings) API");
    }
    preparePayload(params) {
        return {
            model: params.model,
            input: params.args.inputs,
            ...params.args
        };
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/scaleway.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "ScalewayConversationalTask",
    ()=>ScalewayConversationalTask,
    "ScalewayFeatureExtractionTask",
    ()=>ScalewayFeatureExtractionTask,
    "ScalewayTextGenerationTask",
    ()=>ScalewayTextGenerationTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
;
const SCALEWAY_API_BASE_URL = "https://api.scaleway.ai";
class ScalewayConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("scaleway", SCALEWAY_API_BASE_URL);
    }
}
class ScalewayTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("scaleway", SCALEWAY_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            model: params.model,
            ...params.args,
            prompt: params.args.inputs
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && response !== null && "choices" in response && Array.isArray(response.choices) && response.choices.length > 0) {
            const completion = response.choices[0];
            if (typeof completion === "object" && !!completion && "text" in completion && completion.text && typeof completion.text === "string") {
                return {
                    generated_text: completion.text
                };
            }
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Scaleway text generation API");
    }
}
class ScalewayFeatureExtractionTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("scaleway", SCALEWAY_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            input: params.args.inputs,
            model: params.model
        };
    }
    makeRoute() {
        return "v1/embeddings";
    }
    async getResponse(response) {
        return response.data.map((item)=>item.embedding);
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/together.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "TogetherConversationalTask",
    ()=>TogetherConversationalTask,
    "TogetherTextGenerationTask",
    ()=>TogetherTextGenerationTask,
    "TogetherTextToImageTask",
    ()=>TogetherTextToImageTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
const TOGETHER_API_BASE_URL = "https://api.together.xyz";
class TogetherConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("together", TOGETHER_API_BASE_URL);
    }
    preparePayload(params) {
        const payload = super.preparePayload(params);
        const response_format = payload.response_format;
        if (response_format?.type === "json_schema" && response_format?.json_schema?.schema) {
            payload.response_format = {
                type: "json_schema",
                schema: response_format.json_schema.schema
            };
        }
        return payload;
    }
}
class TogetherTextGenerationTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseTextGenerationTask"] {
    constructor(){
        super("together", TOGETHER_API_BASE_URL);
    }
    preparePayload(params) {
        return {
            model: params.model,
            ...params.args,
            prompt: params.args.inputs
        };
    }
    async getResponse(response) {
        if (typeof response === "object" && "choices" in response && Array.isArray(response?.choices) && typeof response?.model === "string") {
            const completion = response.choices[0];
            return {
                generated_text: completion.text
            };
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Together text generation API");
    }
}
class TogetherTextToImageTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TaskProviderHelper"] {
    constructor(){
        super("together", TOGETHER_API_BASE_URL);
    }
    makeRoute() {
        return "v1/images/generations";
    }
    preparePayload(params) {
        return {
            ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(params.args, [
                "inputs",
                "parameters"
            ]),
            ...params.args.parameters,
            prompt: params.args.inputs,
            response_format: "base64",
            model: params.model
        };
    }
    async getResponse(response, url, headers, outputType) {
        if (typeof response === "object" && "data" in response && Array.isArray(response.data) && response.data.length > 0 && "b64_json" in response.data[0] && typeof response.data[0].b64_json === "string") {
            if (outputType === "json") {
                return {
                    ...response
                };
            }
            const base64Data = response.data[0].b64_json;
            if (outputType === "url") {
                return `data:image/jpeg;base64,${base64Data}`;
            }
            return fetch(`data:image/jpeg;base64,${base64Data}`).then((res)=>res.blob());
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderOutputError"]("Received malformed response from Together text-to-image API");
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/providers/zai-org.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 * See the registered mapping of HF model ID => ZAI model ID here:
 *
 * https://huggingface.co/api/partners/zai-org/models
 *
 * This is a publicly available mapping.
 *
 * If you want to try to run inference for a new model locally before it's registered on huggingface.co,
 * you can add it to the dictionary "HARDCODED_MODEL_ID_MAPPING" in consts.ts, for dev purposes.
 *
 * - If you work at zai and want to update this mapping, please use the model mapping API we provide on huggingface.co
 * - If you're a community member and want to add a new supported HF model to zai, please open an issue on the present repo
 * and we will tag zai team members.
 *
 * Thanks!
 */ __turbopack_context__.s([
    "ZaiConversationalTask",
    ()=>ZaiConversationalTask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/providerHelper.js [app-route] (ecmascript)");
;
const ZAI_API_BASE_URL = "https://api.z.ai";
class ZaiConversationalTask extends __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$providerHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BaseConversationalTask"] {
    constructor(){
        super("zai-org", ZAI_API_BASE_URL);
    }
    prepareHeaders(params, binary) {
        const headers = super.prepareHeaders(params, binary);
        headers["x-source-channel"] = "hugging_face";
        headers["accept-language"] = "en-US,en";
        return headers;
    }
    makeRoute() {
        return "/api/paas/v4/chat/completions";
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "PROVIDERS",
    ()=>PROVIDERS,
    "getProviderHelper",
    ()=>getProviderHelper
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$baseten$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/baseten.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$black$2d$forest$2d$labs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/black-forest-labs.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$cerebras$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/cerebras.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$cohere$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/cohere.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/fal-ai.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$featherless$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/featherless-ai.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fireworks$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/fireworks-ai.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$groq$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/groq.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/hf-inference.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hyperbolic$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/hyperbolic.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nebius$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/nebius.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$novita$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/novita.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nscale$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/nscale.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$openai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/openai.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$ovhcloud$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/ovhcloud.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$publicai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/publicai.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/replicate.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$sambanova$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/sambanova.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$scaleway$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/scaleway.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$together$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/together.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$zai$2d$org$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/providers/zai-org.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
const PROVIDERS = {
    baseten: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$baseten$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BasetenConversationalTask"]()
    },
    "black-forest-labs": {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$black$2d$forest$2d$labs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["BlackForestLabsTextToImageTask"]()
    },
    cerebras: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$cerebras$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CerebrasConversationalTask"]()
    },
    cohere: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$cohere$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["CohereConversationalTask"]()
    },
    "fal-ai": {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAITextToImageTask"](),
        "text-to-speech": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAITextToSpeechTask"](),
        "text-to-video": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAITextToVideoTask"](),
        "image-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAIImageToImageTask"](),
        "automatic-speech-recognition": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAIAutomaticSpeechRecognitionTask"](),
        "image-segmentation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAIImageSegmentationTask"](),
        "image-to-video": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fal$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FalAIImageToVideoTask"]()
    },
    "featherless-ai": {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$featherless$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FeatherlessAIConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$featherless$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FeatherlessAITextGenerationTask"]()
    },
    "hf-inference": {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTextToImageTask"](),
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTextGenerationTask"](),
        "text-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTextClassificationTask"](),
        "question-answering": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceQuestionAnsweringTask"](),
        "audio-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceAudioClassificationTask"](),
        "automatic-speech-recognition": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceAutomaticSpeechRecognitionTask"](),
        "fill-mask": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceFillMaskTask"](),
        "feature-extraction": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceFeatureExtractionTask"](),
        "image-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceImageClassificationTask"](),
        "image-segmentation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceImageSegmentationTask"](),
        "document-question-answering": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceDocumentQuestionAnsweringTask"](),
        "image-to-text": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceImageToTextTask"](),
        "object-detection": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceObjectDetectionTask"](),
        "audio-to-audio": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceAudioToAudioTask"](),
        "zero-shot-image-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceZeroShotImageClassificationTask"](),
        "zero-shot-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceZeroShotClassificationTask"](),
        "image-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceImageToImageTask"](),
        "sentence-similarity": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceSentenceSimilarityTask"](),
        "table-question-answering": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTableQuestionAnsweringTask"](),
        "tabular-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTabularClassificationTask"](),
        "text-to-speech": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTextToSpeechTask"](),
        "token-classification": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTokenClassificationTask"](),
        translation: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTranslationTask"](),
        summarization: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceSummarizationTask"](),
        "visual-question-answering": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceVisualQuestionAnsweringTask"](),
        "tabular-regression": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTabularRegressionTask"](),
        "text-to-audio": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTextToAudioTask"]()
    },
    "fireworks-ai": {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$fireworks$2d$ai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["FireworksConversationalTask"]()
    },
    groq: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$groq$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["GroqConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$groq$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["GroqTextGenerationTask"]()
    },
    hyperbolic: {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hyperbolic$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HyperbolicTextToImageTask"](),
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hyperbolic$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HyperbolicConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hyperbolic$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HyperbolicTextGenerationTask"]()
    },
    nebius: {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nebius$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NebiusTextToImageTask"](),
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nebius$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NebiusConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nebius$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NebiusTextGenerationTask"](),
        "feature-extraction": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nebius$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NebiusFeatureExtractionTask"]()
    },
    novita: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$novita$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NovitaConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$novita$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NovitaTextGenerationTask"](),
        "text-to-video": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$novita$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NovitaTextToVideoTask"]()
    },
    nscale: {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nscale$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NscaleTextToImageTask"](),
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$nscale$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["NscaleConversationalTask"]()
    },
    openai: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$openai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OpenAIConversationalTask"]()
    },
    ovhcloud: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$ovhcloud$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OvhCloudConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$ovhcloud$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["OvhCloudTextGenerationTask"]()
    },
    publicai: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$publicai$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PublicAIConversationalTask"]()
    },
    replicate: {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ReplicateTextToImageTask"](),
        "text-to-speech": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ReplicateTextToSpeechTask"](),
        "text-to-video": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ReplicateTextToVideoTask"](),
        "image-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ReplicateImageToImageTask"](),
        "automatic-speech-recognition": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$replicate$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ReplicateAutomaticSpeechRecognitionTask"]()
    },
    sambanova: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$sambanova$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SambanovaConversationalTask"](),
        "feature-extraction": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$sambanova$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["SambanovaFeatureExtractionTask"]()
    },
    scaleway: {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$scaleway$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ScalewayConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$scaleway$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ScalewayTextGenerationTask"](),
        "feature-extraction": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$scaleway$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ScalewayFeatureExtractionTask"]()
    },
    together: {
        "text-to-image": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$together$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TogetherTextToImageTask"](),
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$together$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TogetherConversationalTask"](),
        "text-generation": new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$together$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["TogetherTextGenerationTask"]()
    },
    "zai-org": {
        conversational: new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$zai$2d$org$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["ZaiConversationalTask"]()
    }
};
function getProviderHelper(provider, task) {
    if (provider === "hf-inference" && !task || provider === "auto") {
        return new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$providers$2f$hf$2d$inference$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HFInferenceTask"]();
    }
    if (!task) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("you need to provide a task name when using an external provider, e.g. 'text-to-image'");
    }
    if (!(provider in PROVIDERS)) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Provider '${provider}' not supported. Available providers: ${Object.keys(PROVIDERS)}`);
    }
    const providerTasks = PROVIDERS[provider];
    if (!providerTasks || !(task in providerTasks)) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Task '${task}' not supported for provider '${provider}'. Available tasks: ${Object.keys(providerTasks ?? {})}`);
    }
    return providerTasks[task];
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/package.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

// Generated file from package.json. Issues importing JSON directly when publishing on commonjs/ESM - see https://github.com/microsoft/TypeScript/issues/51783
__turbopack_context__.s([
    "PACKAGE_NAME",
    ()=>PACKAGE_NAME,
    "PACKAGE_VERSION",
    ()=>PACKAGE_VERSION
]);
const PACKAGE_VERSION = "4.10.0";
const PACKAGE_NAME = "@huggingface/inference";
}),
"[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "makeRequestOptions",
    ()=>makeRequestOptions,
    "makeRequestOptionsFromResolvedModel",
    ()=>makeRequestOptionsFromResolvedModel
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$package$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/package.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/isUrl.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
;
;
/**
 * Lazy-loaded from huggingface.co/api/tasks when needed
 * Used to determine the default model to use when it's not user defined
 */ let tasks = null;
async function makeRequestOptions(args, providerHelper, options) {
    const { model: maybeModel } = args;
    const provider = providerHelper.provider;
    const { task } = options ?? {};
    // Validate inputs
    if (args.endpointUrl && provider !== "hf-inference") {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Cannot use endpointUrl with a third-party provider.`);
    }
    if (maybeModel && (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$isUrl$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["isUrl"])(maybeModel)) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Model URLs are no longer supported. Use endpointUrl instead.`);
    }
    if (args.endpointUrl) {
        // No need to have maybeModel, or to load default model for a task
        return makeRequestOptionsFromResolvedModel(maybeModel ?? args.endpointUrl, providerHelper, args, undefined, options);
    }
    if (!maybeModel && !task) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"]("No model provided, and no task has been specified.");
    }
    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
    const hfModel = maybeModel ?? await loadDefaultModel(task);
    if (providerHelper.clientSideRoutingOnly && !maybeModel) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Provider ${provider} requires a model ID to be passed directly.`);
    }
    const inferenceProviderMapping = providerHelper.clientSideRoutingOnly ? {
        provider: provider,
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        providerId: removeProviderPrefix(maybeModel, provider),
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        hfModelId: maybeModel,
        status: "live",
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        task: task
    } : await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getInferenceProviderMapping"])({
        modelId: hfModel,
        // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
        task: task,
        provider,
        accessToken: args.accessToken
    }, {
        fetch: options?.fetch
    });
    if (!inferenceProviderMapping) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`We have not been able to find inference provider information for model ${hfModel}.`);
    }
    // Use the sync version with the resolved model
    return makeRequestOptionsFromResolvedModel(inferenceProviderMapping.providerId, providerHelper, args, inferenceProviderMapping, options);
}
function makeRequestOptionsFromResolvedModel(resolvedModel, providerHelper, args, mapping, options) {
    const { accessToken, endpointUrl, provider: maybeProvider, model, ...remainingArgs } = args;
    void model;
    void maybeProvider;
    const provider = providerHelper.provider;
    const { includeCredentials, task, signal, billTo } = options ?? {};
    const authMethod = (()=>{
        if (providerHelper.clientSideRoutingOnly) {
            // Closed-source providers require an accessToken (cannot be routed).
            if (accessToken && accessToken.startsWith("hf_")) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Provider ${provider} is closed-source and does not support HF tokens.`);
            }
        }
        if (accessToken) {
            return accessToken.startsWith("hf_") ? "hf-token" : "provider-key";
        }
        if (includeCredentials === "include") {
            // If accessToken is passed, it should take precedence over includeCredentials
            return "credentials-include";
        }
        return "none";
    })();
    // Make URL
    const modelId = endpointUrl ?? resolvedModel;
    const url = providerHelper.makeUrl({
        authMethod,
        model: modelId,
        task
    });
    // Make headers
    const headers = providerHelper.prepareHeaders({
        accessToken,
        authMethod
    }, "data" in args && !!args.data);
    if (billTo) {
        headers[__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_HEADER_X_BILL_TO"]] = billTo;
    }
    // Add user-agent to headers
    // e.g. @huggingface/inference/3.1.3
    const ownUserAgent = `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$package$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PACKAGE_NAME"]}/${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$package$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["PACKAGE_VERSION"]}`;
    const userAgent = [
        ownUserAgent,
        typeof navigator !== "undefined" ? navigator.userAgent : undefined
    ].filter((x)=>x !== undefined).join(" ");
    headers["User-Agent"] = userAgent;
    // Make body
    const body = providerHelper.makeBody({
        args: remainingArgs,
        model: resolvedModel,
        task,
        mapping
    });
    /**
     * For edge runtimes, leave 'credentials' undefined, otherwise cloudflare workers will error
     */ let credentials;
    if (typeof includeCredentials === "string") {
        credentials = includeCredentials;
    } else if (includeCredentials === true) {
        credentials = "include";
    }
    const info = {
        headers,
        method: "POST",
        body: body,
        ...credentials ? {
            credentials
        } : undefined,
        signal
    };
    return {
        url,
        info
    };
}
async function loadDefaultModel(task) {
    if (!tasks) {
        tasks = await loadTaskInfo();
    }
    const taskInfo = tasks[task];
    if ((taskInfo?.models.length ?? 0) <= 0) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`No default model defined for task ${task}, please define the model explicitly.`);
    }
    return taskInfo.models[0].id;
}
async function loadTaskInfo() {
    const url = `${__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_HUB_URL"]}/api/tasks`;
    const res = await fetch(url);
    if (!res.ok) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientHubApiError"]("Failed to load tasks definitions from Hugging Face Hub.", {
            url,
            method: "GET"
        }, {
            requestId: res.headers.get("x-request-id") ?? "",
            status: res.status,
            body: await res.text()
        });
    }
    return await res.json();
}
function removeProviderPrefix(model, provider) {
    if (!model.startsWith(`${provider}/`)) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientInputError"](`Models from ${provider} must be prefixed by "${provider}/". Got "${model}".`);
    }
    return model.slice(provider.length + 1);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/vendor/fetch-event-source/parse.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

/**
 This file is a part of fetch-event-source package (as of v2.0.1)
 https://github.com/Azure/fetch-event-source/blob/v2.0.1/src/parse.ts

 Full package can be used after it is made compatible with nodejs:
 https://github.com/Azure/fetch-event-source/issues/20

 Below is the fetch-event-source package license:

 MIT License

 Copyright (c) Microsoft Corporation.

 Permission is hereby granted, free of charge, to any person obtaining a copy
 of this software and associated documentation files (the "Software"), to deal
 in the Software without restriction, including without limitation the rights
 to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 copies of the Software, and to permit persons to whom the Software is
 furnished to do so, subject to the following conditions:

 The above copyright notice and this permission notice shall be included in all
 copies or substantial portions of the Software.

 THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE

 */ /**
 * Converts a ReadableStream into a callback pattern.
 * @param stream The input ReadableStream.
 * @param onChunk A function that will be called on each new byte chunk in the stream.
 * @returns {Promise<void>} A promise that will be resolved when the stream closes.
 */ __turbopack_context__.s([
    "getBytes",
    ()=>getBytes,
    "getLines",
    ()=>getLines,
    "getMessages",
    ()=>getMessages
]);
async function getBytes(stream, onChunk) {
    const reader = stream.getReader();
    let result;
    while(!(result = await reader.read()).done){
        onChunk(result.value);
    }
}
function getLines(onLine) {
    let buffer;
    let position; // current read position
    let fieldLength; // length of the `field` portion of the line
    let discardTrailingNewline = false;
    // return a function that can process each incoming byte chunk:
    return function onChunk(arr) {
        if (buffer === undefined) {
            buffer = arr;
            position = 0;
            fieldLength = -1;
        } else {
            // we're still parsing the old line. Append the new bytes into buffer:
            buffer = concat(buffer, arr);
        }
        const bufLength = buffer.length;
        let lineStart = 0; // index where the current line starts
        while(position < bufLength){
            if (discardTrailingNewline) {
                if (buffer[position] === 10 /* ControlChars.NewLine */ ) {
                    lineStart = ++position; // skip to next char
                }
                discardTrailingNewline = false;
            }
            // start looking forward till the end of line:
            let lineEnd = -1; // index of the \r or \n char
            for(; position < bufLength && lineEnd === -1; ++position){
                switch(buffer[position]){
                    case 58 /* ControlChars.Colon */ :
                        if (fieldLength === -1) {
                            fieldLength = position - lineStart;
                        }
                        break;
                    case 13 /* ControlChars.CarriageReturn */ :
                        discardTrailingNewline = true;
                    // eslint-disable-next-line no-fallthrough
                    case 10 /* ControlChars.NewLine */ :
                        lineEnd = position;
                        break;
                }
            }
            if (lineEnd === -1) {
                break;
            }
            // we've reached the line end, send it out:
            onLine(buffer.subarray(lineStart, lineEnd), fieldLength);
            lineStart = position; // we're now on the next line
            fieldLength = -1;
        }
        if (lineStart === bufLength) {
            buffer = undefined; // we've finished reading it
        } else if (lineStart !== 0) {
            // Create a new view into buffer beginning at lineStart so we don't
            // need to copy over the previous lines when we get the new arr:
            buffer = buffer.subarray(lineStart);
            position -= lineStart;
        }
    };
}
function getMessages(onId, onRetry, onMessage) {
    let message = newMessage();
    const decoder = new TextDecoder();
    // return a function that can process each incoming line buffer:
    return function onLine(line, fieldLength) {
        if (line.length === 0) {
            // empty line denotes end of message. Trigger the callback and start a new message:
            onMessage?.(message);
            message = newMessage();
        } else if (fieldLength > 0) {
            // line is of format "<field>:<value>" or "<field>: <value>"
            // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation
            const field = decoder.decode(line.subarray(0, fieldLength));
            const valueOffset = fieldLength + (line[fieldLength + 1] === 32 /* ControlChars.Space */  ? 2 : 1);
            const value = decoder.decode(line.subarray(valueOffset));
            switch(field){
                case 'data':
                    // if this message already has data, append the new value to the old.
                    // otherwise, just set to the new value:
                    message.data = message.data ? message.data + '\n' + value : value; // otherwise, 
                    break;
                case 'event':
                    message.event = value;
                    break;
                case 'id':
                    onId(message.id = value);
                    break;
                case 'retry':
                    {
                        const retry = parseInt(value, 10);
                        if (!isNaN(retry)) {
                            onRetry(message.retry = retry);
                        }
                        break;
                    }
            }
        }
    };
}
function concat(a, b) {
    const res = new Uint8Array(a.length + b.length);
    res.set(a);
    res.set(b, a.length);
    return res;
}
function newMessage() {
    // data, event, and id must be initialized to empty strings:
    // https://html.spec.whatwg.org/multipage/server-sent-events.html#event-stream-interpretation
    // retry should be initialized to undefined so we return a consistent shape
    // to the js engine all the time: https://mathiasbynens.be/notes/shapes-ics#takeaways
    return {
        data: '',
        event: '',
        id: '',
        retry: undefined
    };
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "innerRequest",
    ()=>innerRequest,
    "innerStreamingRequest",
    ()=>innerStreamingRequest
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$vendor$2f$fetch$2d$event$2d$source$2f$parse$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/vendor/fetch-event-source/parse.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
;
;
;
function bodyToJson(body) {
    let data = null;
    if (body instanceof Blob || body instanceof ArrayBuffer) {
        data = "[Blob or ArrayBuffer]";
    } else if (typeof body === "string") {
        try {
            data = JSON.parse(body);
        } catch  {
            data = body;
        }
    }
    if (data.accessToken) {
        data.accessToken = "[REDACTED]";
    }
    return data;
}
async function innerRequest(args, providerHelper, options) {
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, options);
    const response = await (options?.fetch ?? fetch)(url, info);
    const requestContext = {
        url,
        info
    };
    if (options?.retry_on_error !== false && response.status === 503) {
        return innerRequest(args, providerHelper, options);
    }
    if (!response.ok) {
        const contentType = response.headers.get("Content-Type");
        if ([
            "application/json",
            "application/problem+json"
        ].some((ct)=>contentType?.startsWith(ct))) {
            const output = await response.json();
            if ([
                400,
                422,
                404,
                500
            ].includes(response.status) && options?.chatCompletion) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
            if (typeof output.error === "string" || typeof output.detail === "string" || typeof output.message === "string") {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: ${output.error ?? output.detail ?? output.message}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            } else {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
        }
        const message = contentType?.startsWith("text/plain;") ? await response.text() : undefined;
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: ${message ?? "an HTTP error occurred when requesting the provider"}`, {
            url,
            method: info.method ?? "GET",
            headers: info.headers,
            body: bodyToJson(info.body)
        }, {
            requestId: response.headers.get("x-request-id") ?? "",
            status: response.status,
            body: message ?? ""
        });
    }
    if (response.headers.get("Content-Type")?.startsWith("application/json")) {
        const data = await response.json();
        return {
            data,
            requestContext
        };
    }
    const blob = await response.blob();
    return {
        data: blob,
        requestContext
    };
}
async function* innerStreamingRequest(args, providerHelper, options) {
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])({
        ...args,
        stream: true
    }, providerHelper, options);
    const response = await (options?.fetch ?? fetch)(url, info);
    if (options?.retry_on_error !== false && response.status === 503) {
        return yield* innerStreamingRequest(args, providerHelper, options);
    }
    if (!response.ok) {
        if (response.headers.get("Content-Type")?.startsWith("application/json")) {
            const output = await response.json();
            if ([
                400,
                422,
                404,
                500
            ].includes(response.status) && options?.chatCompletion) {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Provider ${args.provider} does not seem to support chat completion for model ${args.model} . Error: ${JSON.stringify(output.error)}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
            if (typeof output.error === "string") {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: ${output.error}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
            if (output.error && "message" in output.error && typeof output.error.message === "string") {
                /// OpenAI errors
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: ${output.error.message}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
            // Sambanova errors
            if (typeof output.message === "string") {
                throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: ${output.message}`, {
                    url,
                    method: info.method ?? "GET",
                    headers: info.headers,
                    body: bodyToJson(info.body)
                }, {
                    requestId: response.headers.get("x-request-id") ?? "",
                    status: response.status,
                    body: output
                });
            }
        }
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: an HTTP error occurred when requesting the provider.`, {
            url,
            method: info.method ?? "GET",
            headers: info.headers,
            body: bodyToJson(info.body)
        }, {
            requestId: response.headers.get("x-request-id") ?? "",
            status: response.status,
            body: ""
        });
    }
    if (!response.headers.get("content-type")?.startsWith("text/event-stream")) {
        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: server does not support event stream content type, it returned ` + response.headers.get("content-type"), {
            url,
            method: info.method ?? "GET",
            headers: info.headers,
            body: bodyToJson(info.body)
        }, {
            requestId: response.headers.get("x-request-id") ?? "",
            status: response.status,
            body: ""
        });
    }
    if (!response.body) {
        return;
    }
    const reader = response.body.getReader();
    let events = [];
    const onEvent = (event)=>{
        // accumulate events in array
        events.push(event);
    };
    const onChunk = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$vendor$2f$fetch$2d$event$2d$source$2f$parse$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLines"])((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$vendor$2f$fetch$2d$event$2d$source$2f$parse$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getMessages"])(()=>{}, ()=>{}, onEvent));
    try {
        while(true){
            const { done, value } = await reader.read();
            if (done) {
                return;
            }
            onChunk(value);
            for (const event of events){
                if (event.data.length > 0) {
                    if (event.data === "[DONE]") {
                        return;
                    }
                    const data = JSON.parse(event.data);
                    if (typeof data === "object" && data !== null && "error" in data) {
                        const errorStr = typeof data.error === "string" ? data.error : typeof data.error === "object" && data.error && "message" in data.error && typeof data.error.message === "string" ? data.error.message : JSON.stringify(data.error);
                        throw new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["InferenceClientProviderApiError"](`Failed to perform inference: an occurred while streaming the response: ${errorStr}`, {
                            url,
                            method: info.method ?? "GET",
                            headers: info.headers,
                            body: bodyToJson(info.body)
                        }, {
                            requestId: response.headers.get("x-request-id") ?? "",
                            status: response.status,
                            body: data
                        });
                    }
                    yield data;
                }
            }
            events = [];
        }
    } finally{
        reader.releaseLock();
    }
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/request.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "request",
    ()=>request
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
;
;
;
;
async function request(args, options) {
    const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
    logger.warn("The request method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.");
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, options?.task);
    const result = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, options);
    return result.data;
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/streamingRequest.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "streamingRequest",
    ()=>streamingRequest
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
;
;
;
;
async function* streamingRequest(args, options) {
    const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
    logger.warn("The streamingRequest method is deprecated and will be removed in a future version of huggingface.js. Use specific task functions instead.");
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, options?.task);
    yield* (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerStreamingRequest"])(args, providerHelper, options);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/utils.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "preparePayload",
    ()=>preparePayload
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
;
function preparePayload(args) {
    return "data" in args ? args : {
        ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "inputs"),
        data: args.inputs
    };
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "audioClassification",
    ()=>audioClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/utils.js [app-route] (ecmascript)");
;
;
;
;
async function audioClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "audio-classification");
    const payload = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["preparePayload"])(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "audio-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioToAudio.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "audioToAudio",
    ()=>audioToAudio
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/utils.js [app-route] (ecmascript)");
;
;
;
;
async function audioToAudio(args, options) {
    const model = "inputs" in args ? args.model : undefined;
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, model);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "audio-to-audio");
    const payload = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["preparePayload"])(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "audio-to-audio"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/automaticSpeechRecognition.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "automaticSpeechRecognition",
    ()=>automaticSpeechRecognition
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function automaticSpeechRecognition(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "automatic-speech-recognition");
    const payload = await providerHelper.preparePayloadAsync(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "automatic-speech-recognition"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/textToSpeech.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textToSpeech",
    ()=>textToSpeech
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function textToSpeech(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-to-speech");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "text-to-speech"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/utils.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "preparePayload",
    ()=>preparePayload
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
;
function preparePayload(args) {
    return "data" in args ? args : {
        ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(args, "inputs"),
        data: args.inputs
    };
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "imageClassification",
    ()=>imageClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/utils.js [app-route] (ecmascript)");
;
;
;
;
async function imageClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "image-classification");
    const payload = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["preparePayload"])(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "image-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageSegmentation.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "imageSegmentation",
    ()=>imageSegmentation
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
;
;
;
;
async function imageSegmentation(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "image-segmentation");
    const payload = await providerHelper.preparePayloadAsync(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "image-segmentation"
    });
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, {
        ...options,
        task: "image-segmentation"
    });
    return providerHelper.getResponse(res, url, info.headers);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToImage.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "imageToImage",
    ()=>imageToImage
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
;
;
;
;
async function imageToImage(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "image-to-image");
    const payload = await providerHelper.preparePayloadAsync(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "image-to-image"
    });
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, {
        ...options,
        task: "image-to-image"
    });
    return providerHelper.getResponse(res, url, info.headers);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToText.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "imageToText",
    ()=>imageToText
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/utils.js [app-route] (ecmascript)");
;
;
;
;
async function imageToText(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "image-to-text");
    const payload = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["preparePayload"])(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "image-to-text"
    });
    return providerHelper.getResponse(res[0]);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToVideo.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "imageToVideo",
    ()=>imageToVideo
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
;
;
;
;
async function imageToVideo(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "image-to-video");
    const payload = await providerHelper.preparePayloadAsync(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "image-to-video"
    });
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, {
        ...options,
        task: "image-to-video"
    });
    return providerHelper.getResponse(res, url, info.headers);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/objectDetection.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "objectDetection",
    ()=>objectDetection
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/utils.js [app-route] (ecmascript)");
;
;
;
;
async function objectDetection(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "object-detection");
    const payload = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$utils$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["preparePayload"])(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "object-detection"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToImage.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textToImage",
    ()=>textToImage
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
;
async function textToImage(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-to-image");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "text-to-image"
    });
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, {
        ...options,
        task: "text-to-image"
    });
    return providerHelper.getResponse(res, url, info.headers, options?.outputType);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToVideo.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textToVideo",
    ()=>textToVideo
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
;
async function textToVideo(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-to-video");
    const { data: response } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "text-to-video"
    });
    const { url, info } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptions"])(args, providerHelper, {
        ...options,
        task: "text-to-video"
    });
    return providerHelper.getResponse(response, url, info.headers);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/zeroShotImageClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "zeroShotImageClassification",
    ()=>zeroShotImageClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
;
async function preparePayload(args) {
    if (args.inputs instanceof Blob) {
        return {
            ...args,
            inputs: {
                image: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(await args.inputs.arrayBuffer()))
            }
        };
    } else {
        return {
            ...args,
            inputs: {
                image: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(args.inputs.image instanceof ArrayBuffer ? args.inputs.image : await args.inputs.image.arrayBuffer()))
            }
        };
    }
}
async function zeroShotImageClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "zero-shot-image-classification");
    const payload = await preparePayload(args);
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(payload, providerHelper, {
        ...options,
        task: "zero-shot-image-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletion.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "chatCompletion",
    ()=>chatCompletion
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function chatCompletion(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "conversational");
    const { data: response } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "conversational"
    });
    return providerHelper.getResponse(response);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletionStream.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "chatCompletionStream",
    ()=>chatCompletionStream
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function* chatCompletionStream(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "conversational");
    yield* (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerStreamingRequest"])(args, providerHelper, {
        ...options,
        task: "conversational"
    });
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/featureExtraction.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "featureExtraction",
    ()=>featureExtraction
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function featureExtraction(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "feature-extraction");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "feature-extraction"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/fillMask.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "fillMask",
    ()=>fillMask
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function fillMask(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "fill-mask");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "fill-mask"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/questionAnswering.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "questionAnswering",
    ()=>questionAnswering
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function questionAnswering(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "question-answering");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "question-answering"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/sentenceSimilarity.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "sentenceSimilarity",
    ()=>sentenceSimilarity
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function sentenceSimilarity(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "sentence-similarity");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "sentence-similarity"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/summarization.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "summarization",
    ()=>summarization
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function summarization(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "summarization");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "summarization"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tableQuestionAnswering.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "tableQuestionAnswering",
    ()=>tableQuestionAnswering
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function tableQuestionAnswering(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "table-question-answering");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "table-question-answering"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textClassification",
    ()=>textClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function textClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-classification");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "text-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGeneration.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textGeneration",
    ()=>textGeneration
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function textGeneration(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-generation");
    const { data: response } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "text-generation"
    });
    return providerHelper.getResponse(response);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGenerationStream.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "textGenerationStream",
    ()=>textGenerationStream
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function* textGenerationStream(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "text-generation");
    yield* (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerStreamingRequest"])(args, providerHelper, {
        ...options,
        task: "text-generation"
    });
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tokenClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "tokenClassification",
    ()=>tokenClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function tokenClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "token-classification");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "token-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/translation.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "translation",
    ()=>translation
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function translation(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "translation");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "translation"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/zeroShotClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "zeroShotClassification",
    ()=>zeroShotClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function zeroShotClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "zero-shot-classification");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "zero-shot-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/documentQuestionAnswering.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "documentQuestionAnswering",
    ()=>documentQuestionAnswering
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
;
async function documentQuestionAnswering(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "document-question-answering");
    const reqArgs = {
        ...args,
        inputs: {
            question: args.inputs.question,
            // convert Blob or ArrayBuffer to base64
            image: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(await args.inputs.image.arrayBuffer()))
        }
    };
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(reqArgs, providerHelper, {
        ...options,
        task: "document-question-answering"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/visualQuestionAnswering.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "visualQuestionAnswering",
    ()=>visualQuestionAnswering
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/base64FromBytes.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
;
async function visualQuestionAnswering(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "visual-question-answering");
    const reqArgs = {
        ...args,
        inputs: {
            question: args.inputs.question,
            // convert Blob or ArrayBuffer to base64
            image: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$base64FromBytes$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["base64FromBytes"])(new Uint8Array(await args.inputs.image.arrayBuffer()))
        }
    };
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(reqArgs, providerHelper, {
        ...options,
        task: "visual-question-answering"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularClassification.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "tabularClassification",
    ()=>tabularClassification
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function tabularClassification(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "tabular-classification");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "tabular-classification"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularRegression.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "tabularRegression",
    ()=>tabularRegression
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getInferenceProviderMapping.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/request.js [app-route] (ecmascript)");
;
;
;
async function tabularRegression(args, options) {
    const provider = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getInferenceProviderMapping$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["resolveProvider"])(args.provider, args.model, args.endpointUrl);
    const providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, "tabular-regression");
    const { data: res } = await (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["innerRequest"])(args, providerHelper, {
        ...options,
        task: "tabular-regression"
    });
    return providerHelper.getResponse(res);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

// Custom tasks with arbitrary inputs and outputs
__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$streamingRequest$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/streamingRequest.js [app-route] (ecmascript)");
// Audio tasks
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioToAudio$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioToAudio.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$automaticSpeechRecognition$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/automaticSpeechRecognition.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$textToSpeech$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/textToSpeech.js [app-route] (ecmascript)");
// Computer Vision tasks
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageSegmentation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageSegmentation.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToImage.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToText$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToText.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToVideo.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$objectDetection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/objectDetection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToImage.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToVideo.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$zeroShotImageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/zeroShotImageClassification.js [app-route] (ecmascript)");
// Natural Language Processing tasks
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletion$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletion.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletionStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletionStream.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$featureExtraction$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/featureExtraction.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$fillMask$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/fillMask.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$questionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/questionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$sentenceSimilarity$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/sentenceSimilarity.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$summarization$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/summarization.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tableQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tableQuestionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGeneration$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGeneration.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGenerationStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGenerationStream.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tokenClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tokenClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$translation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/translation.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$zeroShotClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/zeroShotClassification.js [app-route] (ecmascript)");
// Multimodal tasks
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$documentQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/documentQuestionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$visualQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/visualQuestionAnswering.js [app-route] (ecmascript)");
// Tabular tasks
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularRegression$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularRegression.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
;
}),
"[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "audioClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["audioClassification"],
    "audioToAudio",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioToAudio$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["audioToAudio"],
    "automaticSpeechRecognition",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$automaticSpeechRecognition$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["automaticSpeechRecognition"],
    "chatCompletion",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletion$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["chatCompletion"],
    "chatCompletionStream",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletionStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["chatCompletionStream"],
    "documentQuestionAnswering",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$documentQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["documentQuestionAnswering"],
    "featureExtraction",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$featureExtraction$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["featureExtraction"],
    "fillMask",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$fillMask$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["fillMask"],
    "imageClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["imageClassification"],
    "imageSegmentation",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageSegmentation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["imageSegmentation"],
    "imageToImage",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["imageToImage"],
    "imageToText",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToText$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["imageToText"],
    "imageToVideo",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["imageToVideo"],
    "objectDetection",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$objectDetection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["objectDetection"],
    "questionAnswering",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$questionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["questionAnswering"],
    "request",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["request"],
    "sentenceSimilarity",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$sentenceSimilarity$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["sentenceSimilarity"],
    "streamingRequest",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$streamingRequest$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["streamingRequest"],
    "summarization",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$summarization$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["summarization"],
    "tableQuestionAnswering",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tableQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tableQuestionAnswering"],
    "tabularClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tabularClassification"],
    "tabularRegression",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularRegression$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tabularRegression"],
    "textClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textClassification"],
    "textGeneration",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGeneration$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textGeneration"],
    "textGenerationStream",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGenerationStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textGenerationStream"],
    "textToImage",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textToImage"],
    "textToSpeech",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$textToSpeech$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textToSpeech"],
    "textToVideo",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["textToVideo"],
    "tokenClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tokenClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["tokenClassification"],
    "translation",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$translation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["translation"],
    "visualQuestionAnswering",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$visualQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["visualQuestionAnswering"],
    "zeroShotClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$zeroShotClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["zeroShotClassification"],
    "zeroShotImageClassification",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$zeroShotImageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["zeroShotImageClassification"]
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$request$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/request.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$custom$2f$streamingRequest$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/custom/streamingRequest.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$audioToAudio$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/audioToAudio.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$automaticSpeechRecognition$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/automaticSpeechRecognition.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$audio$2f$textToSpeech$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/audio/textToSpeech.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageSegmentation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageSegmentation.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToImage.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToText$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToText.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$imageToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/imageToVideo.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$objectDetection$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/objectDetection.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToImage$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToImage.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$textToVideo$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/textToVideo.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$cv$2f$zeroShotImageClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/cv/zeroShotImageClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletion$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletion.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$chatCompletionStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/chatCompletionStream.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$featureExtraction$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/featureExtraction.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$fillMask$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/fillMask.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$questionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/questionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$sentenceSimilarity$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/sentenceSimilarity.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$summarization$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/summarization.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tableQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tableQuestionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGeneration$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGeneration.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$textGenerationStream$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/textGenerationStream.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$tokenClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/tokenClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$translation$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/translation.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$nlp$2f$zeroShotClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/nlp/zeroShotClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$documentQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/documentQuestionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$multimodal$2f$visualQuestionAnswering$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/multimodal/visualQuestionAnswering.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularClassification$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularClassification.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$tabular$2f$tabularRegression$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/tabular/tabularRegression.js [app-route] (ecmascript)");
}),
"[project]/node_modules/@huggingface/inference/dist/esm/utils/typedEntries.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "typedEntries",
    ()=>typedEntries
]);
function typedEntries(obj) {
    return Object.entries(obj);
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/InferenceClient.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "HfInference",
    ()=>HfInference,
    "InferenceClient",
    ()=>InferenceClient,
    "InferenceClientEndpoint",
    ()=>InferenceClientEndpoint
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/omit.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedEntries$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/utils/typedEntries.js [app-route] (ecmascript)");
;
;
;
class InferenceClient {
    accessToken;
    defaultOptions;
    constructor(accessToken = "", defaultOptions = {}){
        this.accessToken = accessToken;
        this.defaultOptions = defaultOptions;
        for (const [name, fn] of (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$typedEntries$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["typedEntries"])(__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__)){
            Object.defineProperty(this, name, {
                enumerable: false,
                value: (params, options)=>// eslint-disable-next-line @typescript-eslint/no-explicit-any
                    fn(/// ^ The cast of fn to any is necessary, otherwise TS can't compile because the generated union type is too complex
                    {
                        endpointUrl: defaultOptions.endpointUrl,
                        accessToken,
                        ...params
                    }, {
                        ...(0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$utils$2f$omit$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["omit"])(defaultOptions, [
                            "endpointUrl"
                        ]),
                        ...options
                    })
            });
        }
    }
    /**
     * Returns a new instance of InferenceClient tied to a specified endpoint.
     *
     * For backward compatibility mostly.
     */ endpoint(endpointUrl) {
        return new InferenceClient(this.accessToken, {
            ...this.defaultOptions,
            endpointUrl
        });
    }
}
class HfInference extends InferenceClient {
}
class InferenceClientEndpoint extends InferenceClient {
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/types.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "INFERENCE_PROVIDERS",
    ()=>INFERENCE_PROVIDERS,
    "PROVIDERS_OR_POLICIES",
    ()=>PROVIDERS_OR_POLICIES
]);
const INFERENCE_PROVIDERS = [
    "baseten",
    "black-forest-labs",
    "cerebras",
    "cohere",
    "fal-ai",
    "featherless-ai",
    "fireworks-ai",
    "groq",
    "hf-inference",
    "hyperbolic",
    "nebius",
    "novita",
    "nscale",
    "openai",
    "ovhcloud",
    "publicai",
    "replicate",
    "sambanova",
    "scaleway",
    "together",
    "zai-org"
];
const PROVIDERS_OR_POLICIES = [
    ...INFERENCE_PROVIDERS,
    "auto"
];
}),
"[project]/node_modules/@huggingface/inference/dist/esm/snippets/templates.exported.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

// Generated file - do not edit directly
__turbopack_context__.s([
    "templates",
    ()=>templates
]);
const templates = {
    "js": {
        "fetch": {
            "basic": "async function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});",
            "basicAudio": "async function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"audio/flac\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});",
            "basicImage": "async function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"image/jpeg\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});",
            "conversational": "async function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({ \n{{ autoInputs.asTsString }}\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});",
            "imageToImage": "const image = fs.readFileSync(\"{{inputs.asObj.inputs}}\");\n\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"image/jpeg\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: {\n\t\t\t\t\"inputs\": `data:image/png;base64,${data.inputs.encode(\"base64\")}`,\n\t\t\t\t\"parameters\": data.parameters,\n\t\t\t}\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({ \n\tinputs: image,\n\tparameters: {\n\t\tprompt: \"{{ inputs.asObj.parameters.prompt }}\",\n\t}\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});",
            "imageToVideo": "const image = fs.readFileSync(\"{{inputs.asObj.inputs}}\");\n\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"image/jpeg\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: {\n\t\t\t\t\"image_url\": `data:image/png;base64,${data.image.encode(\"base64\")}`,\n\t\t\t\t\"prompt\": data.prompt,\n\t\t\t}\n\t\t}\n\t);\n\tconst result = await response.json();\n\treturn result;\n}\n\nquery({\n\t\"image\": image,\n\t\"prompt\": \"{{inputs.asObj.parameters.prompt}}\",\n}).then((response) => {\n    // Use video\n});",
            "textToAudio": "{% if model.library_name == \"transformers\" %}\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.blob();\n    return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    // Returns a byte object of the Audio wavform. Use it directly!\n});\n{% else %}\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n    const result = await response.json();\n    return result;\n}\n\nquery({ inputs: {{ providerInputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});\n{% endif %} ",
            "textToImage": "async function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.blob();\n\treturn result;\n}\n\n\nquery({ {{ providerInputs.asTsString }} }).then((response) => {\n    // Use image\n});",
            "textToSpeech": "{% if model.library_name == \"transformers\" %}\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n{% if billTo %}\n\t\t\t\t\"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n\tconst result = await response.blob();\n    return result;\n}\n\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\n    // Returns a byte object of the Audio wavform. Use it directly!\n});\n{% else %}\nasync function query(data) {\n\tconst response = await fetch(\n\t\t\"{{ fullUrl }}\",\n\t\t{\n\t\t\theaders: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n\t\t\t\t\"Content-Type\": \"application/json\",\n\t\t\t},\n\t\t\tmethod: \"POST\",\n\t\t\tbody: JSON.stringify(data),\n\t\t}\n\t);\n    const result = await response.json();\n    return result;\n}\n\nquery({ text: {{ inputs.asObj.inputs }} }).then((response) => {\n    console.log(JSON.stringify(response));\n});\n{% endif %} ",
            "zeroShotClassification": "async function query(data) {\n    const response = await fetch(\n\t\t\"{{ fullUrl }}\",\n        {\n            headers: {\n\t\t\t\tAuthorization: \"{{ authorizationHeader }}\",\n                \"Content-Type\": \"application/json\",\n{% if billTo %}\n                \"X-HF-Bill-To\": \"{{ billTo }}\",\n{% endif %}         },\n            method: \"POST\",\n            body: JSON.stringify(data),\n        }\n    );\n    const result = await response.json();\n    return result;\n}\n\nquery({\n    inputs: {{ providerInputs.asObj.inputs }},\n    parameters: { candidate_labels: [\"refund\", \"legal\", \"faq\"] }\n}).then((response) => {\n    console.log(JSON.stringify(response));\n});"
        },
        "huggingface.js": {
            "basic": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n\tmodel: \"{{ model.id }}\",\n\tinputs: {{ inputs.asObj.inputs }},\n\tprovider: \"{{ provider }}\",\n}{% if billTo %}, {\n\tbillTo: \"{{ billTo }}\",\n}{% endif %});\n\nconsole.log(output);",
            "basicAudio": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n\tdata,\n\tmodel: \"{{ model.id }}\",\n\tprovider: \"{{ provider }}\",\n}{% if billTo %}, {\n\tbillTo: \"{{ billTo }}\",\n}{% endif %});\n\nconsole.log(output);",
            "basicImage": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst data = fs.readFileSync({{inputs.asObj.inputs}});\n\nconst output = await client.{{ methodName }}({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n\tdata,\n\tmodel: \"{{ model.id }}\",\n\tprovider: \"{{ provider }}\",\n}{% if billTo %}, {\n\tbillTo: \"{{ billTo }}\",\n}{% endif %});\n\nconsole.log(output);",
            "conversational": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst chatCompletion = await client.chatCompletion({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n    provider: \"{{ provider }}\",\n    model: \"{{ model.id }}\",\n{{ inputs.asTsString }}\n}{% if billTo %}, {\n    billTo: \"{{ billTo }}\",\n}{% endif %});\n\nconsole.log(chatCompletion.choices[0].message);",
            "conversationalStream": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nlet out = \"\";\n\nconst stream = client.chatCompletionStream({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n    provider: \"{{ provider }}\",\n    model: \"{{ model.id }}\",\n{{ inputs.asTsString }}\n}{% if billTo %}, {\n    billTo: \"{{ billTo }}\",\n}{% endif %});\n\nfor await (const chunk of stream) {\n\tif (chunk.choices && chunk.choices.length > 0) {\n\t\tconst newContent = chunk.choices[0].delta.content;\n\t\tout += newContent;\n\t\tconsole.log(newContent);\n\t}\n}",
            "imageToImage": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst data = fs.readFileSync(\"{{inputs.asObj.inputs}}\");\n\nconst image = await client.imageToImage({\n{% if endpointUrl %}\n\tendpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n\tprovider: \"{{provider}}\",\n\tmodel: \"{{model.id}}\",\n\tinputs: data,\n\tparameters: { prompt: \"{{inputs.asObj.parameters.prompt}}\", },\n}{% if billTo %}, {\n\tbillTo: \"{{ billTo }}\",\n}{% endif %});\n/// Use the generated image (it's a Blob)\n// For example, you can save it to a file or display it in an image element\n",
            "imageToVideo": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst data = fs.readFileSync(\"{{inputs.asObj.inputs}}\");\n\nconst video = await client.imageToVideo({\n{% if endpointUrl %}\n\tendpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n\tprovider: \"{{provider}}\",\n\tmodel: \"{{model.id}}\",\n\tinputs: data,\n\tparameters: { prompt: \"{{inputs.asObj.parameters.prompt}}\", },\n}{% if billTo %}, {\n\tbillTo: \"{{ billTo }}\",\n}{% endif %});\n\n/// Use the generated video (it's a Blob)\n// For example, you can save it to a file or display it in a video element\n",
            "textToImage": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst image = await client.textToImage({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n    provider: \"{{ provider }}\",\n    model: \"{{ model.id }}\",\n\tinputs: {{ inputs.asObj.inputs }},\n\tparameters: { num_inference_steps: 5 },\n}{% if billTo %}, {\n    billTo: \"{{ billTo }}\",\n}{% endif %});\n/// Use the generated image (it's a Blob)",
            "textToSpeech": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst audio = await client.textToSpeech({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n    provider: \"{{ provider }}\",\n    model: \"{{ model.id }}\",\n\tinputs: {{ inputs.asObj.inputs }},\n}{% if billTo %}, {\n    billTo: \"{{ billTo }}\",\n}{% endif %});\n// Use the generated audio (it's a Blob)",
            "textToVideo": "import { InferenceClient } from \"@huggingface/inference\";\n\nconst client = new InferenceClient(\"{{ accessToken }}\");\n\nconst video = await client.textToVideo({\n{% if endpointUrl %}\n    endpointUrl: \"{{ endpointUrl }}\",\n{% endif %}\n    provider: \"{{ provider }}\",\n    model: \"{{ model.id }}\",\n\tinputs: {{ inputs.asObj.inputs }},\n}{% if billTo %}, {\n    billTo: \"{{ billTo }}\",\n}{% endif %});\n// Use the generated video (it's a Blob)"
        },
        "openai": {
            "conversational": "import { OpenAI } from \"openai\";\n\nconst client = new OpenAI({\n\tbaseURL: \"{{ baseUrl }}\",\n\tapiKey: \"{{ accessToken }}\",\n{% if billTo %}\n\tdefaultHeaders: {\n\t\t\"X-HF-Bill-To\": \"{{ billTo }}\" \n\t}\n{% endif %}\n});\n\nconst chatCompletion = await client.chat.completions.create({\n\tmodel: \"{{ providerModelId }}\",\n{{ inputs.asTsString }}\n});\n\nconsole.log(chatCompletion.choices[0].message);",
            "conversationalStream": "import { OpenAI } from \"openai\";\n\nconst client = new OpenAI({\n\tbaseURL: \"{{ baseUrl }}\",\n\tapiKey: \"{{ accessToken }}\",\n{% if billTo %}\n    defaultHeaders: {\n\t\t\"X-HF-Bill-To\": \"{{ billTo }}\" \n\t}\n{% endif %}\n});\n\nconst stream = await client.chat.completions.create({\n    model: \"{{ providerModelId }}\",\n{{ inputs.asTsString }}\n    stream: true,\n});\n\nfor await (const chunk of stream) {\n    process.stdout.write(chunk.choices[0]?.delta?.content || \"\");\n}"
        }
    },
    "python": {
        "fal_client": {
            "imageToImage": "{%if provider == \"fal-ai\" %}\nimport fal_client\nimport base64\n\ndef on_queue_update(update):\n    if isinstance(update, fal_client.InProgress):\n        for log in update.logs:\n           print(log[\"message\"])\n\nwith open(\"{{inputs.asObj.inputs}}\", \"rb\") as image_file:\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\n\nresult = fal_client.subscribe(\n    \"fal-ai/flux-kontext/dev\",\n    arguments={\n        \"prompt\": f\"data:image/png;base64,{image_base_64}\",\n        \"image_url\": \"{{ providerInputs.asObj.inputs }}\",\n    },\n    with_logs=True,\n    on_queue_update=on_queue_update,\n)\nprint(result)\n{%endif%}\n",
            "imageToVideo": "{%if provider == \"fal-ai\" %}\nimport fal_client\nimport base64\n\ndef on_queue_update(update):\n    if isinstance(update, fal_client.InProgress):\n        for log in update.logs:\n           print(log[\"message\"])\n\nwith open(\"{{inputs.asObj.inputs}}\", \"rb\") as image_file:\n    image_base_64 = base64.b64encode(image_file.read()).decode('utf-8')\n\nresult = fal_client.subscribe(\n    \"{{model.id}}\",\n    arguments={\n        \"image_url\": f\"data:image/png;base64,{image_base_64}\",\n        \"prompt\": \"{{inputs.asObj.parameters.prompt}}\",\n    },\n    with_logs=True,\n    on_queue_update=on_queue_update,\n)\nprint(result)\n{%endif%}\n",
            "textToImage": "{% if provider == \"fal-ai\" %}\nimport fal_client\n\n{% if providerInputs.asObj.loras is defined and providerInputs.asObj.loras != none %}\nresult = fal_client.subscribe(\n    \"{{ providerModelId }}\",\n    arguments={\n        \"prompt\": {{ inputs.asObj.inputs }},\n        \"loras\":{{ providerInputs.asObj.loras | tojson }},\n    },\n)\n{% else %}\nresult = fal_client.subscribe(\n    \"{{ providerModelId }}\",\n    arguments={\n        \"prompt\": {{ inputs.asObj.inputs }},\n    },\n)\n{% endif %} \nprint(result)\n{% endif %} "
        },
        "huggingface_hub": {
            "basic": "result = client.{{ methodName }}(\n    {{ inputs.asObj.inputs }},\n    model=\"{{ model.id }}\",\n)",
            "basicAudio": "output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\"{{ model.id }}\")",
            "basicImage": "output = client.{{ methodName }}({{ inputs.asObj.inputs }}, model=\"{{ model.id }}\")",
            "conversational": "completion = client.chat.completions.create(\n    model=\"{{ model.id }}\",\n{{ inputs.asPythonString }}\n)\n\nprint(completion.choices[0].message) ",
            "conversationalStream": "stream = client.chat.completions.create(\n    model=\"{{ model.id }}\",\n{{ inputs.asPythonString }}\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content, end=\"\") ",
            "documentQuestionAnswering": "output = client.document_question_answering(\n    \"{{ inputs.asObj.image }}\",\n    question=\"{{ inputs.asObj.question }}\",\n    model=\"{{ model.id }}\",\n) ",
            "imageToImage": "with open(\"{{ inputs.asObj.inputs }}\", \"rb\") as image_file:\n   input_image = image_file.read()\n\n# output is a PIL.Image object\nimage = client.image_to_image(\n    input_image,\n    prompt=\"{{ inputs.asObj.parameters.prompt }}\",\n    model=\"{{ model.id }}\",\n)\n",
            "imageToVideo": "with open(\"{{ inputs.asObj.inputs }}\", \"rb\") as image_file:\n   input_image = image_file.read()\n\nvideo = client.image_to_video(\n    input_image,\n    prompt=\"{{ inputs.asObj.parameters.prompt }}\",\n    model=\"{{ model.id }}\",\n) \n",
            "importInferenceClient": "from huggingface_hub import InferenceClient\n\nclient = InferenceClient(\n{% if endpointUrl %}\n    base_url=\"{{ baseUrl }}\",\n{% endif %}\n    provider=\"{{ provider }}\",\n    api_key=\"{{ accessToken }}\",\n{% if billTo %}\n    bill_to=\"{{ billTo }}\",\n{% endif %}\n)",
            "questionAnswering": "answer = client.question_answering(\n    question=\"{{ inputs.asObj.question }}\",\n    context=\"{{ inputs.asObj.context }}\",\n    model=\"{{ model.id }}\",\n) ",
            "tableQuestionAnswering": "answer = client.table_question_answering(\n    query=\"{{ inputs.asObj.query }}\",\n    table={{ inputs.asObj.table }},\n    model=\"{{ model.id }}\",\n) ",
            "textToImage": "# output is a PIL.Image object\nimage = client.text_to_image(\n    {{ inputs.asObj.inputs }},\n    model=\"{{ model.id }}\",\n) ",
            "textToSpeech": "# audio is returned as bytes\naudio = client.text_to_speech(\n    {{ inputs.asObj.inputs }},\n    model=\"{{ model.id }}\",\n) \n",
            "textToVideo": "video = client.text_to_video(\n    {{ inputs.asObj.inputs }},\n    model=\"{{ model.id }}\",\n) "
        },
        "openai": {
            "conversational": "from openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"{{ baseUrl }}\",\n    api_key=\"{{ accessToken }}\",\n{% if billTo %}\n    default_headers={\n        \"X-HF-Bill-To\": \"{{ billTo }}\"\n    }\n{% endif %}\n)\n\ncompletion = client.chat.completions.create(\n    model=\"{{ providerModelId }}\",\n{{ inputs.asPythonString }}\n)\n\nprint(completion.choices[0].message) ",
            "conversationalStream": "from openai import OpenAI\n\nclient = OpenAI(\n    base_url=\"{{ baseUrl }}\",\n    api_key=\"{{ accessToken }}\",\n{% if billTo %}\n    default_headers={\n        \"X-HF-Bill-To\": \"{{ billTo }}\"\n    }\n{% endif %}\n)\n\nstream = client.chat.completions.create(\n    model=\"{{ providerModelId }}\",\n{{ inputs.asPythonString }}\n    stream=True,\n)\n\nfor chunk in stream:\n    print(chunk.choices[0].delta.content, end=\"\")"
        },
        "requests": {
            "basic": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    \"inputs\": {{ providerInputs.asObj.inputs }},\n}) ",
            "basicAudio": "def query(filename):\n    with open(filename, \"rb\") as f:\n        data = f.read()\n    response = requests.post(API_URL, headers={\"Content-Type\": \"audio/flac\", **headers}, data=data)\n    return response.json()\n\noutput = query({{ providerInputs.asObj.inputs }})",
            "basicImage": "def query(filename):\n    with open(filename, \"rb\") as f:\n        data = f.read()\n    response = requests.post(API_URL, headers={\"Content-Type\": \"image/jpeg\", **headers}, data=data)\n    return response.json()\n\noutput = query({{ providerInputs.asObj.inputs }})",
            "conversational": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\nresponse = query({\n{{ autoInputs.asJsonString }}\n})\n\nprint(response[\"choices\"][0][\"message\"])",
            "conversationalStream": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload, stream=True)\n    for line in response.iter_lines():\n        if not line.startswith(b\"data:\"):\n            continue\n        if line.strip() == b\"data: [DONE]\":\n            return\n        yield json.loads(line.decode(\"utf-8\").lstrip(\"data:\").rstrip(\"/n\"))\n\nchunks = query({\n{{ autoInputs.asJsonString }},\n    \"stream\": True,\n})\n\nfor chunk in chunks:\n    print(chunk[\"choices\"][0][\"delta\"][\"content\"], end=\"\")",
            "documentQuestionAnswering": "def query(payload):\n    with open(payload[\"image\"], \"rb\") as f:\n        img = f.read()\n        payload[\"image\"] = base64.b64encode(img).decode(\"utf-8\")\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    \"inputs\": {\n        \"image\": \"{{ inputs.asObj.image }}\",\n        \"question\": \"{{ inputs.asObj.question }}\",\n    },\n}) ",
            "imageToImage": "\ndef query(payload):\n    with open(payload[\"inputs\"], \"rb\") as f:\n        img = f.read()\n        payload[\"inputs\"] = base64.b64encode(img).decode(\"utf-8\")\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nimage_bytes = query({\n{{ providerInputs.asJsonString }}\n})\n\n# You can access the image with PIL.Image for example\nimport io\nfrom PIL import Image\nimage = Image.open(io.BytesIO(image_bytes)) ",
            "imageToVideo": "\ndef query(payload):\n    with open(payload[\"inputs\"], \"rb\") as f:\n        img = f.read()\n        payload[\"inputs\"] = base64.b64encode(img).decode(\"utf-8\")\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nvideo_bytes = query({\n{{ inputs.asJsonString }}\n})\n",
            "importRequests": "{% if importBase64 %}\nimport base64\n{% endif %}\n{% if importJson %}\nimport json\n{% endif %}\nimport requests\n\nAPI_URL = \"{{ fullUrl }}\"\nheaders = {\n    \"Authorization\": \"{{ authorizationHeader }}\",\n{% if billTo %}\n    \"X-HF-Bill-To\": \"{{ billTo }}\"\n{% endif %}\n}",
            "tabular": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nresponse = query({\n    \"inputs\": {\n        \"data\": {{ providerInputs.asObj.inputs }}\n    },\n}) ",
            "textToAudio": "{% if model.library_name == \"transformers\" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\naudio_bytes = query({\n    \"inputs\": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio_bytes)\n{% else %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\naudio, sampling_rate = query({\n    \"inputs\": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio, rate=sampling_rate)\n{% endif %} ",
            "textToImage": "{% if provider == \"hf-inference\" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\nimage_bytes = query({\n    \"inputs\": {{ providerInputs.asObj.inputs }},\n})\n\n# You can access the image with PIL.Image for example\nimport io\nfrom PIL import Image\nimage = Image.open(io.BytesIO(image_bytes))\n{% endif %}",
            "textToSpeech": "{% if model.library_name == \"transformers\" %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.content\n\naudio_bytes = query({\n    \"text\": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio_bytes)\n{% else %}\ndef query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\naudio, sampling_rate = query({\n    \"text\": {{ inputs.asObj.inputs }},\n})\n# You can access the audio with IPython.display for example\nfrom IPython.display import Audio\nAudio(audio, rate=sampling_rate)\n{% endif %} ",
            "zeroShotClassification": "def query(payload):\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    \"inputs\": {{ providerInputs.asObj.inputs }},\n    \"parameters\": {\"candidate_labels\": [\"refund\", \"legal\", \"faq\"]},\n}) ",
            "zeroShotImageClassification": "def query(data):\n    with open(data[\"image_path\"], \"rb\") as f:\n        img = f.read()\n    payload={\n        \"parameters\": data[\"parameters\"],\n        \"inputs\": base64.b64encode(img).decode(\"utf-8\")\n    }\n    response = requests.post(API_URL, headers=headers, json=payload)\n    return response.json()\n\noutput = query({\n    \"image_path\": {{ providerInputs.asObj.inputs }},\n    \"parameters\": {\"candidate_labels\": [\"cat\", \"dog\", \"llama\"]},\n}) "
        }
    },
    "sh": {
        "curl": {
            "basic": "curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ providerInputs.asCurlString }}\n    }'",
            "basicAudio": "curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: audio/flac' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    --data-binary @{{ providerInputs.asObj.inputs }}",
            "basicImage": "curl {{ fullUrl }} \\\n    -X POST \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: image/jpeg' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    --data-binary @{{ providerInputs.asObj.inputs }}",
            "conversational": "curl {{ fullUrl }} \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ autoInputs.asCurlString }},\n        \"stream\": false\n    }'",
            "conversationalStream": "curl {{ fullUrl }} \\\n    -H 'Authorization: {{ authorizationHeader }}' \\\n    -H 'Content-Type: application/json' \\\n{% if billTo %}\n    -H 'X-HF-Bill-To: {{ billTo }}' \\\n{% endif %}\n    -d '{\n{{ autoInputs.asCurlString }},\n        \"stream\": true\n    }'",
            "zeroShotClassification": "curl {{ fullUrl }} \\\n    -X POST \\\n    -d '{\"inputs\": {{ providerInputs.asObj.inputs }}, \"parameters\": {\"candidate_labels\": [\"refund\", \"legal\", \"faq\"]}}' \\\n    -H 'Content-Type: application/json' \\\n    -H 'Authorization: {{ authorizationHeader }}'\n{% if billTo %} \\\n    -H 'X-HF-Bill-To: {{ billTo }}'\n{% endif %}"
        }
    }
};
}),
"[project]/node_modules/@huggingface/inference/dist/esm/snippets/getInferenceSnippets.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getInferenceSnippets",
    ()=>getInferenceSnippets
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$jinja$2f$dist$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/jinja/dist/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/tasks/dist/esm/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/tasks/dist/esm/snippets/inputs.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$types$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/tasks/dist/esm/snippets/types.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$templates$2e$exported$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/templates.exported.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/config.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
const PYTHON_CLIENTS = [
    "huggingface_hub",
    "fal_client",
    "requests",
    "openai"
];
const JS_CLIENTS = [
    "fetch",
    "huggingface.js",
    "openai"
];
const SH_CLIENTS = [
    "curl"
];
const CLIENTS = {
    js: [
        ...JS_CLIENTS
    ],
    python: [
        ...PYTHON_CLIENTS
    ],
    sh: [
        ...SH_CLIENTS
    ]
};
// The "auto"-provider policy is only available through the HF SDKs (huggingface.js / huggingface_hub)
// except for conversational tasks for which we have https://router.huggingface.co/v1/chat/completions
const CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY = {
    js: [
        "huggingface.js"
    ],
    python: [
        "huggingface_hub"
    ]
};
// Helpers to find + load templates
const hasTemplate = (language, client, templateName)=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$templates$2e$exported$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["templates"][language]?.[client]?.[templateName] !== undefined;
const loadTemplate = (language, client, templateName)=>{
    const template = __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$templates$2e$exported$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["templates"][language]?.[client]?.[templateName];
    if (!template) {
        throw new Error(`Template not found: ${language}/${client}/${templateName}`);
    }
    return (data)=>new __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$jinja$2f$dist$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["Template"](template).render({
            ...data
        });
};
const snippetImportPythonInferenceClient = loadTemplate("python", "huggingface_hub", "importInferenceClient");
const snippetImportRequests = loadTemplate("python", "requests", "importRequests");
// Needed for huggingface_hub basic snippets
const HF_PYTHON_METHODS = {
    "audio-classification": "audio_classification",
    "audio-to-audio": "audio_to_audio",
    "automatic-speech-recognition": "automatic_speech_recognition",
    "document-question-answering": "document_question_answering",
    "feature-extraction": "feature_extraction",
    "fill-mask": "fill_mask",
    "image-classification": "image_classification",
    "image-segmentation": "image_segmentation",
    "image-to-image": "image_to_image",
    "image-to-text": "image_to_text",
    "object-detection": "object_detection",
    "question-answering": "question_answering",
    "sentence-similarity": "sentence_similarity",
    summarization: "summarization",
    "table-question-answering": "table_question_answering",
    "tabular-classification": "tabular_classification",
    "tabular-regression": "tabular_regression",
    "text-classification": "text_classification",
    "text-generation": "text_generation",
    "text-to-image": "text_to_image",
    "text-to-speech": "text_to_speech",
    "text-to-video": "text_to_video",
    "token-classification": "token_classification",
    translation: "translation",
    "visual-question-answering": "visual_question_answering",
    "zero-shot-classification": "zero_shot_classification",
    "zero-shot-image-classification": "zero_shot_image_classification"
};
// Needed for huggingface.js basic snippets
const HF_JS_METHODS = {
    "automatic-speech-recognition": "automaticSpeechRecognition",
    "feature-extraction": "featureExtraction",
    "fill-mask": "fillMask",
    "image-classification": "imageClassification",
    "question-answering": "questionAnswering",
    "sentence-similarity": "sentenceSimilarity",
    summarization: "summarization",
    "table-question-answering": "tableQuestionAnswering",
    "text-classification": "textClassification",
    "text-generation": "textGeneration",
    "token-classification": "tokenClassification",
    "text-to-speech": "textToSpeech",
    translation: "translation"
};
// Placeholders to replace with env variable in snippets
// little hack to support both direct requests and routing => routed requests should start with "hf_"
const ACCESS_TOKEN_ROUTING_PLACEHOLDER = "hf_token_placeholder";
const ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER = "not_hf_token_placeholder";
// Snippet generators
const snippetGenerator = (templateName, inputPreparationFn)=>{
    return (model, provider, inferenceProviderMapping, opts)=>{
        const logger = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getLogger"])();
        const providerModelId = inferenceProviderMapping?.providerId ?? model.id;
        /// Hacky: hard-code conversational templates here
        let task = model.pipeline_tag;
        if (model.pipeline_tag && [
            "text-generation",
            "image-text-to-text"
        ].includes(model.pipeline_tag) && model.tags.includes("conversational")) {
            templateName = opts?.streaming ? "conversationalStream" : "conversational";
            inputPreparationFn = prepareConversationalInput;
            task = "conversational";
        }
        let providerHelper;
        try {
            providerHelper = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getProviderHelper"])(provider, task);
        } catch (e) {
            logger.error(`Failed to get provider helper for ${provider} (${task})`, e);
            return [];
        }
        const placeholder = opts?.directRequest ? ACCESS_TOKEN_DIRECT_REQUEST_PLACEHOLDER : ACCESS_TOKEN_ROUTING_PLACEHOLDER;
        const accessTokenOrPlaceholder = opts?.accessToken ?? placeholder;
        /// Prepare inputs + make request
        const inputs = opts?.inputs ? {
            inputs: opts.inputs
        } : inputPreparationFn ? inputPreparationFn(model, opts) : {
            inputs: (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model)
        };
        const request = (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["makeRequestOptionsFromResolvedModel"])(providerModelId, providerHelper, {
            accessToken: accessTokenOrPlaceholder,
            provider,
            endpointUrl: opts?.endpointUrl ?? (provider === "auto" ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_ROUTER_AUTO_ENDPOINT"] : undefined),
            ...inputs
        }, inferenceProviderMapping, {
            task,
            billTo: opts?.billTo
        });
        /// Parse request.info.body if not a binary.
        /// This is the body sent to the provider. Important for snippets with raw payload (e.g curl, requests, etc.)
        let providerInputs = inputs;
        const bodyAsObj = request.info.body;
        if (typeof bodyAsObj === "string") {
            try {
                providerInputs = JSON.parse(bodyAsObj);
            } catch (e) {
                logger.error("Failed to parse body as JSON", e);
            }
        }
        // Inputs for the "auto" route is strictly the same as "inputs", except the model includes the provider
        // If not "auto" route, use the providerInputs
        const autoInputs = !opts?.endpointUrl && !opts?.directRequest ? provider !== "auto" ? {
            ...inputs,
            model: `${model.id}:${provider}`
        } : {
            ...inputs,
            model: `${model.id}`
        } : providerInputs;
        /// Prepare template injection data
        const params = {
            accessToken: accessTokenOrPlaceholder,
            authorizationHeader: request.info.headers?.Authorization,
            baseUrl: task === "conversational" && !opts?.endpointUrl && !opts?.directRequest ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_ROUTER_AUTO_ENDPOINT"] : removeSuffix(request.url, "/chat/completions"),
            fullUrl: task === "conversational" && !opts?.endpointUrl && !opts?.directRequest ? __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$config$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["HF_ROUTER_AUTO_ENDPOINT"] + "/chat/completions" : request.url,
            inputs: {
                asObj: inputs,
                asCurlString: formatBody(inputs, "curl"),
                asJsonString: formatBody(inputs, "json"),
                asPythonString: formatBody(inputs, "python"),
                asTsString: formatBody(inputs, "ts")
            },
            providerInputs: {
                asObj: providerInputs,
                asCurlString: formatBody(providerInputs, "curl"),
                asJsonString: formatBody(providerInputs, "json"),
                asPythonString: formatBody(providerInputs, "python"),
                asTsString: formatBody(providerInputs, "ts")
            },
            autoInputs: {
                asObj: autoInputs,
                asCurlString: formatBody(autoInputs, "curl"),
                asJsonString: formatBody(autoInputs, "json"),
                asPythonString: formatBody(autoInputs, "python"),
                asTsString: formatBody(autoInputs, "ts")
            },
            model,
            provider,
            providerModelId: task === "conversational" && !opts?.endpointUrl && !opts?.directRequest ? provider !== "auto" ? `${model.id}:${provider}` // e.g. "moonshotai/Kimi-K2-Instruct:groq"
             : model.id : providerModelId ?? model.id,
            billTo: opts?.billTo,
            endpointUrl: opts?.endpointUrl
        };
        /// Iterate over clients => check if a snippet exists => generate
        const clients = provider === "auto" && task !== "conversational" ? CLIENTS_NON_CONVERSATIONAL_AUTO_POLICY : CLIENTS;
        return __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$types$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["inferenceSnippetLanguages"].map((language)=>{
            const langClients = clients[language] ?? [];
            return langClients.map((client)=>{
                if (!hasTemplate(language, client, templateName)) {
                    return;
                }
                const template = loadTemplate(language, client, templateName);
                if (client === "huggingface_hub" && templateName.includes("basic")) {
                    if (!(model.pipeline_tag && model.pipeline_tag in HF_PYTHON_METHODS)) {
                        return;
                    }
                    params["methodName"] = HF_PYTHON_METHODS[model.pipeline_tag];
                }
                if (client === "huggingface.js" && templateName.includes("basic")) {
                    if (!(model.pipeline_tag && model.pipeline_tag in HF_JS_METHODS)) {
                        return;
                    }
                    params["methodName"] = HF_JS_METHODS[model.pipeline_tag];
                }
                /// Generate snippet
                let snippet = template(params).trim();
                if (!snippet) {
                    return;
                }
                /// Add import section separately
                if (client === "huggingface_hub") {
                    const importSection = snippetImportPythonInferenceClient({
                        ...params
                    });
                    snippet = `${importSection}\n\n${snippet}`;
                } else if (client === "requests") {
                    const importSection = snippetImportRequests({
                        ...params,
                        importBase64: snippet.includes("base64"),
                        importJson: snippet.includes("json.")
                    });
                    snippet = `${importSection}\n\n${snippet}`;
                }
                /// Replace access token placeholder
                if (snippet.includes(placeholder)) {
                    snippet = replaceAccessTokenPlaceholder(opts?.directRequest, placeholder, snippet, language, provider, opts?.endpointUrl);
                }
                /// Snippet is ready!
                return {
                    language,
                    client: client,
                    content: snippet
                };
            }).filter((snippet)=>snippet !== undefined);
        }).flat();
    };
};
const prepareDocumentQuestionAnsweringInput = (model)=>{
    return JSON.parse((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model));
};
const prepareImageToImageInput = (model)=>{
    const data = JSON.parse((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model));
    return {
        inputs: data.image,
        parameters: {
            prompt: data.prompt
        }
    };
};
const prepareConversationalInput = (model, opts)=>{
    return {
        messages: opts?.messages ?? (0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model),
        ...opts?.temperature ? {
            temperature: opts?.temperature
        } : undefined,
        ...opts?.max_tokens ? {
            max_tokens: opts?.max_tokens
        } : undefined,
        ...opts?.top_p ? {
            top_p: opts?.top_p
        } : undefined
    };
};
const prepareQuestionAnsweringInput = (model)=>{
    const data = JSON.parse((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model));
    return {
        question: data.question,
        context: data.context
    };
};
const prepareTableQuestionAnsweringInput = (model)=>{
    const data = JSON.parse((0, __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$tasks$2f$dist$2f$esm$2f$snippets$2f$inputs$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getModelInputSnippet"])(model));
    return {
        query: data.query,
        table: JSON.stringify(data.table)
    };
};
const snippets = {
    "audio-classification": snippetGenerator("basicAudio"),
    "audio-to-audio": snippetGenerator("basicAudio"),
    "automatic-speech-recognition": snippetGenerator("basicAudio"),
    "document-question-answering": snippetGenerator("documentQuestionAnswering", prepareDocumentQuestionAnsweringInput),
    "feature-extraction": snippetGenerator("basic"),
    "fill-mask": snippetGenerator("basic"),
    "image-classification": snippetGenerator("basicImage"),
    "image-segmentation": snippetGenerator("basicImage"),
    "image-text-to-text": snippetGenerator("conversational"),
    "image-to-image": snippetGenerator("imageToImage", prepareImageToImageInput),
    "image-to-text": snippetGenerator("basicImage"),
    "image-to-video": snippetGenerator("imageToVideo", prepareImageToImageInput),
    "object-detection": snippetGenerator("basicImage"),
    "question-answering": snippetGenerator("questionAnswering", prepareQuestionAnsweringInput),
    "sentence-similarity": snippetGenerator("basic"),
    summarization: snippetGenerator("basic"),
    "tabular-classification": snippetGenerator("tabular"),
    "tabular-regression": snippetGenerator("tabular"),
    "table-question-answering": snippetGenerator("tableQuestionAnswering", prepareTableQuestionAnsweringInput),
    "text-classification": snippetGenerator("basic"),
    "text-generation": snippetGenerator("basic"),
    "text-to-audio": snippetGenerator("textToAudio"),
    "text-to-image": snippetGenerator("textToImage"),
    "text-to-speech": snippetGenerator("textToSpeech"),
    "text-to-video": snippetGenerator("textToVideo"),
    "token-classification": snippetGenerator("basic"),
    translation: snippetGenerator("basic"),
    "zero-shot-classification": snippetGenerator("zeroShotClassification"),
    "zero-shot-image-classification": snippetGenerator("zeroShotImageClassification")
};
function getInferenceSnippets(model, provider, inferenceProviderMapping, opts) {
    return model.pipeline_tag && model.pipeline_tag in snippets ? snippets[model.pipeline_tag]?.(model, provider, inferenceProviderMapping, opts) ?? [] : [];
}
// String manipulation helpers
function formatBody(obj, format) {
    switch(format){
        case "curl":
            return indentString(formatBody(obj, "json"));
        case "json":
            /// Hacky: remove outer brackets to make is extendable in templates
            return JSON.stringify(obj, null, 4).split("\n").slice(1, -1).join("\n");
        case "python":
            return indentString(Object.entries(obj).map(([key, value])=>{
                const formattedValue = JSON.stringify(value, null, 4).replace(/"/g, '"');
                return `${key}=${formattedValue},`;
            }).join("\n"));
        case "ts":
            /// Hacky: remove outer brackets to make is extendable in templates
            return formatTsObject(obj).split("\n").slice(1, -1).join("\n");
        default:
            throw new Error(`Unsupported format: ${format}`);
    }
}
function formatTsObject(obj, depth) {
    depth = depth ?? 0;
    /// Case int, boolean, string, etc.
    if (typeof obj !== "object" || obj === null) {
        return JSON.stringify(obj);
    }
    /// Case array
    if (Array.isArray(obj)) {
        const items = obj.map((item)=>{
            const formatted = formatTsObject(item, depth + 1);
            return `${" ".repeat(4 * (depth + 1))}${formatted},`;
        }).join("\n");
        return `[\n${items}\n${" ".repeat(4 * depth)}]`;
    }
    /// Case mapping
    const entries = Object.entries(obj);
    const lines = entries.map(([key, value])=>{
        const formattedValue = formatTsObject(value, depth + 1);
        const keyStr = /^[a-zA-Z_$][a-zA-Z0-9_$]*$/.test(key) ? key : `"${key}"`;
        return `${" ".repeat(4 * (depth + 1))}${keyStr}: ${formattedValue},`;
    }).join("\n");
    return `{\n${lines}\n${" ".repeat(4 * depth)}}`;
}
function indentString(str) {
    return str.split("\n").map((line)=>" ".repeat(4) + line).join("\n");
}
function removeSuffix(str, suffix) {
    return str.endsWith(suffix) ? str.slice(0, -suffix.length) : str;
}
function replaceAccessTokenPlaceholder(directRequest, placeholder, snippet, language, provider, endpointUrl) {
    // If "opts.accessToken" is not set, the snippets are generated with a placeholder.
    // Once snippets are rendered, we replace the placeholder with code to fetch the access token from an environment variable.
    // Determine if HF_TOKEN or specific provider token should be used
    const useHfToken = !endpointUrl && // custom endpointUrl => use a generic API_TOKEN
    (provider == "hf-inference" || !directRequest && // if explicit directRequest => use provider-specific token
    (snippet.includes("InferenceClient") || // using a client => use $HF_TOKEN
    snippet.includes("https://router.huggingface.co"))); // explicit routed request => use $HF_TOKEN
    const accessTokenEnvVar = useHfToken ? "HF_TOKEN" // e.g. routed request or hf-inference
     : endpointUrl ? "API_TOKEN" : provider.toUpperCase().replace("-", "_") + "_API_KEY"; // e.g. "REPLICATE_API_KEY"
    // Replace the placeholder with the env variable
    if (language === "sh") {
        snippet = snippet.replace(`'Authorization: Bearer ${placeholder}'`, `"Authorization: Bearer $${accessTokenEnvVar}"` // e.g. "Authorization: Bearer $HF_TOKEN"
        );
    } else if (language === "python") {
        snippet = "import os\n" + snippet;
        snippet = snippet.replace(`"${placeholder}"`, `os.environ["${accessTokenEnvVar}"]` // e.g. os.environ["HF_TOKEN")
        );
        snippet = snippet.replace(`"Bearer ${placeholder}"`, `f"Bearer {os.environ['${accessTokenEnvVar}']}"` // e.g. f"Bearer {os.environ['HF_TOKEN']}"
        );
        snippet = snippet.replace(`"Key ${placeholder}"`, `f"Key {os.environ['${accessTokenEnvVar}']}"` // e.g. f"Key {os.environ['FAL_AI_API_KEY']}"
        );
        snippet = snippet.replace(`"X-Key ${placeholder}"`, `f"X-Key {os.environ['${accessTokenEnvVar}']}"` // e.g. f"X-Key {os.environ['BLACK_FOREST_LABS_API_KEY']}"
        );
    } else if (language === "js") {
        snippet = snippet.replace(`"${placeholder}"`, `process.env.${accessTokenEnvVar}` // e.g. process.env.HF_TOKEN
        );
        snippet = snippet.replace(`Authorization: "Bearer ${placeholder}",`, `Authorization: \`Bearer $\{process.env.${accessTokenEnvVar}}\`,` // e.g. Authorization: `Bearer ${process.env.HF_TOKEN}`,
        );
        snippet = snippet.replace(`Authorization: "Key ${placeholder}",`, `Authorization: \`Key $\{process.env.${accessTokenEnvVar}}\`,` // e.g. Authorization: `Key ${process.env.FAL_AI_API_KEY}`,
        );
        snippet = snippet.replace(`Authorization: "X-Key ${placeholder}",`, `Authorization: \`X-Key $\{process.env.${accessTokenEnvVar}}\`,` // e.g. Authorization: `X-Key ${process.env.BLACK_FOREST_LABS_AI_API_KEY}`,
        );
    }
    return snippet;
}
}),
"[project]/node_modules/@huggingface/inference/dist/esm/snippets/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$getInferenceSnippets$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/getInferenceSnippets.js [app-route] (ecmascript)");
;
}),
"[project]/node_modules/@huggingface/inference/dist/esm/snippets/index.js [app-route] (ecmascript)", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([
    "getInferenceSnippets",
    ()=>__TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$getInferenceSnippets$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__["getInferenceSnippets"]
]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$getInferenceSnippets$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/getInferenceSnippets.js [app-route] (ecmascript)");
}),
"[project]/node_modules/@huggingface/inference/dist/esm/index.js [app-route] (ecmascript) <locals>", ((__turbopack_context__) => {
"use strict";

__turbopack_context__.s([]);
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$InferenceClient$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/InferenceClient.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$errors$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/errors.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$types$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/types.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$tasks$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/tasks/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__$3c$locals$3e$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/index.js [app-route] (ecmascript) <locals>");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$snippets$2f$index$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/snippets/index.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$getProviderHelper$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/getProviderHelper.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$makeRequestOptions$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/makeRequestOptions.js [app-route] (ecmascript)");
var __TURBOPACK__imported__module__$5b$project$5d2f$node_modules$2f40$huggingface$2f$inference$2f$dist$2f$esm$2f$lib$2f$logger$2e$js__$5b$app$2d$route$5d$__$28$ecmascript$29$__ = __turbopack_context__.i("[project]/node_modules/@huggingface/inference/dist/esm/lib/logger.js [app-route] (ecmascript)");
;
;
;
;
;
;
;
;
;
}),
];

//# sourceMappingURL=node_modules_%40huggingface_inference_dist_esm_935862ed._.js.map